{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8adac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from openai import AzureOpenAI\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35496e05",
   "metadata": {},
   "source": [
    "Conectando ao Neo4j e aos Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e744efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a3bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando o modelo de Embedding da Azure OpenAI\n",
    "\n",
    "#client_small = AzureOpenAI(\n",
    "#  api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "#  azure_endpoint = os.getenv(\"EMBEDDING_SMALL_ENDPOINT\"),\n",
    "#  api_version = os.getenv(\"API_VERSION\"))\n",
    "\n",
    "client_large = AzureOpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "  azure_endpoint = os.getenv(\"EMBEDDING_LARGE_ENDPOINT\"),\n",
    "  api_version = os.getenv(\"API_VERSION\"))\n",
    "\n",
    "\n",
    "# The function receives a sencence and returns the embedding (1D numpy array)\n",
    "def get_embeddings_openAI(text):\n",
    "    #model = \"text-embedding-3-small\"\n",
    "    #embedding_small = client_small.embeddings.create(input = text, model=model)\n",
    "    #return embedding_small.data[0].embedding\n",
    "    model = \"text-embedding-3-large\"\n",
    "    embedding_large = client_large.embeddings.create(input = text, model=model)\n",
    "    return embedding_large.data[0].embedding \n",
    "\n",
    "\n",
    "# Conectando o modelo de Embedding da Google Gemini\n",
    "#genai.configure(api_key=os.getenv('GEMINI_API'))\n",
    "\n",
    "#def get_embeddings_openAI(text):\n",
    "#    result = genai.embed_content(\n",
    "#        model=\"models/text-embedding-004\",\n",
    "#        content=text)\n",
    "#    return result['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f43cc",
   "metadata": {},
   "source": [
    "### GRAPH RAG  \n",
    "  \n",
    "Definir uma funcao que: 1) recebe um texto; 2)usa o modelo de embedding para transformar o texto em um vetor: 3) Usa o vetor para buscar outros textos do grafo (usando o índice de vetores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4442e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def busca_grafo_vetor(query_text):\n",
    "#    query_embedding = get_embeddings_openAI(query_text)\n",
    "\n",
    "    # Buscando no índice de vetores \n",
    "#    results = graph.query(\"\"\"\n",
    "#        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\")\n",
    "#        YIELD node, score\n",
    "#        RETURN node.uri, node.title, node.abstract, node.description, score \n",
    "#        LIMIT 15 \n",
    "#        \"\"\")\n",
    "    \n",
    "#    return (results)\n",
    "\n",
    "#MATCH (node)-[:author]-(author)\n",
    "#RETURN node.uri, node.title, node.abstract, node.created, author.label, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d270d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def busca_grafo_fulltext(query_text):\n",
    "\n",
    "#    results = graph.query(\"\"\"\n",
    "#        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "#        YIELD node, score\n",
    "#        RETURN node.uri, node.title, node.abstract, node.description, score  \n",
    "#        LIMIT 15 \n",
    "#        \"\"\")\n",
    "#    return (results)\n",
    "\n",
    "#        MATCH (node)-[:author]-(author)\n",
    "#        RETURN node.uri, node.title, node.abstract, node.created , author.label, score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04257315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_vetor(query_text):\n",
    "    query_embedding = get_embeddings_openAI(query_text)\n",
    "\n",
    "    # Buscando no índice de vetores \n",
    "    results = graph.query(\"\"\"\n",
    "        CALL{\n",
    "        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\") \n",
    "        YIELD node, score\n",
    "\n",
    "        MATCH (node:Thesis)\n",
    "        MATCH (node)-[:author]-(author)\n",
    "        RETURN score, node.created AS created, node.uri AS node_uri, node.title AS title, node.abstract AS abstract, node.description AS description, author.label AS author \n",
    "        LIMIT 15 \n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\") \n",
    "        YIELD node, score\n",
    "        MATCH (node:Excerpt)<-[:BFO_0000051]-(t:Thesis)\n",
    "        MATCH (t)-[:author]-(author)\n",
    "        RETURN score, t.created AS created, node.uri AS node_uri, t.title AS title, Null AS abstract, node.description AS description,  author.label AS author\n",
    "        LIMIT 15}\n",
    "\n",
    "        RETURN score, created, node_uri, title, abstract, description, author\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 15\n",
    "        \"\"\")\n",
    "    \n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f731737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_fulltext(query_text):\n",
    "\n",
    "    results = graph.query(\"\"\"\n",
    "        CALL{\n",
    "        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "        YIELD node, score\n",
    "\n",
    "        MATCH (node:Thesis)\n",
    "        MATCH (node)-[:author]-(author)\n",
    "        RETURN score, node.created AS created, node.uri AS node_uri, node.title AS title, node.abstract AS abstract, node.description AS description, author.label AS author \n",
    "        LIMIT 15 \n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "        YIELD node, score\n",
    "        MATCH (node:Excerpt)<-[:BFO_0000051]-(t:Thesis)\n",
    "        MATCH (t)-[:author]-(author)\n",
    "        RETURN score, t.created AS created, node.uri AS node_uri, t.title AS title, Null AS abstract, node.description AS description,  author.label AS author\n",
    "        LIMIT 15}\n",
    "\n",
    "        RETURN score, created, node_uri, title, abstract, description, author\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 15\n",
    "        \"\"\")\n",
    "    return (results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7098e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciprocal Rank Fusion (RRF)\n",
    "def RFF(rank1, rank2, w_rank1=1.0, w_rank2=1.0):\n",
    "    k = 60\n",
    "    score = {}\n",
    "    title_text = {}\n",
    "\n",
    "    for p in range(len(rank1)):\n",
    "        uri = rank1[p]['node_uri']\n",
    "        score[uri] = 1/(p+1+k)\n",
    "        title_text[uri] = {'title': rank1[p]['title'],#['node.title'], \n",
    "                           'text': str(rank1[p]['abstract']) + \" \" + str(rank1[p]['description']),#['node.abstract'], \n",
    "                           'author': rank1[p]['author'],#['author.label'],\n",
    "                           'created': rank1[p]['created'],#['node.created']}\n",
    "                           'uri': uri}\n",
    "\n",
    "    for p in range(len(rank2)):\n",
    "        uri = rank2[p]['node_uri']\n",
    "        if uri not in score:\n",
    "            score[uri] = 1/(p+1+k)\n",
    "            title_text[uri] = {'title': rank1[p]['title'],#['node.title'], \n",
    "                            'text': str(rank1[p]['abstract']) + \" \" + str(rank1[p]['description']),#['node.abstract'], \n",
    "                            'author': rank1[p]['author'],#['author.label'],\n",
    "                            'created': rank1[p]['created'],#['node.created']}\n",
    "                            'uri': uri}\n",
    "        else:\n",
    "            score[uri] = (score[uri]) * w_rank1 + (1/(p+1+k)) * w_rank2\n",
    "\n",
    "\n",
    "    uri_list = []\n",
    "    score_list = []\n",
    "    sorted_title_text = []\n",
    "    for i in sorted(score, key = score.get, reverse=True):\n",
    "        uri_list.append(i)\n",
    "        score_list.append(score[i])\n",
    "        sorted_title_text.append(title_text[i])\n",
    "    return (sorted_title_text, score_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c543a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_hibrida(query_text):\n",
    "    results_vector = busca_grafo_vetor(query_text)\n",
    "    results_text = busca_grafo_fulltext(query_text)\n",
    "    return RFF(results_vector, results_text, w_rank1=1.0, w_rank2=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa323dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conectando Azure OpenAI\n",
    "#endpoint = os.getenv(\"GPT35_ENDPOINT\")  \n",
    "#deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-35-turbo\")\n",
    "#endpoint = os.getenv(\"GPT4_ENDPOINT\")  \n",
    "#deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4\") \n",
    "#subscription_key = os.getenv(\"OPENAI_API_KEY\")   \n",
    "     \n",
    "#client_chat = AzureOpenAI(  \n",
    "#        azure_endpoint=endpoint,  \n",
    "#        api_key=subscription_key,  \n",
    "#        api_version=\"2024-05-01-preview\",  \n",
    "#    )  \n",
    "    \n",
    "#Conectando Google Gemini\n",
    "genai.configure(api_key=os.getenv('GEMINI_API'))\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7f36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_respostas(query_text):\n",
    "\n",
    "    results = busca_grafo_hibrida(query_text)\n",
    "\n",
    "    respostas = []\n",
    "    uris = []\n",
    "\n",
    "    for n in range(5):\n",
    "        text = results[0][n]['text']\n",
    "        titulo = results[0][n]['title']\n",
    "        autor = results[0][n]['author']\n",
    "        created = results[0][n]['created']\n",
    "        uri = results[0][n]['uri']\n",
    "        citation = autor + \". \" + titulo + \". \" + created + \".\"\n",
    "\n",
    "        #Azure OpenAI Completion\n",
    "        #completion = client_chat.chat.completions.create(  \n",
    "        #model=deployment,  \n",
    "        #messages=[\n",
    "        #    {\n",
    "        #    \"role\": \"system\",\n",
    "        #    \"content\": \"You will be provided with a text delimited by triple quotes and a question. Your task is to answer the question using only the provided text and to cite the passage(s) of the document used to answer the question. If the text does not contain the information needed to answer this question then simply write: 'Informação Insuficiente.' If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages (\" + citation + \"). Your answers must be written in Brazilian Portuguese.\"\n",
    "        #    },\n",
    "        #    {\n",
    "        #    \"role\": \"user\",\n",
    "        #    \"content\": '\"\"\"' + text + '\"\"\" \"QUESTION: \"' + query_text\n",
    "        #    }\n",
    "        #    ],    \n",
    "        #        max_tokens=800, temperature=1.0, top_p=0.95, frequency_penalty=0, presence_penalty=0, stop=None, stream=False  \n",
    "        #    )  \n",
    "        #resposta = completion.to_dict()['choices'][0]['message']['content']\n",
    "        \n",
    "        #Google Gemini Completion\n",
    "        resposta = gemini_model.generate_content('You will be provided with a text delimited by triple quotes and a question. Your task is to answer the question using only the provided text and to cite the passage(s) of the document used to answer the question. If the text does not contain the information needed to answer this question then simply write: \"Informação Insuficiente\". If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages (' + citation + '). Your answers must be written in Brazilian Portuguese. /n  \"\"\"' + text + '\"\"\" \"QUESTION: \"' + query_text).text\n",
    "        \n",
    "        respostas.append(resposta)\n",
    "        uris.append(uri)\n",
    "        \n",
    "    return respostas, uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4017d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_respostas(query_text, respostas):\n",
    "\n",
    "    fontes = ''\n",
    "    for r in respostas:\n",
    "        fontes = fontes + '\\n' + r \n",
    "\n",
    "    #completion = client_chat.chat.completions.create(  \n",
    "    #model=deployment,  \n",
    "    #messages=[\n",
    "    #    {\n",
    "    #    \"role\": \"system\",\n",
    "    #    \"content\": \"You will be provided with one question and several answers for the question delimited by triple quotes. Your task is to summarize the provided answers. If all answers were 'Informação Insuficiente', you must also return the text 'Informação Insuficiente.' You must maintain the citations and references for the original documents using the same format. Include facts present in the provided answers that directly address the provided question in the final answer. Your answers must be written in Brazilian Portuguese.\"\n",
    "    #    },\n",
    "    #    {\n",
    "    #    \"role\": \"user\",\n",
    "    #    \"content\": '\"\"\"' + fontes + '\"\"\"' + 'QUESTION: ' + query_text\n",
    "    #    }\n",
    "    #    ],  \n",
    "    #        max_tokens=800, temperature=1.0, top_p=0.95,frequency_penalty=0, presence_penalty=0, stop=None, stream=False  \n",
    "    #    )  \n",
    "    \n",
    "    #resposta = completion.to_json()\n",
    "    #summ_resposta = completion.to_dict()['choices'][0]['message']['content']\n",
    "\n",
    "    #Google Gemini Completion\n",
    "    summ_resposta = gemini_model.generate_content('You will be provided with one question and several answers for the question delimited by triple quotes. Your task is to summarize the provided answers. If all answers were \"Informação Insuficiente\", you must also return the text \"Informação Insuficiente\". You must maintain the citations and references for the original documents using the same format. Include facts present in the provided answers that directly address the provided question in the final answer. Your answers must be written in Brazilian Portuguese. \\n \"\"\"' + fontes + '\"\"\"' + 'QUESTION: ' + query_text).text\n",
    "        \n",
    "        \n",
    "    return summ_resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69d8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de perguntas\n",
    "\n",
    "def perguntas(personagem):\n",
    "    perg = []\n",
    "    #perg.append('Qual o nome completo de ' + personagem + '?')\n",
    "    #perg.append('Onde nasceu ' + personagem + '?')\n",
    "    #perg.append('Qual a data de nascimento de ' + personagem + '?')\n",
    "    #perg.append('Onde morreu ' + personagem + '?')\n",
    "    #perg.append('Qual a data de morte de ' + personagem + '?')\n",
    "    perg.append('Quem foi ' + personagem + '?')\n",
    "    perg.append('Quais os principais feitos de ' + personagem + '?')\n",
    "    perg.append('Quais os principais cargos, funções, ou emprogos de ' + personagem + '?')\n",
    "    \n",
    "    return perg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e9a60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perguntas_e_respostas(personagem):\n",
    "\n",
    "    perg_resp = {}\n",
    "\n",
    "    pergs = perguntas(personagem)\n",
    "\n",
    "    for perg in pergs:\n",
    "        respostas, uris = gen_respostas(perg)\n",
    "        resposta_final = summarize_respostas(perg, respostas)\n",
    "        perg_resp[perg] = {\"Resumo\": resposta_final, \"Respostas\": respostas, \"uris\": uris} \n",
    "\n",
    "    return perg_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93fa2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "personagem = 'Viviane Juguero'\n",
    "dic_perguntas_respostas = perguntas_e_respostas(personagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25cd02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Quem foi Viviane Juguero?', 'Quais os principais feitos de Viviane Juguero?', 'Quais os principais cargos, funções, ou emprogos de Viviane Juguero?'])\n"
     ]
    }
   ],
   "source": [
    "print(dic_perguntas_respostas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "243046fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Resumo': 'Viviane Juguero foi uma figura multifacetada e atuante nas artes, letras e filosofia (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.), nascida em Bagé, no Pampa.  Dramaturga, pesquisadora, professora, atriz, poeta e produtora (Juguero, 2019, p. 4; Juguero, 2023), ela se doutorou em Artes Cênicas pela UFRGS com a tese \"Dramaturgias radicais: poéticas matrísticas para uma arte dialógica\" (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.; Juguero, 2019), que discute a relação entre criação e recepção dramatúrgica,  abordando a questão da autoria e sua intencionalidade, dialogando com Bakhtin (Juguero, 2019, p. 78-79; Juguero, 2019, p. 43).  Sua dramaturgia, descrita como \"radical\",  aborda a complexidade das relações humanas, focando em relações étnicas e de gênero, buscando provocar reflexões sobre a identidade brasileira e ampliando as relações emotivo-racionais do público, dando voz a grupos sociais marginalizados (Juguero, 2023).  Ela  se considerava uma agente de transformação social através da arte (Juguero, 2023), utilizando a dramaturgia radical em todos os seus trabalhos,  como na peça \"Cavalo de Santo\" (Juguero, 2023; p. 191), presente na coletânea *Dramaturgia Negra* (2018).  Sua trajetória incluiu  participação em  Oficinas Populares de Teatro (1994) (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.; p. 190),  integração ao Grupo de Dramaturgas Femininas “As DramaturgAs”, docência no Nordic Black Theatre (Noruega) e  participação no Conselho Consultivo de Especialistas do CAST na Nova Zelândia (p. 190).  Também coordenou o CBTIJ no Rio Grande do Sul e integrou redes nacionais e internacionais, como a ASSITEJ (p. 190-191).  Seu trabalho, influenciado pelo pensamento de Paulo Freire (p. 190),  inclui pesquisa sobre dramaturgia e teatro para a infância, com foco em \"Teatricidades Pluriperceptivas e Multiculturais para Diversas Primeiras Infâncias\" em seu pós-doutorado na Universidade de Stavanger (p. 190).  Sua produção intelectual e artística abrange artigos, livros, dramaturgias, poesias, músicas e audiovisual, com reconhecimento nacional e internacional (p. 191).  Ela descrevia suas criações artísticas como reflexo de suas elaborações teóricas, e vice-versa (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.).\\n',\n",
       " 'Respostas': ['Viviane Juguero foi uma mulher atuante nas artes, letras e filosofia, cujo trabalho se estendeu a outros territórios, línguas e formas de compreender o mundo (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.). Ela mesma descreveu suas criações artísticas como reflexo de suas elaborações teóricas, e vice-versa (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.). Nascida em Bagé, no Pampa, ela se tornou uma desbravadora de fronteiras geográficas, culturais e intelectuais a partir de sua práxis, tendo se envolvido com as Oficinas Populares de Teatro do Projeto de Descentralização da Cultura em 1994 (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.).  Ela se doutorou em Artes Cênicas pela UFRGS, defendendo a tese \"Dramaturgias radicais: poéticas matrísticas para uma arte dialógica\" (Piegaz, Acevesmoreno Flores. Dramaturgias negras do Pampa : uma análise decolonial. 2023.).\\n',\n",
       "  'Viviane Juguero foi uma pesquisadora, dramaturga e artista que, em sua dramaturgia, abordou a complexidade das relações humanas, focando nas relações étnicas e de gênero, buscando provocar a reflexão sobre a identidade brasileira (Juguero, 2023).  Ela se considera uma agente de transformação social através de sua arte, buscando ampliar as relações emotivo-racionais do público e dar voz a grupos sociais negligenciados e silenciados (Juguero, 2023). Sua concepção de dramaturgia radical propõe um diálogo com o espectador, criando caminhos afetivo-racionais para este se conectar com seus próprios referenciais (Juguero, 2023).  Considera que a dramaturgia radical é para qualquer público e a utiliza em todos os seus trabalhos, usando como exemplo a peça \"Cavalo de Santo\" (Juguero, 2023).  A autora também destaca a importância da consciência da dialeticidade presente no encontro dialógico artístico como aspecto essencial da filosofia radical na criação de dramaturgias (Juguero, 2019, p. 47).\\n',\n",
       "  'Viviane Juguero é uma pesquisadora que, em sua tese  *Dramaturgias radicais: poéticas matrísticas para uma arte dialógica* (2019), discute a relação entre a criação dramatúrgica e sua recepção,  abordando a questão da autoria e sua intencionalidade, dialogando com o pensamento de Mikhail Bakhtin.  (Juguero, 2019, p. 78-79; Juguero, 2019, p. 43).  Ela também utiliza a obra *Cavalo de Santo* para analisar a identidade brasileira e a colonialidade brasileira.\\n',\n",
       "  'Viviane Juguero foi uma dramaturga, professora, atriz, poeta e produtora que se doutorou em Artes Cênicas pela UFRGS, defendendo uma tese sobre a dramaturgia como composição artístico-discursiva (Juguero, 2019, p. 4).  Sua trajetória é transfronteiriça, integrando o Grupo de Dramaturgas Femininas “As DramaturgAs”, o corpo docente do Nordic Black Theatre na Noruega e o Conselho Consultivo de Especialistas do CAST na Nova Zelândia (p. 190). Ela também coordenou o Centro Brasileiro de Teatro para a Infância e Juventude (CBTIJ) no Rio Grande do Sul e integrou redes nacionais e internacionais, como a ASSITEJ (p. 191).  Seu trabalho se destacou pela produção intelectual e artística (artigos, livros, dramaturgias, poesias, músicas e audiovisual) que ganhou relevância nacional e internacional, com obras como \"Cavalo de Santo\" (p. 191).  Sua pesquisa de pós-doutorado na Universidade de Stavanger, Noruega, focou em \"Teatricidades Pluriperceptivas e Multiculturais para Diversas Primeiras Infâncias\" (p. 190).  Seu trabalho é influenciado pelo pensamento de Paulo Freire e aborda a dramaturgia negra e o trabalho teatral e pedagógico voltado para a criança (p. 190-191).\\n',\n",
       "  'Viviane Juguero foi uma dramaturga, professora, atriz, poeta e produtora que se doutorou em Artes Cênicas pela UFRGS, com tese defendida em 2017 (p. 172).  Sua trajetória é descrita como transfronteiriça, integrando o Grupo de Dramaturgas Femininas “As DramaturgAs”, o corpo docente do Nordic Black Theatre na Noruega e o Conselho Consultivo de Especialistas do CAST – Center for the Arts and Social Transformation da Universidade de Auckland, na Nova Zelândia (p. 190).  Sua produção intelectual e artística inclui artigos, livros, dramaturgias, poesias, músicas e audiovisual, tendo ganhado relevância nacional e internacional (p. 191).  Ela também coordenou o Centro Brasileiro de Teatro para a Infância e Juventude (CBTIJ) no Rio Grande do Sul e integrou redes nacionais e internacionais, como a ASSITEJ (p. 190-191).  Seu trabalho é influenciado pelo pensamento de Paulo Freire (p. 190) e inclui pesquisa sobre dramaturgia e teatro para a infância, com foco em \"Teatricidades Pluriperceptivas e Multiculturais para Diversas Primeiras Infâncias\" em seu pós-doutorado na Universidade de Stavanger, Noruega (p. 190).  Sua produção dramatúrgica inclui a peça *Cavalo de Santo*, presente na coletânea *Dramaturgia Negra* (2018) (p. 191).  Ela também participou das Oficinas Populares de Teatro do Projeto de Descentralização da Cultura em 1994 (p. 190).\\n'],\n",
       " 'uris': ['tag:stardog:api:dramaturgias_negras_do_pampa__uma_analise_decolonial__page_190',\n",
       "  'tag:stardog:api:dramaturgias_negras_do_pampa__uma_analise_decolonial__page_250',\n",
       "  'tag:stardog:api:dramaturgias_negras_do_pampa__uma_analise_decolonial__page_237',\n",
       "  'tag:stardog:api:dramaturgias_negras_do_pampa__uma_analise_decolonial__page_191',\n",
       "  'tag:stardog:api:somos_aqueles_por_quem_esperamos__reexistencia_dos_povos_originarios_em_diferentes_materialidades']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_perguntas_respostas['Quem foi Viviane Juguero?']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

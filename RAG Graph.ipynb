{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8adac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35496e05",
   "metadata": {},
   "source": [
    "Conectando ao Neo4j e aos Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e744efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a3bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando o modelo de Embedding\n",
    "\n",
    "#client_small = AzureOpenAI(\n",
    "#  api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "#  azure_endpoint = os.getenv(\"EMBEDDING_SMALL_ENDPOINT\"),\n",
    "#  api_version = os.getenv(\"API_VERSION\"))\n",
    "\n",
    "client_large = AzureOpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "  azure_endpoint = os.getenv(\"EMBEDDING_LARGE_ENDPOINT\"),\n",
    "  api_version = os.getenv(\"API_VERSION\"))\n",
    "\n",
    "\n",
    "# The function receives a sencence and returns the embedding (1D numpy array)\n",
    "def get_embeddings_openAI(text):\n",
    "    #model = \"text-embedding-3-small\"\n",
    "    #embedding_small = client_small.embeddings.create(input = text, model=model)\n",
    "    #return embedding_small.data\n",
    "    model = \"text-embedding-3-large\"\n",
    "    embedding_large = client_large.embeddings.create(input = text, model=model)\n",
    "    return embedding_large.data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f43cc",
   "metadata": {},
   "source": [
    "### GRAPH RAG  \n",
    "  \n",
    "Definir uma funcao que: 1) recebe um texto; 2)usa o modelo de embedding para transformar o texto em um vetor: 3) Usa o vetor para buscar outros textos do grafo (usando o índice de vetores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4442e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def busca_grafo_vetor(query_text):\n",
    "#    query_embedding = get_embeddings_openAI(query_text)[0].embedding\n",
    "\n",
    "    # Buscando no índice de vetores \n",
    "#    results = graph.query(\"\"\"\n",
    "#        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\")\n",
    "#        YIELD node, score\n",
    "#        RETURN node.uri, node.title, node.abstract, node.description, score \n",
    "#        LIMIT 15 \n",
    "#        \"\"\")\n",
    "    \n",
    "#    return (results)\n",
    "\n",
    "#MATCH (node)-[:author]-(author)\n",
    "#RETURN node.uri, node.title, node.abstract, node.created, author.label, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d270d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def busca_grafo_fulltext(query_text):\n",
    "\n",
    "#    results = graph.query(\"\"\"\n",
    "#        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "#        YIELD node, score\n",
    "#        RETURN node.uri, node.title, node.abstract, node.description, score  \n",
    "#        LIMIT 15 \n",
    "#        \"\"\")\n",
    "#    return (results)\n",
    "\n",
    "#        MATCH (node)-[:author]-(author)\n",
    "#        RETURN node.uri, node.title, node.abstract, node.created , author.label, score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04257315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_vetor(query_text):\n",
    "    query_embedding = get_embeddings_openAI(query_text)[0].embedding\n",
    "\n",
    "    # Buscando no índice de vetores \n",
    "    results = graph.query(\"\"\"\n",
    "        CALL{\n",
    "        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\") \n",
    "        YIELD node, score\n",
    "\n",
    "        MATCH (node:Thesis)\n",
    "        MATCH (node)-[:author]-(author)\n",
    "        RETURN score, node.created AS created, node.uri AS node_uri, node.title AS title, node.abstract AS abstract, node.description AS description, author.label AS author \n",
    "        LIMIT 15 \n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        CALL db.index.vector.queryNodes('Thesis_Embeddings', 15, \"\"\" + str(query_embedding) + \"\"\") \n",
    "        YIELD node, score\n",
    "        MATCH (node:Excerpt)<-[:BFO_0000051]-(t:Thesis)\n",
    "        MATCH (t)-[:author]-(author)\n",
    "        RETURN score, t.created AS created, node.uri AS node_uri, t.title AS title, Null AS abstract, node.description AS description,  author.label AS author\n",
    "        LIMIT 15}\n",
    "\n",
    "        RETURN score, created, node_uri, title, abstract, description, author\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 15\n",
    "        \"\"\")\n",
    "    \n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f731737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_fulltext(query_text):\n",
    "\n",
    "    results = graph.query(\"\"\"\n",
    "        CALL{\n",
    "        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "        YIELD node, score\n",
    "\n",
    "        MATCH (node:Thesis)\n",
    "        MATCH (node)-[:author]-(author)\n",
    "        RETURN score, node.created AS created, node.uri AS node_uri, node.title AS title, node.abstract AS abstract, node.description AS description, author.label AS author \n",
    "        LIMIT 15 \n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        CALL db.index.fulltext.queryNodes(\"Thesis_fulltext\", '\"\"\" + query_text + \"\"\"') \n",
    "        YIELD node, score\n",
    "        MATCH (node:Excerpt)<-[:BFO_0000051]-(t:Thesis)\n",
    "        MATCH (t)-[:author]-(author)\n",
    "        RETURN score, t.created AS created, node.uri AS node_uri, t.title AS title, Null AS abstract, node.description AS description,  author.label AS author\n",
    "        LIMIT 15}\n",
    "\n",
    "        RETURN score, created, node_uri, title, abstract, description, author\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 15\n",
    "        \"\"\")\n",
    "    return (results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7098e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciprocal Rank Fusion (RRF)\n",
    "def RFF(rank1, rank2, w_rank1=1.0, w_rank2=1.0):\n",
    "    k = 60\n",
    "    score = {}\n",
    "    title_text = {}\n",
    "\n",
    "    for p in range(len(rank1)):\n",
    "        uri = rank1[p]['node_uri']\n",
    "        score[uri] = 1/(p+1+k)\n",
    "        title_text[uri] = {'title': rank1[p]['title'],#['node.title'], \n",
    "                           'text': str(rank1[p]['abstract']) + \" \" + str(rank1[p]['description']),#['node.abstract'], \n",
    "                           'author': rank1[p]['author'],#['author.label'],\n",
    "                           'created': rank1[p]['created'],#['node.created']}\n",
    "                           'uri': uri}\n",
    "\n",
    "    for p in range(len(rank2)):\n",
    "        uri = rank2[p]['node_uri']\n",
    "        if uri not in score:\n",
    "            score[uri] = 1/(p+1+k)\n",
    "            title_text[uri] = {'title': rank1[p]['title'],#['node.title'], \n",
    "                            'text': str(rank1[p]['abstract']) + \" \" + str(rank1[p]['description']),#['node.abstract'], \n",
    "                            'author': rank1[p]['author'],#['author.label'],\n",
    "                            'created': rank1[p]['created'],#['node.created']}\n",
    "                            'uri': uri}\n",
    "        else:\n",
    "            score[uri] = (score[uri]) * w_rank1 + (1/(p+1+k)) * w_rank2\n",
    "\n",
    "\n",
    "    uri_list = []\n",
    "    score_list = []\n",
    "    sorted_title_text = []\n",
    "    for i in sorted(score, key = score.get, reverse=True):\n",
    "        uri_list.append(i)\n",
    "        score_list.append(score[i])\n",
    "        sorted_title_text.append(title_text[i])\n",
    "    return (sorted_title_text, score_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c543a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_grafo_hibrida(query_text):\n",
    "    results_vector = busca_grafo_vetor(query_text)\n",
    "    results_text = busca_grafo_fulltext(query_text)\n",
    "    return RFF(results_vector, results_text, w_rank1=1.0, w_rank2=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de7f36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_respostas(query_text):\n",
    "\n",
    "    results = busca_grafo_hibrida(query_text)\n",
    "\n",
    "    #endpoint = os.getenv(\"GPT35_ENDPOINT\")  \n",
    "    #deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-35-turbo\")\n",
    "    endpoint = os.getenv(\"GPT4_ENDPOINT\")  \n",
    "    deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4\") \n",
    "    subscription_key = os.getenv(\"OPENAI_API_KEY\")   \n",
    "        \n",
    "    \n",
    "            \n",
    "    client_chat = AzureOpenAI(  \n",
    "            azure_endpoint=endpoint,  \n",
    "            api_key=subscription_key,  \n",
    "            api_version=\"2024-05-01-preview\",  \n",
    "        )  \n",
    "\n",
    "    respostas = []\n",
    "    uris = []\n",
    "\n",
    "    for n in range(5):\n",
    "        text = results[0][n]['text']\n",
    "        titulo = results[0][n]['title']\n",
    "        autor = results[0][n]['author']\n",
    "        created = results[0][n]['created']\n",
    "        uri = results[0][n]['uri']\n",
    "        citation = autor + \". \" + titulo + \". \" + created + \".\"\n",
    "\n",
    "        completion = client_chat.chat.completions.create(  \n",
    "        model=deployment,  \n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a text delimited by triple quotes and a question. Your task is to answer the question using only the provided text and to cite the passage(s) of the document used to answer the question. If the text does not contain the information needed to answer this question then simply write: 'Informação Insuficiente.' If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages (\" + citation + \"). Your answers must be written in Brazilian Portuguese.\"\n",
    "            #\"content\": \"Use the provided text delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write {NONE}\"\n",
    "            #\"content\": \"INSTRUCTIONS:\\nAnswer the users QUESTION using the CONTEXT text below.\\nKeep your answer ground in the facts of the CONTEX.\\n Very important: If the CONTEXT doesn’t contain the facts to answer the QUESTION return {NONE}.\\n\\nCONTEXT:\\n\" + text\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": '\"\"\"' + text + '\"\"\" \"QUESTION: \"' + query_text\n",
    "            }\n",
    "            ],  \n",
    "                #past_messages=10,  \n",
    "                max_tokens=800,  \n",
    "                temperature=1.0,  \n",
    "                top_p=0.95,  \n",
    "                frequency_penalty=0,  \n",
    "                presence_penalty=0,  \n",
    "                stop=None,  \n",
    "                stream=False  \n",
    "            )  \n",
    "\n",
    "        #resposta = completion.to_json()\n",
    "        resposta = completion.to_dict()['choices'][0]['message']['content']\n",
    "        respostas.append(resposta)\n",
    "        uris.append(uri)\n",
    "        \n",
    "    return respostas, uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4017d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_respostas(query_text, respostas):\n",
    "\n",
    "    fontes = ''\n",
    "    for r in respostas:\n",
    "        fontes = fontes + '\\n' + r\n",
    "\n",
    "    #endpoint = os.getenv(\"GPT35_ENDPOINT\")  \n",
    "    #deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-35-turbo\")\n",
    "    endpoint = os.getenv(\"GPT4_ENDPOINT\")  \n",
    "    deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4\") \n",
    "    subscription_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "        \n",
    "    \n",
    "            \n",
    "    client_chat = AzureOpenAI(  \n",
    "            azure_endpoint=endpoint,  \n",
    "            api_key=subscription_key,  \n",
    "            api_version=\"2024-05-01-preview\",  \n",
    "        )  \n",
    "\n",
    "    completion = client_chat.chat.completions.create(  \n",
    "    model=deployment,  \n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with one question and several answers for the question delimited by triple quotes. Your task is to summarize the provided answers. If all answers were 'Informação Insuficiente', you must also return the text 'Informação Insuficiente.' You must maintain the citations and references for the original documents using the same format. Include facts present in the provided answers that directly address the provided question in the final answer. Your answers must be written in Brazilian Portuguese.\"\n",
    "        #\"content\": \"INSTRUCTIONS:\\n Sumarize os textos do contexto, referenciando as fontes ao final em uma bibliografia. Não mencione nem use como fonte os textos que não falem sobre \" + personagem + \".\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": '\"\"\"' + fontes + '\"\"\"' + 'QUESTION: ' + query_text\n",
    "        }\n",
    "        ],  \n",
    "            #past_messages=10,  \n",
    "            max_tokens=800,  \n",
    "            temperature=1.0,  \n",
    "            top_p=0.95,  \n",
    "            frequency_penalty=0,  \n",
    "            presence_penalty=0,  \n",
    "            stop=None,  \n",
    "            stream=False  \n",
    "        )  \n",
    "\n",
    "    #resposta = completion.to_json()\n",
    "    summ_resposta = completion.to_dict()['choices'][0]['message']['content']\n",
    "        \n",
    "    return summ_resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69d8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de perguntas\n",
    "\n",
    "def perguntas(personagem):\n",
    "    perg = []\n",
    "    #perg.append('Qual o nome completo de ' + personagem + '?')\n",
    "    #perg.append('Onde nasceu ' + personagem + '?')\n",
    "    #perg.append('Qual a data de nascimento de ' + personagem + '?')\n",
    "    #perg.append('Onde morreu ' + personagem + '?')\n",
    "    #perg.append('Qual a data de morte de ' + personagem + '?')\n",
    "    perg.append('Quem foi ' + personagem + '?')\n",
    "    perg.append('Quais os principais feitos de ' + personagem + '?')\n",
    "    perg.append('Quais os principais cargos, funções, ou emprogos de ' + personagem + '?')\n",
    "    \n",
    "    return perg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e9a60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perguntas_e_respostas(personagem):\n",
    "\n",
    "    perg_resp = {}\n",
    "\n",
    "    pergs = perguntas(personagem)\n",
    "\n",
    "    for perg in pergs:\n",
    "        respostas, uris = gen_respostas(perg)\n",
    "        resposta_final = summarize_respostas(perg, respostas)\n",
    "        perg_resp[perg] = {\"Resumo\": resposta_final, \"Respostas\": respostas, \"uris\": uris} \n",
    "\n",
    "    return perg_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93fa2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "personagem = 'Beatriz Nascimento' #'Viviane Juguero'\n",
    "dic_perguntas_respostas = perguntas_e_respostas(personagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25cd02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Quem foi Beatriz Nascimento?', 'Quais os principais feitos de Beatriz Nascimento?', 'Quais os principais cargos, funções, ou emprogos de Beatriz Nascimento?'])\n"
     ]
    }
   ],
   "source": [
    "print(dic_perguntas_respostas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "243046fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Resumo': 'Beatriz Nascimento é renomada por sua contribuição significativa ao estudo da identidade negra e do papel dos quilombos no Brasil. Ela enfatiza a importância do registro visual na recuperação da identidade negra, apontando a experiência da perda da imagem e a necessidade de visibilidade para a afirmação dessa identidade (NASCIMENTO, 2018, p. 330). Além disso, Nascimento amplia o conceito de quilombo, não somente como um território geográfico, mas também associando-o ao corpo e à ideologia. Esta nova noção de quilombismo serve de inspiração para mobilizações e lutas sociais (NASCIMENTO, 2018, p. 278, 334). Ela também explora as relações entre os quilombos históricos e outras formas de expressão cultural negra contemporânea, incluindo favelas, escolas de samba, o Movimento Negro, manifestações artísticas, e expressões de fé e devoção (NASCIMENTO, 2018, p. 278).',\n",
       " 'Respostas': ['Informação Insuficiente.',\n",
       "  'Informação Insuficiente.',\n",
       "  'Informação Insuficiente.',\n",
       "  'Beatriz Nascimento é destacada por sua pesquisa e abordagem em relação à identidade negra e o papel dos quilombos no Brasil. Ela identifica a importância do registro visual na recuperação da identidade negra, destacando a experiência da perda da imagem e a necessidade de visibilidade para a afirmação dessa identidade (NASCIMENTO, 2018, p. 330). Nascimento estende o conceito de quilombo para além de um território geográfico, associando-o também ao corpo e a ideologia, propondo uma noção de quilombismo que inspira mobilizações e lutas sociais (NASCIMENTO, 2018, p. 278, 334). Ademais, ela explora as conexões entre os quilombos históricos e outras formas de expressão cultural negra contemporânea como favelas, escolas de samba, Movimento Negro, manifestações artísticas, e expressões de fé e devoção (NASCIMENTO, 2018, p. 278).',\n",
       "  'Informação Insuficiente.'],\n",
       " 'uris': ['tag:stardog:api:o_pensamento_de_beatriz_nascimento__analise_do_longametragem_ori_1989',\n",
       "  'tag:stardog:api:palavras_sobre_uma_historiadora_transatlantica_estudo_da_trajetoria_intelectual_de_maria_beatriz_nascimento',\n",
       "  'tag:stardog:api:os_valores_civilizatorios_afrobrasileiros_na_erer_uma_proposta_de_ensino_de_historia_por_meio_do_comunitarismo_de_beatriz_nascimento_19701990',\n",
       "  'tag:stardog:api:a_rememoracao_nas_imagens_dos_quilombos__page_34',\n",
       "  'tag:stardog:api:e_por_falar_em_povos_indigenas_quais_narrativas_contam_em_praticas_pedagogicas']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_perguntas_respostas['Quais os principais feitos de Beatriz Nascimento?']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

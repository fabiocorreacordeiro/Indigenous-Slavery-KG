{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install openai==1.13.3\n",
    "%pip install -qU langchain-openai\n",
    "%pip install neo4j\n",
    "%pip install langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28e35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f889c1e8-d4c5-43d6-9879-37707bf549e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI variables\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT =os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe60bf-739b-4ea4-a9fd-3f0f202b0aa3",
   "metadata": {},
   "source": [
    "### Connecting to the graph and making a Cypher query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db500e9a-2310-498f-a397-f2b54a584f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67dbfe49-e1bd-4e34-a79c-34e5cef53c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quering the graph unsing Cypher\n",
    "result = graph.query(\"\"\"\n",
    "MATCH (t:Thesis)-[:advisor]-(a:Person) MATCH (a {label: 'Silva, Jamile Borges da'}) RETURN t.title, t.abstract;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b77fff-07ce-4032-9b4e-3248ab751d75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'t.title': 'A implementação das leis 10.639/2003 e a 11.645/2008 na Rede de Ensino de Lapão: uma proposta de intervenção curricular intercultural',\n",
       "  't.abstract': 'Este Projeto de Intervenção estuda a implementação das Leis 10.639/2003 e 11.645/2008 na Rede Municipal de Ensino de Lapão-Ba, na perspectiva do currículo intercultural e representa uma continuidade dos estudos e pesquisas que realizo na área de educação e diversidade. Teve como objetivo de pesquisa, a investigação de duas situações principais: primeiro, a análise de como o trabalho pedagógico, realizado no ambiente escolar, com relação à temática pode ser considerado processo de efetivação da legislação em estudo. Nessa abordagem a escola é vista como campo propício para afirmação de uma construção identitária reconhecendo que nossa identidade é também social e culturalmente construída. Segundo, investigar como o município de Lapão está organizado em termos legais e com relação à política de formação continuada para professores, especificamente no trato com as questões etnicorraciais. Os estudos que norteiam a pesquisa estão fundamentados no tripé, identidade, currículo e interculturalidade. A metodologia utilizada foi de caráter qualitativo, de inspiração etnográfica e utilizei os dispositivos metodológicos de: observação participante, entrevistas individuais semiestruturadas, oficina metodológica e análise documental. O processo de investigação possibilitou identificar que ao longo da década observada (2006-2016), o Sistema Municipal de Ensino de Lapão já possui um aparato que normatizam políticas públicas que colocam em prática as ações das referidas leis. Porém, as propostas curriculares das escolas devem promover tempos educativos, nos quais os professores que lecionam principalmente as Disciplinas de História, Arte e Língua Portuguesa possam contemplar nos planejamentos, ações pedagógicas que abordem a temática de forma natural e não como algo esporádico, como ocorre de fato. A proposta da interculturalidade como elemento norteador do currículo de Lapão, pode contribuir para galgar resultados positivos no que se refere à educação que valoriza a diversidade local existente. E neste ínterim propõe-se esta intervenção.'},\n",
       " {'t.title': '“Entre a rua e o ciberespaço”: ciberracismo nas redes sociais brasileiras',\n",
       "  't.abstract': 'A grande questão que suscito nesta tese é pensar as práticas de ciberracismo direcionadas à população negra no Facebook, a fim de problematizar o fenômeno das relações raciais a partir desse espaço, que se estabelece, no presente, como a principal rede social no Brasil com maior número de práticas e de denúncia de ciberracismo, conforme destaca a Safernet (2020). Diante do exposto, a tese tem como objetivo analisar as práticas de ciberracismo e ciberantirracismo no Facebook, observando como esse fenômeno pode facilitar o entendimento da produção do racismo no mundo digital que se apresenta mediante suas formas de expressões e de denúncia. Os caminhos percorridos amparam-se na etnografia e se confluem com a metodologia parafuso para potencializar as estratégias de análise, ao ampliar os caminhos metodológicos que se constituem, como uma proposta antirracista, que aplico e desenvolvo, conceitualmente, ao longo da tese e pretendo pensar os fenômenos que permeiam as relações raciais que potencializam os saberes existentes das comunidades negras. Assim, busquei as dinâmicas do racismo na literatura teórica e produzidas nos meios de comunicação, analisando esse fenômeno em diferentes mídias com base na ideia do giro que oportuniza os diferentes discursos, posicionamentos e reflexões tecidas acerca da sociedade brasileira. No segundo momento, executei uma pesquisa documental por meio do levantamento de boletins sobre denúncias das práticas de racismo nas redes sociais, com o intuito de compreender as diferentes maneiras em que o ciberracismo ocorre, além de trazer à tona outros documentos como os jornais e as revistas on-line a fim de catalogar os noticiários relacionados às práticas em foco. No terceiro momento, realizei a pesquisa de campo no Facebook, logo após a análise dos dados obtidos. Por fim, observei os desfeches do ciberracismo, e suas implicações na rede social Facebook, partindo do impacto de sua disseminação e efetivação que afeta os atores sociais envolvidos em contextos locais e globais.'},\n",
       " {'t.title': 'Método Colhetear: a heteroidentificação como princípio educativo',\n",
       "  't.abstract': 'Esta dissertação trata de proposta interventiva em dimensão multirreferencial, de abordagem qualitativa do tipo pesquisa-ação. Se dedica ao território da heteroidentificação para além do controle na implementação de política pública, buscando compreender o potencial educativo do procedimento de verificação da autodeclaração e suas contribuições para o fortalecimento da Educação para as relações Étnico-raciais, no Instituto Federal do Espírito Santo. Para prosseguir com reflexões acerca das relações raciais no Brasil, a pesquisa dialoga com conceitos de raça, racismo, identidade e fenótipo e relaciona o uso que as ciências humanas fazem desses conceitos para nos auxiliar na compreensão de movimentos socioculturais da atualidade. Propõe como objetivo geral a construção de uma proposta de heteroidentificação que atue de forma educativa e apresenta um método próprio e apropriado para alcançar o objetivo proposto: o Método Colhetear – Colaborações da Heteroidentificação para a Educação Antirracista. Criando significações outras, o método integra o sentido de colheita (resultado de um cultivo) com o significado de tear (entrelaçamento de fios entre si ou transformação mediante trabalho intencional), sendo compreendido como um método adequado para cultivar e colher ações (individuais, coletivas e institucionais) que transformam a estrutura das relações raciais através das tecituras da educação, podendo se desdobrar como instrumento - forma - ou como ação geradora – motivo; ora conhecimento - conteúdo - ora produção/partilha - proposta interventiva. O novo método se concretiza por meio de uma metodologia única materializada no que se denomina de “Instalação Colhetear”, um instrumento de coleta de dados capaz de diagnosticar o nível de leitura fenotípica e a compreensão sobre a heteroidentificação dos membros de comissões de heteroidentificação. O Método Colhetear está estruturado em cinco dimensões e, inspirado nas estruturas da pesquisa-ação, se ocupa em diagnosticar o território da pesquisa, planejar, construir, avaliar e propor a implementação de uma proposta interventiva colaborativa. O trabalho dialogado e participativo é proporcionado por um método inovador e desafiador, que reconhece a ERER como proposta curricular inicialmente pavimentada no IFES e a heteroidentificação como ferramenta educativa que traz grandes impactos para o sentirpensarfazerexperenciar de cada dia, sendo capaz de fortalecer a ERER.'},\n",
       " {'t.title': 'Necroeducação: Racismo, juventude e enfrentamento na escola pública em Salvador',\n",
       "  't.abstract': 'Na presente pesquisa toma-se por base a teoria da Educação Antirracista para analisar as práticas dos professores sobre a política do enfrentamento ao racismo direcionado à juventude negra em escolas públicas de Salvador; além disso, observam-se as ferramentas pedagógicas que tornam possível que a necroeducação seja acionada como mecanismo de aniquilamento dos sujeitos negros. Assim, verifica-se como a escola tem traçado estratégias para o combate ao racismo e trabalhado a questão da negritude, temos como objetivo compreender as práticas docentes quanto à política de enfrentamento ao racismo, no âmbito escolar. Nesse sentido, a pesquisa suscita a seguinte questão, se as práticas pedagógicas presentes na escola pública em Salvador favorecem a emancipação/autonomia do (a) jovem negro (a). Busca também compreender temáticas relacionadas ao empoderamento, à exclusão e a discriminação. A metodologia aplicada foi a qualitativa exploratória, na perspectiva dialética, visto que ela favorece a reflexão sobre a prática educativa buscando causas e consequências do fenômeno descrito, através da discussão e argumentação dialogada, podendo proporcionar a identificação nessa construção pedagógica, de elementos de uma Educação Equitária Antirracista ou uma educação eurocêntrica, aqui denominada de prática da Necroeducação, e como elas contribuem para a emancipação e construção do ser jovem negro. A pesquisa tem como objeto a análise das práticas de docentes que trabalham com jovens negros na faixa etária entre 15 a 29 anos matriculados no ensino médio e na EJA - educação de jovens e adultos em escolas públicas de Salvador. O estudo indica uma contribuição da educação antirracista para favorecer o respeito à diversidade e a valorização da história e cultura africana e afro-brasileira na educação básica. Os dados foram colhidos por um questionário/entrevista através do google forms e quando analisados demonstraram entre outros resultados; a ratificação da existência do racismo no ambiente escolar; o fortalecimento do racismo através de práticas pedagógicas eurocêntricas; que o enfrentamento ao racismo não compõe o fazer pedagógico das escolas públicas pesquisadas; que existe uma relação entre os fatores de exclusão dos jovens negros (as) e as práticas educacionais presentes na escola pública em Salvador; e que a prática da educação antirracista pode promover a autonomia do jovem negro (a).'},\n",
       " {'t.title': 'Uma intervenção formativa para as relações étnico-raciais no curso de Licenciatura em Pedagogia do IFES Campus Itapina',\n",
       "  't.abstract': 'Esse projeto de intervenção buscou analisar a presença das questões étnico-raciais na formação dos discentes do curso de Licenciatura em Pedagogia do Ifes Campus Itapina. O objetivo foi elaborar uma proposta de intervenção em Educação para as Relações Étnico-Raciais, visando enriquecer a formação dos estudantes do curso. A pesquisa foi conduzida com alunos matriculados nos períodos 2º, 4º, 6º e 8º do ano letivo de 2022. A abordagem metodológica adotada foi qualitativa, embasada nas diretrizes da pesquisa-ação. No embasamento teórico, dialogamos com Nilma Lino Gomes, Petrônio Domingues, Tomaz Tadeu da Silva, Paulo Freire entre outros. Além disso, foram examinadas as legislações pertinentes que abordam as questões étnico-raciais na educação, as ações afirmativas, o currículo e a Base Nacional Comum Curricular. No tocante à metodologia, foi realizado um levantamento bibliográfico detalhado e uma análise de documentos internos. A coleta de dados se deu por meio da aplicação de um questionário online, composto por perguntas abertas e fechadas. Os resultados da pesquisa evidenciaram a presença das questões étnico-raciais na matriz curricular, por meio dos componentes curriculares que abordam conteúdos propícios para a discussão sobre Educação para as Relações Étnico-Raciais (ERER), preparando assim os futuros docentes com conhecimentos relevantes para sua atuação profissional. Adicionalmente, foi constatado que as ações promovidas pelo Núcleo de Estudos Afro-Brasileiros e Indígenas (NEABI) também desempenham um papel significativo na formação dos discentes. A Política de Educação para as Relações Étnico-Raciais do Ifes se mostrou como um instrumento essencial para a efetivação das Leis nº 10.639/2003 e nº 11.645/2008. Como proposta interventiva, propõe-se uma ação complementar ao ensino por meio da realização de um seminário. Esse seminário abordará temas que necessitam de revisão e/ou aprofundamento, como racismo e discriminação racial, legislação relativa à ERER, intolerância religiosa e abordagens curriculares alinhadas à perspectiva da ERER. Dessa forma, a proposta de intervenção visa ampliar a formação dos discentes do curso de Licenciatura em Pedagogia, capacitando-os para abordar de maneira sensível e eficaz as questões étnico-raciais.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633f3aed-66b6-461f-a6a5-6bb0957ca803",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Resource {uri: STRING, label: STRING, givenname: STRING, family_name: STRING, acronym: STRING, scopeNote: STRING, repository: STRING, created: STRING, abstract: STRING, title: STRING, identifier: STRING}\n",
      "_GraphConfig {_dataTypePropertyLabel: STRING, _subPropertyOfRel: STRING, _classNamePropName: STRING, _handleVocabUris: INTEGER, _applyNeo4jNaming: BOOLEAN, _relNamePropName: STRING, _domainRel: STRING, _keepLangTag: BOOLEAN, _keepCustomDataTypes: BOOLEAN, _handleMultival: INTEGER, _objectPropertyLabel: STRING, _rangeRel: STRING, _classLabel: STRING, _handleRDFTypes: INTEGER, _subClassOfRel: STRING}\n",
      "Program {uri: STRING, label: STRING}\n",
      "NamedIndividual {family_name: STRING, label: STRING, givenname: STRING, uri: STRING, acronym: STRING, created: STRING, abstract: STRING, title: STRING, repository: STRING, identifier: STRING}\n",
      "Department {label: STRING, uri: STRING}\n",
      "DatatypeProperty {uri: STRING, scopeNote: STRING, isDefinedBy: STRING, term_status: STRING, label: STRING, comment: STRING, note: STRING, example: STRING, historyNote: STRING, deprecated: BOOLEAN}\n",
      "Person {label: STRING, family_name: STRING, uri: STRING, givenname: STRING}\n",
      "AnnotationProperty {uri: STRING, scopeNote: STRING}\n",
      "University {label: STRING, acronym: STRING, uri: STRING}\n",
      "ObjectProperty {uri: STRING, note: STRING, scopeNote: STRING, comment: STRING, label: STRING, isDefinedBy: STRING, term_status: STRING, editorialNote: STRING, example: STRING, seeAlso: STRING}\n",
      "Subject {label: STRING, uri: STRING}\n",
      "Class {label: STRING, uri: STRING, note: STRING, comment: STRING, isDefinedBy: STRING, term_status: STRING, example: STRING, scopeNote: STRING}\n",
      "ThesisDegree {uri: STRING, label: STRING}\n",
      "Thing {label: STRING, comment: STRING, term_status: STRING, uri: STRING, seeAlso: STRING, name: STRING, isDefinedBy: STRING}\n",
      "Thesis {title: STRING, repository: STRING, identifier: STRING, created: STRING, abstract: STRING, uri: STRING}\n",
      "CNPQ {label: STRING, uri: STRING}\n",
      "Ontology {uri: STRING, description: STRING}\n",
      "TransitiveProperty {label: STRING, note: STRING, comment: STRING, uri: STRING, example: STRING, seeAlso: STRING}\n",
      "Datatype {uri: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Resource)-[:BFO_0000050]->(:Resource)\n",
      "(:Resource)-[:BFO_0000050]->(:NamedIndividual)\n",
      "(:Resource)-[:BFO_0000050]->(:University)\n",
      "(:Resource)-[:publisher]->(:Resource)\n",
      "(:Resource)-[:publisher]->(:Program)\n",
      "(:Resource)-[:publisher]->(:NamedIndividual)\n",
      "(:Resource)-[:publisher]->(:University)\n",
      "(:Resource)-[:publisher]->(:Department)\n",
      "(:Resource)-[:subject]->(:Resource)\n",
      "(:Resource)-[:subject]->(:NamedIndividual)\n",
      "(:Resource)-[:subject]->(:Subject)\n",
      "(:Resource)-[:subject]->(:CNPQ)\n",
      "(:Resource)-[:opponent]->(:Resource)\n",
      "(:Resource)-[:opponent]->(:NamedIndividual)\n",
      "(:Resource)-[:opponent]->(:Person)\n",
      "(:Resource)-[:opponent]->(:Subject)\n",
      "(:Resource)-[:author]->(:Resource)\n",
      "(:Resource)-[:author]->(:NamedIndividual)\n",
      "(:Resource)-[:author]->(:Person)\n",
      "(:Resource)-[:degree]->(:Resource)\n",
      "(:Resource)-[:degree]->(:NamedIndividual)\n",
      "(:Resource)-[:degree]->(:ThesisDegree)\n",
      "(:Resource)-[:advisor]->(:Resource)\n",
      "(:Resource)-[:advisor]->(:NamedIndividual)\n",
      "(:Resource)-[:advisor]->(:Person)\n",
      "(:Program)-[:BFO_0000050]->(:Resource)\n",
      "(:Program)-[:BFO_0000050]->(:NamedIndividual)\n",
      "(:Program)-[:BFO_0000050]->(:University)\n",
      "(:NamedIndividual)-[:BFO_0000050]->(:Resource)\n",
      "(:NamedIndividual)-[:BFO_0000050]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:BFO_0000050]->(:University)\n",
      "(:NamedIndividual)-[:subject]->(:Resource)\n",
      "(:NamedIndividual)-[:subject]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:subject]->(:Subject)\n",
      "(:NamedIndividual)-[:subject]->(:CNPQ)\n",
      "(:NamedIndividual)-[:author]->(:Resource)\n",
      "(:NamedIndividual)-[:author]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:author]->(:Person)\n",
      "(:NamedIndividual)-[:degree]->(:Resource)\n",
      "(:NamedIndividual)-[:degree]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:degree]->(:ThesisDegree)\n",
      "(:NamedIndividual)-[:publisher]->(:Resource)\n",
      "(:NamedIndividual)-[:publisher]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:publisher]->(:University)\n",
      "(:NamedIndividual)-[:publisher]->(:Program)\n",
      "(:NamedIndividual)-[:publisher]->(:Department)\n",
      "(:NamedIndividual)-[:BFO_0000051]->(:Resource)\n",
      "(:NamedIndividual)-[:BFO_0000051]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:BFO_0000051]->(:CNPQ)\n",
      "(:NamedIndividual)-[:BFO_0000051]->(:Subject)\n",
      "(:NamedIndividual)-[:opponent]->(:Resource)\n",
      "(:NamedIndividual)-[:opponent]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:opponent]->(:Person)\n",
      "(:NamedIndividual)-[:advisor]->(:Resource)\n",
      "(:NamedIndividual)-[:advisor]->(:NamedIndividual)\n",
      "(:NamedIndividual)-[:advisor]->(:Person)\n",
      "(:Department)-[:BFO_0000050]->(:Resource)\n",
      "(:Department)-[:BFO_0000050]->(:NamedIndividual)\n",
      "(:Department)-[:BFO_0000050]->(:University)\n",
      "(:DatatypeProperty)-[:equivalentProperty]->(:Resource)\n",
      "(:DatatypeProperty)-[:equivalentProperty]->(:DatatypeProperty)\n",
      "(:DatatypeProperty)-[:subPropertyOf]->(:Resource)\n",
      "(:DatatypeProperty)-[:subPropertyOf]->(:DatatypeProperty)\n",
      "(:DatatypeProperty)-[:range]->(:Resource)\n",
      "(:DatatypeProperty)-[:domain]->(:Resource)\n",
      "(:DatatypeProperty)-[:domain]->(:Class)\n",
      "(:ObjectProperty)-[:range]->(:Resource)\n",
      "(:ObjectProperty)-[:range]->(:Class)\n",
      "(:ObjectProperty)-[:domain]->(:Resource)\n",
      "(:ObjectProperty)-[:domain]->(:Class)\n",
      "(:ObjectProperty)-[:subPropertyOf]->(:Resource)\n",
      "(:ObjectProperty)-[:subPropertyOf]->(:ObjectProperty)\n",
      "(:ObjectProperty)-[:inverseOf]->(:Resource)\n",
      "(:ObjectProperty)-[:inverseOf]->(:ObjectProperty)\n",
      "(:ObjectProperty)-[:inverseOf]->(:TransitiveProperty)\n",
      "(:Subject)-[:BFO_0000051]->(:Resource)\n",
      "(:Subject)-[:BFO_0000051]->(:NamedIndividual)\n",
      "(:Subject)-[:BFO_0000051]->(:Subject)\n",
      "(:Subject)-[:BFO_0000051]->(:CNPQ)\n",
      "(:Class)-[:subClassOf]->(:Resource)\n",
      "(:Class)-[:subClassOf]->(:Class)\n",
      "(:Thesis)-[:author]->(:Resource)\n",
      "(:Thesis)-[:author]->(:NamedIndividual)\n",
      "(:Thesis)-[:author]->(:Person)\n",
      "(:Thesis)-[:subject]->(:Resource)\n",
      "(:Thesis)-[:subject]->(:NamedIndividual)\n",
      "(:Thesis)-[:subject]->(:Subject)\n",
      "(:Thesis)-[:subject]->(:CNPQ)\n",
      "(:Thesis)-[:subject]->(:Person)\n",
      "(:Thesis)-[:publisher]->(:Resource)\n",
      "(:Thesis)-[:publisher]->(:NamedIndividual)\n",
      "(:Thesis)-[:publisher]->(:University)\n",
      "(:Thesis)-[:publisher]->(:Program)\n",
      "(:Thesis)-[:publisher]->(:Department)\n",
      "(:Thesis)-[:opponent]->(:Resource)\n",
      "(:Thesis)-[:opponent]->(:NamedIndividual)\n",
      "(:Thesis)-[:opponent]->(:Person)\n",
      "(:Thesis)-[:degree]->(:Resource)\n",
      "(:Thesis)-[:degree]->(:NamedIndividual)\n",
      "(:Thesis)-[:degree]->(:ThesisDegree)\n",
      "(:Thesis)-[:advisor]->(:Resource)\n",
      "(:Thesis)-[:advisor]->(:NamedIndividual)\n",
      "(:Thesis)-[:advisor]->(:Person)\n",
      "(:CNPQ)-[:BFO_0000051]->(:Resource)\n",
      "(:CNPQ)-[:BFO_0000051]->(:NamedIndividual)\n",
      "(:CNPQ)-[:BFO_0000051]->(:Subject)\n",
      "(:CNPQ)-[:BFO_0000051]->(:CNPQ)\n",
      "(:Ontology)-[:imports]->(:Resource)\n",
      "(:TransitiveProperty)-[:range]->(:Resource)\n",
      "(:TransitiveProperty)-[:range]->(:Class)\n",
      "(:TransitiveProperty)-[:domain]->(:Resource)\n",
      "(:TransitiveProperty)-[:domain]->(:Class)\n",
      "(:TransitiveProperty)-[:inverseOf]->(:Resource)\n",
      "(:TransitiveProperty)-[:inverseOf]->(:ObjectProperty)\n",
      "(:TransitiveProperty)-[:inverseOf]->(:TransitiveProperty)\n"
     ]
    }
   ],
   "source": [
    "# Printing the graph schema\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a85b5-70a3-430e-b201-bc555cf47561",
   "metadata": {},
   "source": [
    "### Using a cypher query to ground the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0beb5c90-653e-413d-b00d-72e0b34ebd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the Azure OpenAI model\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "  api_key=AZURE_OPENAI_API_KEY,  \n",
    "  api_version=OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "\n",
    "chat_llm = AzureChatOpenAI(deployment_name=OPENAI_DEPLOYMENT_NAME,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70f4a73-e7c5-45a2-9dab-97bb79d63d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using information queried from the knowledge graph\n",
    "ground_information =  graph.query(\"\"\" MATCH (t:Thesis)-[:advisor]-(a:Person) MATCH (a {label: 'Silva, Jamile Borges da'}) RETURN t.title, t.abstract;\"\"\")\n",
    "#ground_information =  graph.query(\"\"\" MATCH (n:Wellbore {WellboreName: \"31/2-22 S\"}) RETURN n;\"\"\")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=\"\"\"You are a bot assistant having a conversation about academic thesis and dissertations.\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\", input_variables=[\"chat_history\", \"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fccca2-77cd-436a-b384-2e10b2593c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23892\\767680771.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\", return_messages=True)\n",
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23892\\767680771.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chat_chain = LLMChain(llm=chat_llm, prompt=prompt, memory=memory) #LLMChain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the titles of the thesis in your contex?\n",
      "The titles of the thesis in my context are:\n",
      "\n",
      "1. \"A implementação das leis 10.639/2003 e a 11.645/2008 na Rede de Ensino de Lapão: uma proposta de intervenção curricular intercultural\"\n",
      "2. \"“Entre a rua e o ciberespaço”: ciberracismo nas redes sociais brasileiras\"\n",
      "3. \"Método Colhetear: a heteroidentificação como princípio educativo\"\n",
      "4. \"Necroeducação: Racismo, juventude e enfrentamento na escola pública em Salvador\"\n",
      "5. \"Uma intervenção formativa para as relações étnico-raciais no curso de Licenciatura em Pedagogia do IFES Campus Itapina\"\n",
      "Summarize the abstract in your context. Give the answer in Portuguease.\n",
      "Os títulos das teses em meu contexto são sobre temas relacionados à educação e diversidade, ciberracismo nas redes sociais brasileiras, heteroidentificação como princípio educativo, práticas docentes sobre a política de enfrentamento ao racismo em escolas públicas de Salvador e uma intervenção formativa para as relações étnico-raciais no curso de Licenciatura em Pedagogia do IFES Campus Itapina. Cada tese apresenta uma proposta de intervenção ou análise de práticas pedagógicas para promover a educação antirracista e a valorização da diversidade étnico-racial.\n",
      "quit\n",
      "I'm sorry, I don't understand what you're asking. Can you please provide more information or clarify your question?\n",
      "\n",
      "What is the summary of the abstracts for the academic theses in your context?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\", return_messages=True)\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=prompt, memory=memory) #LLMChain\n",
    "\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    print(question)\n",
    "    response = chat_chain.invoke({\n",
    "        \"context\": ground_information,\n",
    "        \"question\": question\n",
    "        })\n",
    "    print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "655d36ac-aa40-409c-a131-e3baaa0845ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = input(\"> \")\n",
    "#print (question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b231f98-fbd1-426c-bf58-020e053fdec9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Connection to the Azure OpenAI model\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "  api_key=AZURE_OPENAI_API_KEY,  \n",
    "  api_version=OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=OPENAI_DEPLOYMENT_NAME,temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb1690-0ebb-4110-b34a-e4e9287102c1",
   "metadata": {},
   "source": [
    "### Using LLM to query the graph using GraphCypherQAChain library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84477b1-76be-4f44-8b24-5718e60412e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mWhat are the names of the facilities that are responsible for drilling wellbore with NpdidWellbore '5693-L-008'? \n",
      "\n",
      "Cypher statement:\n",
      "MATCH (:Wellbore {NpdidWellbore: '5693-L-008'})<-[:DRILLED]-(f:Facility) WHERE EXISTS((:Company)-[:IS_RESPONSIBLE_FOR]->(f)) RETURN f.Name\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'What': expected\n  \"ALTER\"\n  \"CALL\"\n  \"CREATE\"\n  \"DEALLOCATE\"\n  \"DELETE\"\n  \"DENY\"\n  \"DETACH\"\n  \"DROP\"\n  \"DRYRUN\"\n  \"ENABLE\"\n  \"FINISH\"\n  \"FOREACH\"\n  \"GRANT\"\n  \"INSERT\"\n  \"LOAD\"\n  \"MATCH\"\n  \"MERGE\"\n  \"NODETACH\"\n  \"OPTIONAL\"\n  \"REALLOCATE\"\n  \"REMOVE\"\n  \"RENAME\"\n  \"RETURN\"\n  \"REVOKE\"\n  \"SET\"\n  \"SHOW\"\n  \"START\"\n  \"STOP\"\n  \"TERMINATE\"\n  \"UNWIND\"\n  \"USE\"\n  \"USING\"\n  \"WITH\" (line 1, column 1 (offset: 0))\n\"What are the names of the facilities that are responsible for drilling wellbore with NpdidWellbore '5693-L-008'?\"\n ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:391\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:313\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_disabled_categories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:181\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:301\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:178\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:850\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    847\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    848\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    849\u001b[0m )\n\u001b[1;32m--> 850\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:369\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:245\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    244\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'What': expected\n  \"ALTER\"\n  \"CALL\"\n  \"CREATE\"\n  \"DEALLOCATE\"\n  \"DELETE\"\n  \"DENY\"\n  \"DETACH\"\n  \"DROP\"\n  \"DRYRUN\"\n  \"ENABLE\"\n  \"FINISH\"\n  \"FOREACH\"\n  \"GRANT\"\n  \"INSERT\"\n  \"LOAD\"\n  \"MATCH\"\n  \"MERGE\"\n  \"NODETACH\"\n  \"OPTIONAL\"\n  \"REALLOCATE\"\n  \"REMOVE\"\n  \"RENAME\"\n  \"RETURN\"\n  \"REVOKE\"\n  \"SET\"\n  \"SHOW\"\n  \"START\"\n  \"STOP\"\n  \"TERMINATE\"\n  \"UNWIND\"\n  \"USE\"\n  \"USING\"\n  \"WITH\" (line 1, column 1 (offset: 0))\n\"What are the names of the facilities that are responsible for drilling wellbore with NpdidWellbore '5693-L-008'?\"\n ^}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcypher_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\langchain_community\\chains\\graph_qa\\cypher.py:274\u001b[0m, in \u001b[0;36mGraphCypherQAChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Retrieve and limit the number of results\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# Generated Cypher be null if query corrector identifies invalid schema\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_cypher:\n\u001b[1;32m--> 274\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_cypher\u001b[49m\u001b[43m)\u001b[49m[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k]\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     context \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\Customers\\Equinor\\PoC\\RAG Graph and Embeddings\\.PoC_venv\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:397\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_data\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CypherSyntaxError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Cypher Statement is not valid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'What': expected\n  \"ALTER\"\n  \"CALL\"\n  \"CREATE\"\n  \"DEALLOCATE\"\n  \"DELETE\"\n  \"DENY\"\n  \"DETACH\"\n  \"DROP\"\n  \"DRYRUN\"\n  \"ENABLE\"\n  \"FINISH\"\n  \"FOREACH\"\n  \"GRANT\"\n  \"INSERT\"\n  \"LOAD\"\n  \"MATCH\"\n  \"MERGE\"\n  \"NODETACH\"\n  \"OPTIONAL\"\n  \"REALLOCATE\"\n  \"REMOVE\"\n  \"RENAME\"\n  \"RETURN\"\n  \"REVOKE\"\n  \"SET\"\n  \"SHOW\"\n  \"START\"\n  \"STOP\"\n  \"TERMINATE\"\n  \"UNWIND\"\n  \"USE\"\n  \"USING\"\n  \"WITH\" (line 1, column 1 (offset: 0))\n\"What are the names of the facilities that are responsible for drilling wellbore with NpdidWellbore '5693-L-008'?\"\n ^}"
     ]
    }
   ],
   "source": [
    "# FIRST PROMPT - Transform a natural language query in a Cypher query\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about the offshore oil and gas industry.\n",
    "Convert the user's question based on the schema.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "The property existence syntax `... exists(variable.property)` is no longer supported. Please use `variable.property IS NOT NULL` instead.\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "# Memory for chat conversation\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"query\", return_messages=True)\n",
    "\n",
    "# SECOND PROMPT - Use the Cypher query to answer the user query\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    response = cypher_chain.invoke({\n",
    "        \"query\": question\n",
    "        })\n",
    "    \n",
    "    print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac54d9-953b-487e-883a-2de8ab6bcd8f",
   "metadata": {},
   "source": [
    "-   How many facilities belongs to the \"GULLFAKS\" oil field?\n",
    "-   Give me the name and FactPage URL of the facilities of the \"GULLFAKS\" oil field?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

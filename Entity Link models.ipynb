{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import io\n",
    "from langdetect import detect\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando as teses e seus abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'IndigenousSlavery'\n",
    "conn = stardog.Connection(database_name, **connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query que busca as teses e os seus abstracts. Foi incluído um filtro para buscar apenas \n",
    "# os abstract em português, inglês ou em outra língua\n",
    "query = \"\"\"\n",
    "SELECT ?thesis ?abstract (lang(?abstract) AS ?lang) WHERE {\n",
    "  ?thesis a <http://purl.org/ontology/bibo/Thesis>.\n",
    "  ?thesis <http://purl.org/ontology/bibo/abstract> ?abstract.\n",
    "  FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "  \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# FILTER (langMatches(lang(?abstract),\"pt\"))\n",
    "# FILTER (langMatches(lang(?abstract),\"en\"))\n",
    "# FILTER (lang(?abstract) NOT IN(\"pt\", \"en\"))\n",
    "# LIMIT 20\n",
    "\n",
    "csv_results = conn.select(query, content_type='text/csv')\n",
    "thesis_abstract = pd.read_csv(io.BytesIO(csv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo arquivo com as entidades extraídas dos abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/abstract_NER.json') as fp:\n",
    "    NER_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo arquivos com as entidades da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_people.json') as fp:\n",
    "    dbpedia_people = json.load(fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_locals.json') as fp:\n",
    "    dbpedia_locals = json.load(fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_orgs.json') as fp:\n",
    "    dbpedia_orgs = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando listas de labels e texto para os abstracts das teses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "uris = []\n",
    "classes = []\n",
    "labels = []\n",
    "texts = []\n",
    "languages = []\n",
    "\n",
    "for thesis_uri in NER_dic:\n",
    "    n = n + 1\n",
    "    abstract = thesis_abstract[thesis_abstract['thesis'] == 'tag:stardog:api:'+ thesis_uri]['abstract']\n",
    "    abstract = list(abstract)[0]\n",
    "    \n",
    "    lang = NER_dic[thesis_uri]['lang']\n",
    "    \n",
    "    for classe in ['PER', 'LOC', 'ORG']:\n",
    "        try:\n",
    "            for ent in NER_dic[thesis_uri][classe]:\n",
    "                for label in NER_dic[thesis_uri][classe][ent]['labels']:\n",
    "                    uris.append(thesis_uri)\n",
    "                    classes.append(classe)\n",
    "                    labels.append(label)\n",
    "                    texts.append(abstract)\n",
    "                    languages.append(lang)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "#Criando dataframe\n",
    "theses_df = pd.DataFrame({'Classes':classes, 'URIs':uris, 'Labels': labels, 'Abstract': texts, 'Language': languages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando listas de labels e texto para as páginas da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = []\n",
    "classes = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for i in dbpedia_people:\n",
    "    classes.append('PER')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "for i in dbpedia_locals:\n",
    "    classes.append('LOC')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "for i in dbpedia_orgs:\n",
    "    classes.append('ORG')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "#Criando dataframe\n",
    "dbpedia_df = pd.DataFrame({'Classes':classes, 'URIs':uris, 'Labels': labels, 'Abstract': texts})\n",
    "\n",
    "#Criando coluna com lingua\n",
    "dbpedia_df['Language'] = dbpedia_df['Abstract'].apply(detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processo de amostragem para a criacao do dataset de dentity linking.\n",
    "\n",
    "Para cada classe serão amostradas 100 entidades. Serão amostradas 100 teses e para cada tese será amostrada uma entidade. Para cada entidade, recuperaremos todas as páginas da DBPEDIA encontradas, usando as label amostradas ou outras variacões que o anotador possa tentar. Também serão coletada os abstracts de teses que contenham essa entidade. Caso haja muitas teses, serão recuperadas 10 teses.\n",
    "\n",
    "Para as pessoas, não iremos anotar aquelas que aparecem no texto apenas como referência bibliográfica (ex: \"tomamos como suporte a teoria da argumentação de Chaïm Perelman e Lucie Olbrechts-Tyteca na Nova Retórica\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "por_voce_ser_negra_e_pobre_tem_esse_direito_negado_um_estudo_sobre_direitos_reprodutivos_de_mulheres_negras_com_doenca_falciforme_em_salvador\n",
      "Michel Foucault\n",
      "['Michel Foucault']\n"
     ]
    }
   ],
   "source": [
    "#Amostrando uma tese e uma label\n",
    "classe = 'PER'\n",
    "\n",
    "thesis_uris = list(NER_dic.keys())\n",
    "uri = random.sample(thesis_uris, 1)[0]\n",
    "\n",
    "NERs = list(NER_dic[uri][classe].keys())\n",
    "NER = random.sample(NERs, 1)[0]\n",
    "\n",
    "labels = NER_dic[uri][classe][NER]['labels']\n",
    "\n",
    "print(uri)\n",
    "print(NER)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>URIs</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>PER</td>\n",
       "      <td>a_constituicao_do_sujeito_infame_negro_no_cine...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>The purpose of this dissertation is to investi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>PER</td>\n",
       "      <td>a_construcao_do_morto_indigente_no_instituto_m...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>Esta tese tem como objetivo investigar a const...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>PER</td>\n",
       "      <td>a_educacao_escolar_de_indigenas_surdos_guarani...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>O atendimento escolar de estudantes surdos est...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>PER</td>\n",
       "      <td>a_filosofia_politica_de_achille_mbembe_entre_a...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>This research aims to develop conceptual compa...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>PER</td>\n",
       "      <td>a_imagem_da_escola_pblica_produzida_por_estuda...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>This research was born with the intention of s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82797</th>\n",
       "      <td>PER</td>\n",
       "      <td>uma_perspectiva_criticoracial_da_historia_da_m...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>A presente tese tem por objetivo identificar e...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84174</th>\n",
       "      <td>PER</td>\n",
       "      <td>violando_identidades_um_estudo_das_representac...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>O presente trabalho configura-se como um estud...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84372</th>\n",
       "      <td>PER</td>\n",
       "      <td>violento_e_o_estado_violencia_politica_nas_pra...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>The present dissertation investigates the use ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84438</th>\n",
       "      <td>PER</td>\n",
       "      <td>vitimas_e_controle_punitivo_um_percurso_pelos_...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>The field of promotion of criminal public poli...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84665</th>\n",
       "      <td>PER</td>\n",
       "      <td>vixe_que_menina_preta_e_essa_eu_tassia_reis_pr...</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>Nesta tese intitulada “Vixe!!! Que menina pret...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes                                               URIs  \\\n",
       "1233      PER  a_constituicao_do_sujeito_infame_negro_no_cine...   \n",
       "1493      PER  a_construcao_do_morto_indigente_no_instituto_m...   \n",
       "2603      PER  a_educacao_escolar_de_indigenas_surdos_guarani...   \n",
       "3707      PER  a_filosofia_politica_de_achille_mbembe_entre_a...   \n",
       "4663      PER  a_imagem_da_escola_pblica_produzida_por_estuda...   \n",
       "...       ...                                                ...   \n",
       "82797     PER  uma_perspectiva_criticoracial_da_historia_da_m...   \n",
       "84174     PER  violando_identidades_um_estudo_das_representac...   \n",
       "84372     PER  violento_e_o_estado_violencia_politica_nas_pra...   \n",
       "84438     PER  vitimas_e_controle_punitivo_um_percurso_pelos_...   \n",
       "84665     PER  vixe_que_menina_preta_e_essa_eu_tassia_reis_pr...   \n",
       "\n",
       "                Labels                                           Abstract  \\\n",
       "1233   Michel Foucault  The purpose of this dissertation is to investi...   \n",
       "1493   Michel Foucault  Esta tese tem como objetivo investigar a const...   \n",
       "2603   Michel Foucault  O atendimento escolar de estudantes surdos est...   \n",
       "3707   Michel Foucault  This research aims to develop conceptual compa...   \n",
       "4663   Michel Foucault  This research was born with the intention of s...   \n",
       "...                ...                                                ...   \n",
       "82797  Michel Foucault  A presente tese tem por objetivo identificar e...   \n",
       "84174  Michel Foucault  O presente trabalho configura-se como um estud...   \n",
       "84372  Michel Foucault  The present dissertation investigates the use ...   \n",
       "84438  Michel Foucault  The field of promotion of criminal public poli...   \n",
       "84665  Michel Foucault  Nesta tese intitulada “Vixe!!! Que menina pret...   \n",
       "\n",
       "      Language  \n",
       "1233        en  \n",
       "1493        pt  \n",
       "2603        pt  \n",
       "3707        en  \n",
       "4663        en  \n",
       "...        ...  \n",
       "82797       pt  \n",
       "84174       pt  \n",
       "84372       en  \n",
       "84438       en  \n",
       "84665       pt  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'Michel Foucault'\n",
    "sample_thesis = theses_df[(theses_df['Classes'] == classe) & (theses_df['Labels'] == l)]#.sample(1)\n",
    "sample_thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_construcao_do_morto_indigente_no_instituto_medico_legal_de_pernambuco__afinal_de_contas_de_quem_se_trata']\n",
      "foram utilizadas as ideias de biopoder e biopolítica, trabalhadas por Michel Foucault. Como estratégia metodológica, foi utilizada pesquisa \n",
      "Esta tese tem como objetivo investigar a constituição de mortos indigentes no IMLAPC Recife e como essa constituição se inscreve como dispositivo necropolítico. Buscou analisar os lugares, práticas, atores e argumentos que compõem a produção da noção de mortos indigentes; e, investigar de quem são os corpos classificados como indigentes. Está embasada teoricamente na noção de necropolítica, lançada por Achille Mbembe. Para entender essa noção, foram utilizadas as ideias de biopoder e biopolítica, trabalhadas por Michel Foucault. Como estratégia metodológica, foi utilizada pesquisa \n"
     ]
    }
   ],
   "source": [
    "sample_thesis2 = sample_thesis.sample(1)\n",
    "print(sample_thesis2['URIs'].values)\n",
    "position = sample_thesis2['Abstract'].values[0].find(l)\n",
    "print(sample_thesis2['Abstract'].values[0][position-70:position+70])\n",
    "print(sample_thesis2['Abstract'].values[0][:position+70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>URIs</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>PER</td>\n",
       "      <td>http://dbpedia.org/resource/Michel_Foucault</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>Michel Foucault (pronúncia em francês: ​[miʃɛl...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>PER</td>\n",
       "      <td>http://dbpedia.org/resource/Michel_Foucault</td>\n",
       "      <td>Michel Foucault</td>\n",
       "      <td>Paul-Michel Foucault (UK: /ˈfuːkoʊ/, US: /fuːˈ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Classes                                         URIs           Labels  \\\n",
       "790      PER  http://dbpedia.org/resource/Michel_Foucault  Michel Foucault   \n",
       "5757     PER  http://dbpedia.org/resource/Michel_Foucault  Michel Foucault   \n",
       "\n",
       "                                               Abstract Language  \n",
       "790   Michel Foucault (pronúncia em francês: ​[miʃɛl...       pt  \n",
       "5757  Paul-Michel Foucault (UK: /ˈfuːkoʊ/, US: /fuːˈ...       en  "
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'Michel Foucault'\n",
    "dbpedia_df[(dbpedia_df['Classes'] == classe) & (dbpedia_df['Labels'] == l)]\n",
    "#dbpedia_df[(dbpedia_df['URIs'] == 'http://dbpedia.org/resource/Conceição_Evaristo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://dbpedia.org/resource/Carolina_Maria_de_Jesus'"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_df.loc[2689]['URIs']\n",
    "#dbpedia_df.loc[2689]['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_lg\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'IndigenousSlavery'\n",
    "conn = stardog.Connection(database_name, **connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thesis</th>\n",
       "      <th>abstract</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:stardog:api:_as_negras_estao_chegando_pra_...</td>\n",
       "      <td>Esta pesquisa dedicou-se ao estudo das produçõ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:stardog:api:_e_teko_e_arandu_e_producao_de...</td>\n",
       "      <td>Esta pesquisa persegue pistas na produção de s...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag:stardog:api:_nos_aqui_e_o_espaco_dos_sem_v...</td>\n",
       "      <td>This article deals with families and schools i...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag:stardog:api:_ou_entao_e_influencia_da_cor_...</td>\n",
       "      <td>This thesis has as main objective to understan...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag:stardog:api:_para_conter_os_pretos_debates...</td>\n",
       "      <td>The purpose of this research is to understand ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>tag:stardog:api:137_anos_de_sempre_um_capitulo...</td>\n",
       "      <td>Dissertação (mestrado) - Universidade Federal ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>tag:stardog:api:1923_investigacao_sobre_a_exis...</td>\n",
       "      <td>In 1923, the Clube de Regatas Vasco da Gama ta...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>tag:stardog:api:1958_o_ano_que_nao_terminou_me...</td>\n",
       "      <td>This inquiry treats of the black dance nights ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13851</th>\n",
       "      <td>tag:stardog:api:4_mulheres_e_o_encontro_na_edu...</td>\n",
       "      <td>How to produce existence in a systematic produ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>tag:stardog:api:7_ensayos_de_interpretacion_de...</td>\n",
       "      <td>Tese (Doutorado em Estudos Comparados sobre as...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  thesis  \\\n",
       "0      tag:stardog:api:_as_negras_estao_chegando_pra_...   \n",
       "1      tag:stardog:api:_e_teko_e_arandu_e_producao_de...   \n",
       "2      tag:stardog:api:_nos_aqui_e_o_espaco_dos_sem_v...   \n",
       "3      tag:stardog:api:_ou_entao_e_influencia_da_cor_...   \n",
       "4      tag:stardog:api:_para_conter_os_pretos_debates...   \n",
       "...                                                  ...   \n",
       "13848  tag:stardog:api:137_anos_de_sempre_um_capitulo...   \n",
       "13849  tag:stardog:api:1923_investigacao_sobre_a_exis...   \n",
       "13850  tag:stardog:api:1958_o_ano_que_nao_terminou_me...   \n",
       "13851  tag:stardog:api:4_mulheres_e_o_encontro_na_edu...   \n",
       "13852  tag:stardog:api:7_ensayos_de_interpretacion_de...   \n",
       "\n",
       "                                                abstract lang  \n",
       "0      Esta pesquisa dedicou-se ao estudo das produçõ...   pt  \n",
       "1      Esta pesquisa persegue pistas na produção de s...   pt  \n",
       "2      This article deals with families and schools i...   en  \n",
       "3      This thesis has as main objective to understan...   en  \n",
       "4      The purpose of this research is to understand ...   en  \n",
       "...                                                  ...  ...  \n",
       "13848  Dissertação (mestrado) - Universidade Federal ...   pt  \n",
       "13849  In 1923, the Clube de Regatas Vasco da Gama ta...   en  \n",
       "13850  This inquiry treats of the black dance nights ...   en  \n",
       "13851  How to produce existence in a systematic produ...   en  \n",
       "13852  Tese (Doutorado em Estudos Comparados sobre as...   pt  \n",
       "\n",
       "[13853 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query que busca as teses e os seus abstracts. Foi incluído um filtro para buscar apenas \n",
    "# os abstract em português, inglês ou em outra língua\n",
    "query = \"\"\"\n",
    "SELECT ?thesis ?abstract (lang(?abstract) AS ?lang) WHERE {\n",
    "  ?thesis a <http://purl.org/ontology/bibo/Thesis>.\n",
    "  ?thesis <http://purl.org/ontology/bibo/abstract> ?abstract.\n",
    "  FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "  \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# FILTER (langMatches(lang(?abstract),\"pt\"))\n",
    "# FILTER (langMatches(lang(?abstract),\"en\"))\n",
    "# FILTER (lang(?abstract) NOT IN(\"pt\", \"en\"))\n",
    "# LIMIT 20\n",
    "\n",
    "csv_results = conn.select(query, content_type='text/csv')\n",
    "thesis_abstract = pd.read_csv(io.BytesIO(csv_results))\n",
    "thesis_abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraíndo as entidades dos abstracts\n",
    "\n",
    "#Carregando os modelos SpaCy para inglês e português \n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "nlp_pt = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "#Dicionário que receberá as instâncias de cada tese\n",
    "instances_dic = {}\n",
    "\n",
    "for n in range(len(thesis_abstract)):\n",
    "\n",
    "    # Processando os abstracts em português\n",
    "    if thesis_abstract['lang'][n] == 'pt':\n",
    "\n",
    "        doc_pt = nlp_pt(str(thesis_abstract['abstract'][n]))\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        orgs = []\n",
    "        for ent in doc_pt.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(ent)\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(ent)\n",
    "            if ent.label_ == \"ORG\":\n",
    "                orgs.append(ent)\n",
    "\n",
    "        instances_dic[thesis_abstract['thesis'][n].replace('tag:stardog:api:','')] = {'PER':persons, 'LOC':gpes, 'ORG':orgs, 'lang': 'pt'}\n",
    "\n",
    "    # Processando os abstracts em inglês\n",
    "    if thesis_abstract['lang'][n] == 'en':\n",
    "\n",
    "        doc_en = nlp_en(str(thesis_abstract['abstract'][n]))\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        orgs = []\n",
    "        for ent in doc_en.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                persons.append(ent)\n",
    "            if ent.label_ == \"GPE\":\n",
    "                gpes.append(ent)\n",
    "            if ent.label_ == \"ORG\":\n",
    "                orgs.append(ent)\n",
    "\n",
    "        instances_dic[thesis_abstract['thesis'][n].replace('tag:stardog:api:','')] = {'PER':persons, 'LOC':gpes, 'ORG':orgs, 'lang': 'en'}\n",
    "\n",
    "    if n%500 == 499:\n",
    "        print(n, \" teses processadas.\")\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para uma lista de entidades verificar se são a mesma instância e qual o termo mais comum para representá-las\n",
    "\n",
    "def entidades_consolidadas(list_ent, th):\n",
    "    \n",
    "    if list_ent == []:\n",
    "        return None\n",
    "\n",
    "    # lista com os vetores das entidades\n",
    "  \n",
    "    list_vectors = np.array([i.vector for i in list_ent])\n",
    "\n",
    "    #clusterizando os vetores de acordo com threshold th\n",
    "    clustering = DBSCAN(eps=1-th, min_samples=1, metric='cosine').fit(list_vectors)\n",
    "\n",
    "    #processnado os clusters \n",
    "    ents_dic ={}\n",
    "\n",
    "    for i in set(clustering.labels_):\n",
    "        clus_index = np.where(clustering.labels_ == i)[0]\n",
    "        label = []\n",
    "        vec = []\n",
    "        \n",
    "        for c in clus_index:\n",
    "            vec.append(list_ent[c].vector)\n",
    "            label.append(list_ent[c].text)\n",
    "\n",
    "        ents_dic[max(set(label), key=label.count)] = {'labels': list(set(label)), 'vector': np.average(vec, axis=0).tolist()}\n",
    "\n",
    "    return ents_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprocessando as listas de entidades para eliminar as entidades duplicadas de cada tese e obtendo o vetor de cada entidade\n",
    "th = 0.90\n",
    "\n",
    "i = 0\n",
    "for key in instances_dic:\n",
    "    for type_ent in instances_dic[key]:\n",
    "        if type_ent != 'lang':\n",
    "            list_ent = instances_dic[key][type_ent]\n",
    "            instances_dic[key][type_ent] = entidades_consolidadas(list_ent, th)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o dicionário com a lista de entidades mencionadas no abstract\n",
    "#with open('data/abstract_NER.json', 'w') as fp:\n",
    "#    json.dump(instances_dic, fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/abstract_NER.json') as fp:\n",
    "    instances_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Clusterizando as entidades em Português\n",
    "\n",
    "per_list = []\n",
    "per_label_list = []\n",
    "per_vector_list = []\n",
    "per_key_list = []\n",
    "\n",
    "for key in instances_dic:\n",
    "    if instances_dic[key]['lang'] == 'pt':\n",
    "        if instances_dic[key]['PER'] != None:\n",
    "            for p in instances_dic[key]['PER']:\n",
    "                per_list.append(p)\n",
    "                per_label_list.append(instances_dic[key]['PER'][p]['labels'])\n",
    "                per_vector_list.append(instances_dic[key]['PER'][p]['vector'])\n",
    "                per_key_list.append(key)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"th =0.98\n",
    "clustering_per = DBSCAN(eps=1-th, min_samples=1, metric='cosine').fit(per_vector_list)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"per_citadas = pd.DataFrame({'teses': per_key_list, 'person': per_list, 'labels' :per_label_list, 'cluster': clustering_per.labels_})\\nper_citadas[per_citadas['cluster'] == 140]\\n#len(set(clustering_per.labels_))\\n#per_label_list[[clustering_per.labels_ == 0]]\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"per_citadas = pd.DataFrame({'teses': per_key_list, 'person': per_list, 'labels' :per_label_list, 'cluster': clustering_per.labels_})\n",
    "per_citadas[per_citadas['cluster'] == 140]\n",
    "#len(set(clustering_per.labels_))\n",
    "#per_label_list[[clustering_per.labels_ == 0]]\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando dados da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de labels de ORG:  14472\n",
      "Total de labels de PER:  12564\n",
      "Total de labels de LOC:  14126\n"
     ]
    }
   ],
   "source": [
    "# Coletando todas as labels das entidades extraídas dos abstracts\n",
    "\n",
    "people_labels = []\n",
    "local_labels = []\n",
    "org_labels = []\n",
    "\n",
    "for key in instances_dic:\n",
    "    for type_ent in instances_dic[key]:\n",
    "\n",
    "        list_ent = instances_dic[key][type_ent]\n",
    "        if list_ent != None:\n",
    "            for ent in list_ent:\n",
    "                if type_ent == 'PER':\n",
    "                    people_labels = people_labels + list_ent[ent]['labels']\n",
    "                if type_ent == 'LOC':\n",
    "                    local_labels = local_labels + list_ent[ent]['labels']\n",
    "                if type_ent == 'ORG':\n",
    "                    org_labels = org_labels + list_ent[ent]['labels']\n",
    "\n",
    "people_labels = list(set(people_labels))\n",
    "local_labels = list(set(local_labels))\n",
    "org_labels = list(set(org_labels))\n",
    "\n",
    "print('Total de labels de ORG: ', len(org_labels))\n",
    "print('Total de labels de PER: ', len(people_labels))\n",
    "print('Total de labels de LOC: ', len(local_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para buscar as labels na DBPEDIA. A funcao retorna as URI a abstracts de entidades que estao registradas na DBPEDIA.\n",
    "# sc_th é o threshold do score de busca para uma URI da DBPEDIA ser retornada.\n",
    "def DBPEDIA_search(labels, classe, sc_th):\n",
    "\n",
    "    dbpedia_ent = []\n",
    "\n",
    "    for ent_bruto in labels:\n",
    "        # processando as labels para ser buscada na DBPEDIA\n",
    "        ent = re.sub('[^a-zA-Z0-9_ ]', '', unidecode(ent_bruto)).strip()\n",
    "        ent = ent.replace(' and ', ' ').replace(' or ', ' ')\n",
    "        ent = re.sub(\"\\s\\s+\" , \" \", ent)\n",
    "        \n",
    "        ent_vector = \"'\" + ent.replace(\" \", \"', '\") + \"'\"\n",
    "        ent_contains = ent.replace(\" \", \" AND \")\n",
    "\n",
    "        # Sparql query para fazer busca em linguagem natural e retornar os resultados rankeados pelo score ?sc.\n",
    "        query = \"\"\" \n",
    "            define input:ifp \"IFP_OFF\"  \n",
    "            select ?s1 as ?c1, (bif:search_excerpt (bif:vector (\"\"\" + ent_vector + \"\"\"), ?o1)) as ?c2, ?sc, ?rank, ?g, ?abstract \n",
    "            where \n",
    "            { \n",
    "            select ?s1, (?sc * 3e-1) as ?sc, ?o1, (sql:rnk_scale (<LONG::IRI_RANK> (?s1))) as ?rank, ?g, ?abstract \n",
    "            \n",
    "            where  \n",
    "            { \n",
    "                quad map virtrdf:DefaultQuadMap \n",
    "                { \n",
    "                graph ?g \n",
    "                { \n",
    "                    ?s1 ?s1textp ?o1 .\n",
    "                    ?o1 bif:contains  '(\"\"\" + ent_contains + \"\"\")'  option (score ?sc)  .\n",
    "                    ?s1 a \"\"\" + classe + \"\"\".\n",
    "                    ?s1 dbo:abstract ?abstract.\n",
    "                    FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "                }\n",
    "                } \n",
    "            }\n",
    "\n",
    "            order by desc (?sc * 3e-1 + sql:rnk_scale (<LONG::IRI_RANK> (?s1)))  limit 5  offset 0 \n",
    "            } \n",
    "            \"\"\"\n",
    "        # URL da DBPEDIA e request\n",
    "        url = 'http://dbpedia.org/sparql'\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "            data = r.json()\n",
    "\n",
    "            # processando os resultados obtidos\n",
    "            if data['results']['bindings'] != []:\n",
    "\n",
    "                bindings = []\n",
    "                for r in data['results']['bindings']:\n",
    "                    if float(r['sc']['value']) > sc_th:\n",
    "                        bindings.append((ent_bruto, r['sc']['value'], r['c1']['value'], r['abstract']['value']))\n",
    "                \n",
    "                dbpedia_ent = dbpedia_ent + list(set(bindings))\n",
    "        except:\n",
    "            print('Erro ao buscar a label: ', ent_bruto)\n",
    "    return dbpedia_ent  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe uma lista de labels de uma determinada classe, \n",
    "# busca essas labels na DBPEDIA e salva as tuplas com as labels e abstracts no diretório desejado.\n",
    "\n",
    "def coletando_dbpedia_tuplas(labels, classe, path):\n",
    "    # Lista recebe as tuplas\n",
    "    db_tupla = []\n",
    "    #Bach em que as tuplas serão salvas\n",
    "    step = 100\n",
    "    for n in range(0, len(labels), step):\n",
    "        # Busca as labels usando a funcão DBPEDIA_search\n",
    "        ex_DB = DBPEDIA_search(labels[n:n+step], classe, 3.0)\n",
    "        \n",
    "        for ex in ex_DB:\n",
    "            db_tupla.append((ex[2], ex[3]))\n",
    "        # Elimina as tuplas repetidas\n",
    "        db_tupla = list(set(db_tupla))\n",
    "\n",
    "        # Salvando o dicionário com a lista de entidades mencionadas no abstract\n",
    "        with open(path, 'w') as fp:\n",
    "            json.dump(db_tupla, fp)\n",
    "        print(n+step, '- Total de tuplas: ', len(db_tupla))\n",
    "\n",
    "    return db_tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(people_labels, 'dbo:Person', 'data/DBPEDIA_people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(local_labels, 'dbo:Place', 'data/DBPEDIA_locals.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(org_labels, 'dbo:Organisation', 'data/DBPEDIA_orgs.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as triplas e carregando no knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixos\n",
    "prefixos = \"\"\" @prefix ns: <http://www.w3.org/2003/06/sw-vocab-status/ns#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
    "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "@prefix vann: <http://purl.org/vocab/vann/> .\n",
    "@prefix event: <http://purl.org/NET/c4dm/event.owl#> .\n",
    "@prefix prism: <http://prismstandard.org/namespaces/1.2/basic/> .\n",
    "@prefix terms: <http://purl.org/dc/terms/> .\n",
    "@prefix schema: <http://schemas.talis.com/2005/address/schema#> .\n",
    "@prefix status: <http://purl.org/ontology/bibo/status/> .\n",
    "@prefix degrees: <http://purl.org/ontology/bibo/degrees/> .\n",
    "@prefix stardog: <tag:stardog:api:> .\n",
    "@base <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe os prefixos e triplas e as carrega à base de dados\n",
    "def add_triplas_to_stardog(prefixos, triplas):\n",
    "\n",
    "    # Incluindo prefixos às triplas\n",
    "    triplas = prefixos + \" \" + triplas\n",
    "\n",
    "    ### Connect to the Stardog database\n",
    "    database_name = 'IndigenousSlavery'\n",
    "    conn = stardog.Connection(database_name, **connection_details)\n",
    "\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.Raw(triplas, 'text/turtle'))\n",
    "    conn.commit() # commit the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_people.json') as fp:\n",
    "    dbpedia_people = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando pessoas\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_people:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type foaf:Person.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_locals.json') as fp:\n",
    "    dbpedia_locals = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando locais\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_locals:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type <https://schema.org/Place>.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_orgs.json') as fp:\n",
    "    dbpedia_orgs = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando organizacões\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_orgs:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type foaf:Organization.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

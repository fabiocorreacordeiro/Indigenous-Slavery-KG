{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import io\n",
    "from langdetect import detect\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando as teses e seus abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'IndigenousSlavery'\n",
    "conn = stardog.Connection(database_name, **connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query que busca as teses e os seus abstracts. Foi incluído um filtro para buscar apenas \n",
    "# os abstract em português, inglês ou em outra língua\n",
    "query = \"\"\"\n",
    "SELECT ?thesis ?abstract (lang(?abstract) AS ?lang) WHERE {\n",
    "  ?thesis a <http://purl.org/ontology/bibo/Thesis>.\n",
    "  ?thesis <http://purl.org/ontology/bibo/abstract> ?abstract.\n",
    "  FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "  \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# FILTER (langMatches(lang(?abstract),\"pt\"))\n",
    "# FILTER (langMatches(lang(?abstract),\"en\"))\n",
    "# FILTER (lang(?abstract) NOT IN(\"pt\", \"en\"))\n",
    "# LIMIT 20\n",
    "\n",
    "csv_results = conn.select(query, content_type='text/csv')\n",
    "thesis_abstract = pd.read_csv(io.BytesIO(csv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo arquivo com as entidades extraídas dos abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/abstract_NER.json') as fp:\n",
    "    NER_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo arquivos com as entidades da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_people.json') as fp:\n",
    "    dbpedia_people = json.load(fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_locals.json') as fp:\n",
    "    dbpedia_locals = json.load(fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_orgs.json') as fp:\n",
    "    dbpedia_orgs = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando listas de labels e texto para os abstracts das teses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "uris = []\n",
    "classes = []\n",
    "labels = []\n",
    "texts = []\n",
    "languages = []\n",
    "\n",
    "for thesis_uri in NER_dic:\n",
    "    n = n + 1\n",
    "    abstract = thesis_abstract[thesis_abstract['thesis'] == 'tag:stardog:api:'+ thesis_uri]['abstract']\n",
    "    abstract = list(abstract)[0]\n",
    "    \n",
    "    lang = NER_dic[thesis_uri]['lang']\n",
    "    \n",
    "    for classe in ['PER', 'LOC', 'ORG']:\n",
    "        try:\n",
    "            for ent in NER_dic[thesis_uri][classe]:\n",
    "                for label in NER_dic[thesis_uri][classe][ent]['labels']:\n",
    "                    uris.append(thesis_uri)\n",
    "                    classes.append(classe)\n",
    "                    labels.append(label)\n",
    "                    texts.append(abstract)\n",
    "                    languages.append(lang)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "#Criando dataframe\n",
    "theses_df = pd.DataFrame({'Classes':classes, 'URIs':uris, 'Labels': labels, 'Abstract': texts, 'Language': languages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando listas de labels e texto para as páginas da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = []\n",
    "classes = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for i in dbpedia_people:\n",
    "    classes.append('PER')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "for i in dbpedia_locals:\n",
    "    classes.append('LOC')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "for i in dbpedia_orgs:\n",
    "    classes.append('ORG')\n",
    "    uris.append(i[0])\n",
    "    labels.append(i[0].replace('http://dbpedia.org/resource/',\"\").replace(\"_\", \" \"))\n",
    "    texts.append(i[1])\n",
    "\n",
    "#Criando dataframe\n",
    "dbpedia_df = pd.DataFrame({'Classes':classes, 'URIs':uris, 'Labels': labels, 'Abstract': texts})\n",
    "\n",
    "#Criando coluna com lingua\n",
    "dbpedia_df['Language'] = dbpedia_df['Abstract'].apply(detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processo de amostragem para a criacao do dataset de dentity linking.\n",
    "\n",
    "Para cada classe serão amostradas 100 entidades. Serão amostradas 100 teses e para cada tese será amostrada uma entidade. Para cada entidade, recuperaremos todas as páginas da DBPEDIA encontradas, usando as label amostradas ou outras variacões que o anotador possa tentar. Também serão coletada os abstracts de teses que contenham essa entidade. Caso haja muitas teses, serão recuperadas 10 teses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indios_civilizados_e_escolarizados_a_producao_de_uma_outra_condicao_de_etnicidade\n",
      "Minas Gerais\n",
      "['Minas Gerais']\n"
     ]
    }
   ],
   "source": [
    "#Amostrando uma tese e uma label\n",
    "classe = 'LOC'\n",
    "\n",
    "thesis_uris = list(NER_dic.keys())\n",
    "uri = random.sample(thesis_uris, 1)[0]\n",
    "\n",
    "NERs = list(NER_dic[uri][classe].keys())\n",
    "NER = random.sample(NERs, 1)[0]\n",
    "\n",
    "labels = NER_dic[uri][classe][NER]['labels']\n",
    "\n",
    "print(uri)\n",
    "print(NER)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>URIs</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>LOC</td>\n",
       "      <td>a_construcao_de_sentidos_no_reinado_do_rosario...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Atribuímos sentidos e significados em cada enu...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>LOC</td>\n",
       "      <td>a_educacao_quilombola_na_comunidade_colonia_do...</td>\n",
       "      <td>MG</td>\n",
       "      <td>A pesquisa intitulada “A Educação Quilombola n...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>LOC</td>\n",
       "      <td>a_festa_de_nossa_senhora_do_rosario_de_paula_c...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Os diferentes períodos de colonização, somando...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>LOC</td>\n",
       "      <td>a_formao_de_professores_da_educao_bsica_a_real...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Em todas as partes que comp?em a obra, consta ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>LOC</td>\n",
       "      <td>a_imagem_do_negro_em_manuais_para_o_professor_...</td>\n",
       "      <td>MG</td>\n",
       "      <td>No presente estudo, visamos investigar como se...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83076</th>\n",
       "      <td>LOC</td>\n",
       "      <td>urdiduras_museais_e_tramas_expositivas_no_muse...</td>\n",
       "      <td>MG</td>\n",
       "      <td>A presente pesquisa está delineada pela proble...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83154</th>\n",
       "      <td>LOC</td>\n",
       "      <td>uso_de_alcool_e_problemas_relacionados_no_povo...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Com desenho sequencial exploratório, utilizou-...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83386</th>\n",
       "      <td>LOC</td>\n",
       "      <td>usos_sociais_da_leitura_e_da_escrita_em_uma_co...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Esta pesquisa buscou investigar os usos sociai...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83784</th>\n",
       "      <td>LOC</td>\n",
       "      <td>vem_que_hoje_e_dia_de_festa_corpo_territorio_e...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Este estudo apresenta um mergulho imagético e ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85132</th>\n",
       "      <td>LOC</td>\n",
       "      <td>xi_honha_e_agora_vamos_ser_pesquisadores_um_fa...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Esta tese é uma experiência concreta de um faz...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes                                               URIs Labels  \\\n",
       "1437      LOC  a_construcao_de_sentidos_no_reinado_do_rosario...     MG   \n",
       "2932      LOC  a_educacao_quilombola_na_comunidade_colonia_do...     MG   \n",
       "3680      LOC  a_festa_de_nossa_senhora_do_rosario_de_paula_c...     MG   \n",
       "4046      LOC  a_formao_de_professores_da_educao_bsica_a_real...     MG   \n",
       "4717      LOC  a_imagem_do_negro_em_manuais_para_o_professor_...     MG   \n",
       "...       ...                                                ...    ...   \n",
       "83076     LOC  urdiduras_museais_e_tramas_expositivas_no_muse...     MG   \n",
       "83154     LOC  uso_de_alcool_e_problemas_relacionados_no_povo...     MG   \n",
       "83386     LOC  usos_sociais_da_leitura_e_da_escrita_em_uma_co...     MG   \n",
       "83784     LOC  vem_que_hoje_e_dia_de_festa_corpo_territorio_e...     MG   \n",
       "85132     LOC  xi_honha_e_agora_vamos_ser_pesquisadores_um_fa...     MG   \n",
       "\n",
       "                                                Abstract Language  \n",
       "1437   Atribuímos sentidos e significados em cada enu...       pt  \n",
       "2932   A pesquisa intitulada “A Educação Quilombola n...       pt  \n",
       "3680   Os diferentes períodos de colonização, somando...       pt  \n",
       "4046   Em todas as partes que comp?em a obra, consta ...       pt  \n",
       "4717   No presente estudo, visamos investigar como se...       pt  \n",
       "...                                                  ...      ...  \n",
       "83076  A presente pesquisa está delineada pela proble...       pt  \n",
       "83154  Com desenho sequencial exploratório, utilizou-...       pt  \n",
       "83386  Esta pesquisa buscou investigar os usos sociai...       pt  \n",
       "83784  Este estudo apresenta um mergulho imagético e ...       pt  \n",
       "85132  Esta tese é uma experiência concreta de um faz...       pt  \n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'MG'\n",
    "sample_thesis = theses_df[(theses_df['Classes'] == classe) & (theses_df['Labels'] == l)]#.sample(1)\n",
    "sample_thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['na_batida_do_corpo_na_pisada_do_canta_inscricoes_poeticas_no_coco_cearense_e_candombe_mineiro']\n",
      " a segunda, o candombe mineiro da comunidade da Lapinha, Lagoa Santa (MG). Essas culturas orais distintas são comparadas através das perform\n",
      "Grande parte das tradições de cantos dançados encontradas no Brasil resulta do continuum inscrito pelos palimpsestos de matrizes africanas que tiveram que ser ressignificadas. Estudos têm revelado, nos últimos tempos, que a maioria das manifestações afrobrasileiras é ramificada na grande família linguística e cultural banto, constituída por trezentas línguas muito semelhantes e faladas em vinte e um países. No solo brasileiro muitos africanos protagonizaram várias e complexas etnogêneses sucessivamente reiniciadas ao longo dos últimos três séculos: formas diversas de culto aos antepassados, cosmologias de vidas distintas do sistema europeu dominante, com valores, costumes, crenças e tradições que constituíram a cultura afrobrasileira. Porém, é importante ressaltar que as convergências e trocas culturais, porque originárias de diferentes agrupamentos e referências etnolinguísticas, realizadas ao longo de nossa história, estão marcadas por conflitos e negociações e, muitas delas, manifestas também a partir de diferentes tentativas de diálogo, nem sempre amistosas. Estudamos duas culturas de cantos dançados encontradas no Nordeste e Sudeste do país: a primeira, o coco dançado, localizada no Cariri cearense; a segunda, o candombe mineiro da comunidade da Lapinha, Lagoa Santa (MG). Essas culturas orais distintas são comparadas através das performances dos cantos dançados, que\n"
     ]
    }
   ],
   "source": [
    "sample_thesis2 = sample_thesis.sample(1)\n",
    "print(sample_thesis2['URIs'].values)\n",
    "position = sample_thesis2['Abstract'].values[0].find(l)\n",
    "print(sample_thesis2['Abstract'].values[0][position-70:position+70])\n",
    "print(sample_thesis2['Abstract'].values[0][:position+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>URIs</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>LOC</td>\n",
       "      <td>http://dbpedia.org/resource/Minas_Gerais</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>Minas Gerais ([ˈminɐz ʒeˈɾajs]) is a state in ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12847</th>\n",
       "      <td>LOC</td>\n",
       "      <td>http://dbpedia.org/resource/Minas_Gerais</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>Minas Gerais é uma das 27 unidades federativas...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes                                      URIs        Labels  \\\n",
       "10025     LOC  http://dbpedia.org/resource/Minas_Gerais  Minas Gerais   \n",
       "12847     LOC  http://dbpedia.org/resource/Minas_Gerais  Minas Gerais   \n",
       "\n",
       "                                                Abstract Language  \n",
       "10025  Minas Gerais ([ˈminɐz ʒeˈɾajs]) is a state in ...       en  \n",
       "12847  Minas Gerais é uma das 27 unidades federativas...       pt  "
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'Minas Gerais'\n",
    "dbpedia_df[(dbpedia_df['Classes'] == classe) & (dbpedia_df['Labels'] == l)]\n",
    "#dbpedia_df[(dbpedia_df['URIs'] == 'http://dbpedia.org/resource/Walter_Lippmann')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://dbpedia.org/resource/Rio_de_Janeiro_(state)'"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_df.loc[8842]['URIs']\n",
    "#dbpedia_df.loc[8842]['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_lg\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'IndigenousSlavery'\n",
    "conn = stardog.Connection(database_name, **connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thesis</th>\n",
       "      <th>abstract</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:stardog:api:_as_negras_estao_chegando_pra_...</td>\n",
       "      <td>Esta pesquisa dedicou-se ao estudo das produçõ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:stardog:api:_e_teko_e_arandu_e_producao_de...</td>\n",
       "      <td>Esta pesquisa persegue pistas na produção de s...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag:stardog:api:_nos_aqui_e_o_espaco_dos_sem_v...</td>\n",
       "      <td>This article deals with families and schools i...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag:stardog:api:_ou_entao_e_influencia_da_cor_...</td>\n",
       "      <td>This thesis has as main objective to understan...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag:stardog:api:_para_conter_os_pretos_debates...</td>\n",
       "      <td>The purpose of this research is to understand ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>tag:stardog:api:137_anos_de_sempre_um_capitulo...</td>\n",
       "      <td>Dissertação (mestrado) - Universidade Federal ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>tag:stardog:api:1923_investigacao_sobre_a_exis...</td>\n",
       "      <td>In 1923, the Clube de Regatas Vasco da Gama ta...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>tag:stardog:api:1958_o_ano_que_nao_terminou_me...</td>\n",
       "      <td>This inquiry treats of the black dance nights ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13851</th>\n",
       "      <td>tag:stardog:api:4_mulheres_e_o_encontro_na_edu...</td>\n",
       "      <td>How to produce existence in a systematic produ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>tag:stardog:api:7_ensayos_de_interpretacion_de...</td>\n",
       "      <td>Tese (Doutorado em Estudos Comparados sobre as...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  thesis  \\\n",
       "0      tag:stardog:api:_as_negras_estao_chegando_pra_...   \n",
       "1      tag:stardog:api:_e_teko_e_arandu_e_producao_de...   \n",
       "2      tag:stardog:api:_nos_aqui_e_o_espaco_dos_sem_v...   \n",
       "3      tag:stardog:api:_ou_entao_e_influencia_da_cor_...   \n",
       "4      tag:stardog:api:_para_conter_os_pretos_debates...   \n",
       "...                                                  ...   \n",
       "13848  tag:stardog:api:137_anos_de_sempre_um_capitulo...   \n",
       "13849  tag:stardog:api:1923_investigacao_sobre_a_exis...   \n",
       "13850  tag:stardog:api:1958_o_ano_que_nao_terminou_me...   \n",
       "13851  tag:stardog:api:4_mulheres_e_o_encontro_na_edu...   \n",
       "13852  tag:stardog:api:7_ensayos_de_interpretacion_de...   \n",
       "\n",
       "                                                abstract lang  \n",
       "0      Esta pesquisa dedicou-se ao estudo das produçõ...   pt  \n",
       "1      Esta pesquisa persegue pistas na produção de s...   pt  \n",
       "2      This article deals with families and schools i...   en  \n",
       "3      This thesis has as main objective to understan...   en  \n",
       "4      The purpose of this research is to understand ...   en  \n",
       "...                                                  ...  ...  \n",
       "13848  Dissertação (mestrado) - Universidade Federal ...   pt  \n",
       "13849  In 1923, the Clube de Regatas Vasco da Gama ta...   en  \n",
       "13850  This inquiry treats of the black dance nights ...   en  \n",
       "13851  How to produce existence in a systematic produ...   en  \n",
       "13852  Tese (Doutorado em Estudos Comparados sobre as...   pt  \n",
       "\n",
       "[13853 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query que busca as teses e os seus abstracts. Foi incluído um filtro para buscar apenas \n",
    "# os abstract em português, inglês ou em outra língua\n",
    "query = \"\"\"\n",
    "SELECT ?thesis ?abstract (lang(?abstract) AS ?lang) WHERE {\n",
    "  ?thesis a <http://purl.org/ontology/bibo/Thesis>.\n",
    "  ?thesis <http://purl.org/ontology/bibo/abstract> ?abstract.\n",
    "  FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "  \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# FILTER (langMatches(lang(?abstract),\"pt\"))\n",
    "# FILTER (langMatches(lang(?abstract),\"en\"))\n",
    "# FILTER (lang(?abstract) NOT IN(\"pt\", \"en\"))\n",
    "# LIMIT 20\n",
    "\n",
    "csv_results = conn.select(query, content_type='text/csv')\n",
    "thesis_abstract = pd.read_csv(io.BytesIO(csv_results))\n",
    "thesis_abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraíndo as entidades dos abstracts\n",
    "\n",
    "#Carregando os modelos SpaCy para inglês e português \n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "nlp_pt = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "#Dicionário que receberá as instâncias de cada tese\n",
    "instances_dic = {}\n",
    "\n",
    "for n in range(len(thesis_abstract)):\n",
    "\n",
    "    # Processando os abstracts em português\n",
    "    if thesis_abstract['lang'][n] == 'pt':\n",
    "\n",
    "        doc_pt = nlp_pt(str(thesis_abstract['abstract'][n]))\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        orgs = []\n",
    "        for ent in doc_pt.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(ent)\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(ent)\n",
    "            if ent.label_ == \"ORG\":\n",
    "                orgs.append(ent)\n",
    "\n",
    "        instances_dic[thesis_abstract['thesis'][n].replace('tag:stardog:api:','')] = {'PER':persons, 'LOC':gpes, 'ORG':orgs, 'lang': 'pt'}\n",
    "\n",
    "    # Processando os abstracts em inglês\n",
    "    if thesis_abstract['lang'][n] == 'en':\n",
    "\n",
    "        doc_en = nlp_en(str(thesis_abstract['abstract'][n]))\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        orgs = []\n",
    "        for ent in doc_en.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                persons.append(ent)\n",
    "            if ent.label_ == \"GPE\":\n",
    "                gpes.append(ent)\n",
    "            if ent.label_ == \"ORG\":\n",
    "                orgs.append(ent)\n",
    "\n",
    "        instances_dic[thesis_abstract['thesis'][n].replace('tag:stardog:api:','')] = {'PER':persons, 'LOC':gpes, 'ORG':orgs, 'lang': 'en'}\n",
    "\n",
    "    if n%500 == 499:\n",
    "        print(n, \" teses processadas.\")\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para uma lista de entidades verificar se são a mesma instância e qual o termo mais comum para representá-las\n",
    "\n",
    "def entidades_consolidadas(list_ent, th):\n",
    "    \n",
    "    if list_ent == []:\n",
    "        return None\n",
    "\n",
    "    # lista com os vetores das entidades\n",
    "  \n",
    "    list_vectors = np.array([i.vector for i in list_ent])\n",
    "\n",
    "    #clusterizando os vetores de acordo com threshold th\n",
    "    clustering = DBSCAN(eps=1-th, min_samples=1, metric='cosine').fit(list_vectors)\n",
    "\n",
    "    #processnado os clusters \n",
    "    ents_dic ={}\n",
    "\n",
    "    for i in set(clustering.labels_):\n",
    "        clus_index = np.where(clustering.labels_ == i)[0]\n",
    "        label = []\n",
    "        vec = []\n",
    "        \n",
    "        for c in clus_index:\n",
    "            vec.append(list_ent[c].vector)\n",
    "            label.append(list_ent[c].text)\n",
    "\n",
    "        ents_dic[max(set(label), key=label.count)] = {'labels': list(set(label)), 'vector': np.average(vec, axis=0).tolist()}\n",
    "\n",
    "    return ents_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprocessando as listas de entidades para eliminar as entidades duplicadas de cada tese e obtendo o vetor de cada entidade\n",
    "th = 0.90\n",
    "\n",
    "i = 0\n",
    "for key in instances_dic:\n",
    "    for type_ent in instances_dic[key]:\n",
    "        if type_ent != 'lang':\n",
    "            list_ent = instances_dic[key][type_ent]\n",
    "            instances_dic[key][type_ent] = entidades_consolidadas(list_ent, th)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o dicionário com a lista de entidades mencionadas no abstract\n",
    "#with open('data/abstract_NER.json', 'w') as fp:\n",
    "#    json.dump(instances_dic, fp)\n",
    "\n",
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/abstract_NER.json') as fp:\n",
    "    instances_dic = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Clusterizando as entidades em Português\n",
    "\n",
    "per_list = []\n",
    "per_label_list = []\n",
    "per_vector_list = []\n",
    "per_key_list = []\n",
    "\n",
    "for key in instances_dic:\n",
    "    if instances_dic[key]['lang'] == 'pt':\n",
    "        if instances_dic[key]['PER'] != None:\n",
    "            for p in instances_dic[key]['PER']:\n",
    "                per_list.append(p)\n",
    "                per_label_list.append(instances_dic[key]['PER'][p]['labels'])\n",
    "                per_vector_list.append(instances_dic[key]['PER'][p]['vector'])\n",
    "                per_key_list.append(key)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"th =0.98\n",
    "clustering_per = DBSCAN(eps=1-th, min_samples=1, metric='cosine').fit(per_vector_list)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"per_citadas = pd.DataFrame({'teses': per_key_list, 'person': per_list, 'labels' :per_label_list, 'cluster': clustering_per.labels_})\\nper_citadas[per_citadas['cluster'] == 140]\\n#len(set(clustering_per.labels_))\\n#per_label_list[[clustering_per.labels_ == 0]]\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"per_citadas = pd.DataFrame({'teses': per_key_list, 'person': per_list, 'labels' :per_label_list, 'cluster': clustering_per.labels_})\n",
    "per_citadas[per_citadas['cluster'] == 140]\n",
    "#len(set(clustering_per.labels_))\n",
    "#per_label_list[[clustering_per.labels_ == 0]]\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando dados da DBPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de labels de ORG:  14472\n",
      "Total de labels de PER:  12564\n",
      "Total de labels de LOC:  14126\n"
     ]
    }
   ],
   "source": [
    "# Coletando todas as labels das entidades extraídas dos abstracts\n",
    "\n",
    "people_labels = []\n",
    "local_labels = []\n",
    "org_labels = []\n",
    "\n",
    "for key in instances_dic:\n",
    "    for type_ent in instances_dic[key]:\n",
    "\n",
    "        list_ent = instances_dic[key][type_ent]\n",
    "        if list_ent != None:\n",
    "            for ent in list_ent:\n",
    "                if type_ent == 'PER':\n",
    "                    people_labels = people_labels + list_ent[ent]['labels']\n",
    "                if type_ent == 'LOC':\n",
    "                    local_labels = local_labels + list_ent[ent]['labels']\n",
    "                if type_ent == 'ORG':\n",
    "                    org_labels = org_labels + list_ent[ent]['labels']\n",
    "\n",
    "people_labels = list(set(people_labels))\n",
    "local_labels = list(set(local_labels))\n",
    "org_labels = list(set(org_labels))\n",
    "\n",
    "print('Total de labels de ORG: ', len(org_labels))\n",
    "print('Total de labels de PER: ', len(people_labels))\n",
    "print('Total de labels de LOC: ', len(local_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para buscar as labels na DBPEDIA. A funcao retorna as URI a abstracts de entidades que estao registradas na DBPEDIA.\n",
    "# sc_th é o threshold do score de busca para uma URI da DBPEDIA ser retornada.\n",
    "def DBPEDIA_search(labels, classe, sc_th):\n",
    "\n",
    "    dbpedia_ent = []\n",
    "\n",
    "    for ent_bruto in labels:\n",
    "        # processando as labels para ser buscada na DBPEDIA\n",
    "        ent = re.sub('[^a-zA-Z0-9_ ]', '', unidecode(ent_bruto)).strip()\n",
    "        ent = ent.replace(' and ', ' ').replace(' or ', ' ')\n",
    "        ent = re.sub(\"\\s\\s+\" , \" \", ent)\n",
    "        \n",
    "        ent_vector = \"'\" + ent.replace(\" \", \"', '\") + \"'\"\n",
    "        ent_contains = ent.replace(\" \", \" AND \")\n",
    "\n",
    "        # Sparql query para fazer busca em linguagem natural e retornar os resultados rankeados pelo score ?sc.\n",
    "        query = \"\"\" \n",
    "            define input:ifp \"IFP_OFF\"  \n",
    "            select ?s1 as ?c1, (bif:search_excerpt (bif:vector (\"\"\" + ent_vector + \"\"\"), ?o1)) as ?c2, ?sc, ?rank, ?g, ?abstract \n",
    "            where \n",
    "            { \n",
    "            select ?s1, (?sc * 3e-1) as ?sc, ?o1, (sql:rnk_scale (<LONG::IRI_RANK> (?s1))) as ?rank, ?g, ?abstract \n",
    "            \n",
    "            where  \n",
    "            { \n",
    "                quad map virtrdf:DefaultQuadMap \n",
    "                { \n",
    "                graph ?g \n",
    "                { \n",
    "                    ?s1 ?s1textp ?o1 .\n",
    "                    ?o1 bif:contains  '(\"\"\" + ent_contains + \"\"\")'  option (score ?sc)  .\n",
    "                    ?s1 a \"\"\" + classe + \"\"\".\n",
    "                    ?s1 dbo:abstract ?abstract.\n",
    "                    FILTER (lang(?abstract) IN(\"pt\", \"en\"))\n",
    "                }\n",
    "                } \n",
    "            }\n",
    "\n",
    "            order by desc (?sc * 3e-1 + sql:rnk_scale (<LONG::IRI_RANK> (?s1)))  limit 5  offset 0 \n",
    "            } \n",
    "            \"\"\"\n",
    "        # URL da DBPEDIA e request\n",
    "        url = 'http://dbpedia.org/sparql'\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "            data = r.json()\n",
    "\n",
    "            # processando os resultados obtidos\n",
    "            if data['results']['bindings'] != []:\n",
    "\n",
    "                bindings = []\n",
    "                for r in data['results']['bindings']:\n",
    "                    if float(r['sc']['value']) > sc_th:\n",
    "                        bindings.append((ent_bruto, r['sc']['value'], r['c1']['value'], r['abstract']['value']))\n",
    "                \n",
    "                dbpedia_ent = dbpedia_ent + list(set(bindings))\n",
    "        except:\n",
    "            print('Erro ao buscar a label: ', ent_bruto)\n",
    "    return dbpedia_ent  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe uma lista de labels de uma determinada classe, \n",
    "# busca essas labels na DBPEDIA e salva as tuplas com as labels e abstracts no diretório desejado.\n",
    "\n",
    "def coletando_dbpedia_tuplas(labels, classe, path):\n",
    "    # Lista recebe as tuplas\n",
    "    db_tupla = []\n",
    "    #Bach em que as tuplas serão salvas\n",
    "    step = 100\n",
    "    for n in range(0, len(labels), step):\n",
    "        # Busca as labels usando a funcão DBPEDIA_search\n",
    "        ex_DB = DBPEDIA_search(labels[n:n+step], classe, 3.0)\n",
    "        \n",
    "        for ex in ex_DB:\n",
    "            db_tupla.append((ex[2], ex[3]))\n",
    "        # Elimina as tuplas repetidas\n",
    "        db_tupla = list(set(db_tupla))\n",
    "\n",
    "        # Salvando o dicionário com a lista de entidades mencionadas no abstract\n",
    "        with open(path, 'w') as fp:\n",
    "            json.dump(db_tupla, fp)\n",
    "        print(n+step, '- Total de tuplas: ', len(db_tupla))\n",
    "\n",
    "    return db_tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(people_labels, 'dbo:Person', 'data/DBPEDIA_people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(local_labels, 'dbo:Place', 'data/DBPEDIA_locals.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletando_dbpedia_tuplas(org_labels, 'dbo:Organisation', 'data/DBPEDIA_orgs.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as triplas e carregando no knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixos\n",
    "prefixos = \"\"\" @prefix ns: <http://www.w3.org/2003/06/sw-vocab-status/ns#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
    "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "@prefix vann: <http://purl.org/vocab/vann/> .\n",
    "@prefix event: <http://purl.org/NET/c4dm/event.owl#> .\n",
    "@prefix prism: <http://prismstandard.org/namespaces/1.2/basic/> .\n",
    "@prefix terms: <http://purl.org/dc/terms/> .\n",
    "@prefix schema: <http://schemas.talis.com/2005/address/schema#> .\n",
    "@prefix status: <http://purl.org/ontology/bibo/status/> .\n",
    "@prefix degrees: <http://purl.org/ontology/bibo/degrees/> .\n",
    "@prefix stardog: <tag:stardog:api:> .\n",
    "@base <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe os prefixos e triplas e as carrega à base de dados\n",
    "def add_triplas_to_stardog(prefixos, triplas):\n",
    "\n",
    "    # Incluindo prefixos às triplas\n",
    "    triplas = prefixos + \" \" + triplas\n",
    "\n",
    "    ### Connect to the Stardog database\n",
    "    database_name = 'IndigenousSlavery'\n",
    "    conn = stardog.Connection(database_name, **connection_details)\n",
    "\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.Raw(triplas, 'text/turtle'))\n",
    "    conn.commit() # commit the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_people.json') as fp:\n",
    "    dbpedia_people = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando pessoas\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_people:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type foaf:Person.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_locals.json') as fp:\n",
    "    dbpedia_locals = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando locais\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_locals:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type <https://schema.org/Place>.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "with open('data/DBPEDIA_orgs.json') as fp:\n",
    "    dbpedia_orgs = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando organizacões\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for resource in dbpedia_orgs:\n",
    "    tripla = \"\"\"\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> rdf:type bibo:dbpedia.\n",
    "    <\"\"\" + resource[0] + \"\"\"> rdf:type foaf:Organization.\n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> terms:subject <\"\"\" + resource[0] + \"\"\">. \n",
    "    <\"\"\" + resource[0].replace('/resource/', '/page/') + \"\"\"> bibo:abstract '\"\"\" + str(resource[1]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + detect(resource[1]) + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pystardog\n",
    "#%pip install dotenv\n",
    "#%pip install Unidecode\n",
    "#%pip install langdetect\n",
    "#%pip install -U pip setuptools wheel\n",
    "#%pip install -U spacy\n",
    "#!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stardog\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import requests, uuid, json\n",
    "import time\n",
    "import json\n",
    "#from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new database in Stardog\n",
    "\n",
    "Drop the database if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_name = 'IndigenousSlavery'\n",
    "\n",
    "#with stardog.Admin(**connection_details) as admin:\n",
    "#   if database_name in [db.name for db in admin.databases()]:\n",
    "#       admin.database(database_name).drop()\n",
    "#   db = admin.new_database(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Opcao - Adicionar o schema via Stardog Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados do arquivo CSV\n",
    "data = pd.read_csv(\"data/BDTD_Consolidado.csv\")\n",
    "data = data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando o texto em turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixos\n",
    "prefixos = \"\"\" @prefix ns: <http://www.w3.org/2003/06/sw-vocab-status/ns#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
    "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "@prefix vann: <http://purl.org/vocab/vann/> .\n",
    "@prefix event: <http://purl.org/NET/c4dm/event.owl#> .\n",
    "@prefix prism: <http://prismstandard.org/namespaces/1.2/basic/> .\n",
    "@prefix terms: <http://purl.org/dc/terms/> .\n",
    "@prefix schema: <http://schemas.talis.com/2005/address/schema#> .\n",
    "@prefix status: <http://purl.org/ontology/bibo/status/> .\n",
    "@prefix degrees: <http://purl.org/ontology/bibo/degrees/> .\n",
    "@prefix stardog: <tag:stardog:api:> .\n",
    "@base <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando com o banco e adicionando as triplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe os prefixos e triplas e as carrega à base de dados\n",
    "def add_triplas_to_stardog(prefixos, triplas):\n",
    "\n",
    "    # Incluindo prefixos às triplas\n",
    "    triplas = prefixos + \" \" + triplas\n",
    "\n",
    "    ### Connect to the Stardog database\n",
    "    database_name = 'IndigenousSlavery'\n",
    "    conn = stardog.Connection(database_name, **connection_details)\n",
    "\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.Raw(triplas, 'text/turtle'))\n",
    "    conn.commit() # commit the transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando e processando os dados das Teses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe uma string e a limpar para ficar no formato aceitável para uma URI\n",
    "def process_uri(x):\n",
    "    return (re.sub('[^a-zA-Z0-9_ ]', '',\n",
    "            unidecode(x.strip())\n",
    "                        .replace(\" \", \"_\")\n",
    "                        .replace(\"[\",\"\")\n",
    "                        .replace(\"]\",\"\")\n",
    "                        .replace(\"?\",\"\")\n",
    "                        .replace(\"'\",\"\")\n",
    "                        .lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_12180\\3317037659.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4] = data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4].apply(lambda x: 2000 + x if x < 25 else 1900 + x)\n"
     ]
    }
   ],
   "source": [
    "titulo = data['Título']\n",
    "thesis_uri = data['Título'].apply(lambda x: process_uri(x))\n",
    "#Alterando os anos com dois dígitos para 4 dígitos\n",
    "data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4] = data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4].apply(lambda x: 2000 + x if x < 25 else 1900 + x)\n",
    "ano = data['Ano de defesa']\n",
    "link = data['Link de acesso']\n",
    "referencia = data['Referência Bibliográfica']\n",
    "resumo = data['Resumo']\n",
    "resumo_pt = data['Resumo em Português']\n",
    "resumo_en = data['Resumo em Inglês']\n",
    "resumo_lang = data['Resumo'].apply(lambda x: detect(str(x) + \"sem texto\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" rdf:type bibo:Thesis.\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:title '\"\"\" + titulo[m].replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"\"\"'.\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:created '\"\"\" + str(ano[m]) +  \"\"\"'^^xsd:gYear.\n",
    "    \"\"\"\n",
    "    if link[m].startswith(\"http\"):\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:repository '\"\"\" + link[m].replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'. \"\"\"\n",
    "\n",
    "    if referencia[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:identifier '\"\"\" + referencia[m].replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'. \"\"\"\n",
    "\n",
    "    if resumo[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + resumo_lang[m] + \"\"\". \"\"\"\n",
    "    \n",
    "    if resumo_pt[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo_pt[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "\n",
    "    if resumo_en[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo_en[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@en. \"\"\"\n",
    "\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + thesis_uri[m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando dados e propriedades das pessoas (\"Person\") - Autores, Orientadores e Membros da Banca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_person(person_column):\n",
    "\n",
    "    column_raw = person_column.apply(lambda x: x.split(\"',\")).replace(\"['\", \"\")\n",
    "\n",
    "    column_raw_list = []\n",
    "    for i in column_raw:\n",
    "        for person in i:\n",
    "            if person != '[]':\n",
    "                person = person.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"\", \"\").split(\",\")\n",
    "                column_raw_list.append(person)\n",
    "\n",
    "    column_raw_list = pd.Series(column_raw_list) \n",
    "\n",
    "    #Último Sobrenome   \n",
    "    column_family_name = column_raw_list.apply(lambda x: x[0].strip().replace(u'\\\\', u' '))\n",
    "\n",
    "    # Primeiros nomes\n",
    "    column_given_name = column_raw_list.apply(lambda x: x[1].strip().replace(u'\\\\', u' ') if len(x) > 1 else \"\")\n",
    "\n",
    "    # Unindo nome e sobrenome\n",
    "    column_uri = (column_given_name + \"_\" + column_family_name) \n",
    "\n",
    "    #substituindo espaco por \"_\", retirando diacrítico e colocando em minúscula\n",
    "    column_uri = column_uri.apply(lambda x: process_uri(x))\n",
    "\n",
    "    return (column_raw_list, column_family_name, column_given_name, column_uri)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando colunas\n",
    "autor_raw_list, autor_family_name, autor_given_name, autor_uri = clean_person(data[\"Autor(a)\"])\n",
    "orientador_raw_list, orientador_family_name, orientador_given_name, orientador_uri = clean_person(data['Orientadores'])\n",
    "banca_raw_list, banca_family_name, banca_given_name, banca_uri = clean_person(data['Membros da banca'])\n",
    "\n",
    "# Unindo as colunas com informacões de pessoas\n",
    "family_name = pd.concat([autor_family_name, orientador_family_name, banca_family_name],  ignore_index=True)\n",
    "given_name = pd.concat([autor_given_name, orientador_given_name, banca_given_name],  ignore_index=True)\n",
    "name_uri = pd.concat([autor_uri, orientador_uri, banca_uri],  ignore_index=True)\n",
    "\n",
    "# Removendo duplicados\n",
    "name_uri = name_uri.drop_duplicates()\n",
    "uniq_index = name_uri.index\n",
    "family_name = family_name[uniq_index]\n",
    "given_name = given_name[uniq_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in uniq_index:\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" rdf:type foaf:Person.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" rdfs:label '\"\"\" + family_name[m].replace(\"'\",\"\") + \"\"\", \"\"\"+ given_name[m].replace(\"'\",\"\") + \"\"\"'.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" foaf:givenname '\"\"\" + given_name[m].strip().replace(\"'\",\"\") + \"\"\"'.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" foaf:family_name '\"\"\" + family_name[m].replace(\"'\",\"\") + \"\"\"'.\n",
    "    \"\"\"\n",
    "\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + name_uri[m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding autor relationship between thesis and its author.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:author stardog:\"\"\" + autor_uri[m] +  \"\"\".\"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding autor relationship between thesis and its advisors and opponents.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    person_uris = clean_person(data['Orientadores'][m:m+1])[3]\n",
    "    for person_uri in person_uris:\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:advisor stardog:\"\"\" + person_uri +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    person_uris = clean_person(data['Membros da banca'][m:m+1])[3]\n",
    "    for person_uri in person_uris:\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:opponent stardog:\"\"\" + person_uri +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando dados e propriedades da instituicao de pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as triplas das instituicões\n",
    "university = data[['Instituição de defesa', 'Sigla da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(university)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdf:type bibo:University. \n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdfs:label '\"\"\" + university['Instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" bibo:acronym '\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\"'.\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as triplas dos departamentos e programas\n",
    "departamento = data[data['Departamento da instituição de defesa'] != 'Não informado pela instituição']\n",
    "departamento = departamento[['Sigla da instituição de defesa', 'Departamento da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "departamento['uri'] = departamento['Sigla da instituição de defesa'] + '_' + departamento['Departamento da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "\n",
    "programa = data[data['Programa de Pós-Graduação da instituição de defesa'] != 'Não informado pela instituição']\n",
    "programa = programa[['Sigla da instituição de defesa', 'Programa de Pós-Graduação da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "programa['uri'] = programa['Sigla da instituição de defesa'] + '_' + programa['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(departamento)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdf:type bibo:Department. \n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdfs:label '\"\"\" + departamento['Departamento da instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000050> stardog:\"\"\" + departamento['Sigla da instituição de defesa'][m] + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "for m in range(len(programa)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" rdf:type bibo:Program. \n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" rdfs:label '\"\"\" + programa['Programa de Pós-Graduação da instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000050> stardog:\"\"\" + programa['Sigla da instituição de defesa'][m] + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdf:type owl:NamedIndividual.\n",
    "# stardog:\"\"\" + programa['uri'][m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses às organizacoes (univeridades, departamentos e programas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_17376\\1663232402.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  publishers['dep_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Departamento da instituição de defesa'].apply(process_uri)\n",
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_17376\\1663232402.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  publishers['program_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n"
     ]
    }
   ],
   "source": [
    "publishers = data[['Sigla da instituição de defesa', 'Departamento da instituição de defesa', 'Programa de Pós-Graduação da instituição de defesa']] \n",
    "publishers['dep_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Departamento da instituição de defesa'].apply(process_uri)\n",
    "publishers['program_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    if publishers['Sigla da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['Sigla da instituição de defesa'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if publishers['Departamento da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['dep_uri'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if publishers['Programa de Pós-Graduação da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['program_uri'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando os assuntos e áreas do conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando as listas únicas (SET) com assuntos\n",
    "# Inglês\n",
    "assunto_en_v1 = data['Assuntos em inglês'].apply(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")).values\n",
    "\n",
    "assunto_en_v2 = []\n",
    "for i in assunto_en_v1:\n",
    "    assunto_en_v2 = assunto_en_v2 + i\n",
    "\n",
    "assunto_en_v3 = []\n",
    "for i in assunto_en_v2:\n",
    "    assunto_en_v3.append(i.strip())\n",
    "assunto_en = set(assunto_en_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Português\n",
    "assunto_pt_v1 = data['Assuntos em português'].apply(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")).values\n",
    "\n",
    "assunto_pt_v2 = []\n",
    "for i in assunto_pt_v1:\n",
    "    assunto_pt_v2 = assunto_pt_v2 + i\n",
    "\n",
    "assunto_pt_v3 = []\n",
    "for i in assunto_pt_v2:\n",
    "    assunto_pt_v3.append(i.strip())\n",
    "assunto_pt = set(assunto_pt_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para encontrar o lemma da palavra em inglês e formar a URI do assunto\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def lemma(word):\n",
    "    doc = nlp(word)\n",
    "    uri = ''\n",
    "    for token in doc:\n",
    "        uri = uri + token.lemma_ + ' '\n",
    "    return (process_uri(uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para traduzir os assuntos em português para inglês\n",
    "\n",
    "# Add your key and endpoint\n",
    "key = os.getenv('TRANSLATOR_KEY') #\"<your-translator-key>\"\n",
    "endpoint = os.getenv('TRANSLATOR_ENDPOINT') #\"https://api.cognitive.microsofttranslator.com\"\n",
    "\n",
    "# location, also known as region.\n",
    "# required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
    "location = os.getenv('TRANSLATOR_LOCATION') #\"<YOUR-RESOURCE-LOCATION>\"\n",
    "\n",
    "path = '/translate'\n",
    "constructed_url = endpoint + path\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'pt',\n",
    "    'to': ['en']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    # location required if you're using a multi-service or regional (not global) resource.\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "# You can pass more than one object in body.\n",
    "#body = [{\n",
    "#    'text': 'I would really like to drive your car around the block a few times!'\n",
    "#}]\n",
    "\n",
    "def translate_pt_en(word):\n",
    "    body = [{'text': word}]\n",
    "\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "    return (response[0]['translations'][0]['text'])\n",
    "    #print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário com assunto_URI e termos em inglês\n",
    "uri_dic = {}\n",
    "\n",
    "for word in assunto_en:\n",
    "    assunto_uri = lemma(word)\n",
    "    if assunto_uri not in uri_dic:\n",
    "        uri_dic[assunto_uri] = {'en': [word], 'pt': []}\n",
    "    else:\n",
    "        uri_dic[assunto_uri]['en'] = uri_dic[assunto_uri]['en'] + [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário com assunto_URI e termos em português\n",
    "n = 0\n",
    "for word in assunto_pt:\n",
    "    n = n + 1\n",
    "    if n % 100 == 0:\n",
    "        time.sleep(2.5)\n",
    "    assunto_translate = translate_pt_en(word)\n",
    "    assunto_uri = lemma(assunto_translate)\n",
    "    if assunto_uri not in uri_dic:\n",
    "        uri_dic[assunto_uri] = {'en': [assunto_translate], 'pt': [word]}\n",
    "    else:\n",
    "        uri_dic[assunto_uri]['en'] = list(set(uri_dic[assunto_uri]['en'] + [assunto_translate]))\n",
    "        uri_dic[assunto_uri]['pt'] = uri_dic[assunto_uri]['pt'] + [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/assunto_dict.json', 'w') as fp:\n",
    "    json.dump(uri_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lista em de assuntos em português, possui muito termos em inglês porque os cadastros estao misturados. \n",
    "# Vamos verificar se um termo em portugês já existe na lista em ingles e exclui-los\n",
    "\n",
    "for uri in uri_dic:\n",
    "    for assunto_pt in uri_dic[uri]['pt']:\n",
    "        if assunto_pt in uri_dic[uri]['en']:\n",
    "            uri_dic[uri]['pt'].remove(assunto_pt)\n",
    "\n",
    "# Excluindo do dicionário os termos ' ' e 'Não informado pela instituição'.\n",
    "\n",
    "del uri_dic['']\n",
    "del uri_dic['_']\n",
    "del uri_dic[process_uri('Não informado pela instituição')]\n",
    "\n",
    "# save dict\n",
    "with open('data/assunto_dict.json', 'w') as fp:\n",
    "    json.dump(uri_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31000  URIs carregadas\n",
      "31117  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Carregando as triplas dos assuntos na base de dados \n",
    "\n",
    "uri_dic_keys = list(uri_dic.keys())\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in range(0, len(uri_dic_keys)):\n",
    "\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdf:type bibo:Subject.\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_pt in uri_dic[uri_dic_keys[n]]['pt']:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_pt).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_en in uri_dic[uri_dic_keys[n]]['en']:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_en).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@en. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if n%1000 == 0: \n",
    "        print (n, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (n, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses aos assuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dicionario com label apontando para as uri\n",
    "# portugues\n",
    "label_uri_pt = {}\n",
    "for uri in uri_dic:\n",
    "    for assunto_pt in uri_dic[uri]['pt']:\n",
    "        label_uri_pt[assunto_pt] = uri\n",
    "\n",
    "with open('data/assunto_uri_pt.json', 'w') as fp:\n",
    "    json.dump(label_uri_pt, fp)\n",
    "\n",
    "# inglês\n",
    "label_uri_en = {}\n",
    "for uri in uri_dic:\n",
    "    for assunto_en in uri_dic[uri]['en']:\n",
    "        label_uri_en[assunto_en] = uri\n",
    "\n",
    "with open('data/assunto_uri_en.json', 'w') as fp:\n",
    "    json.dump(label_uri_en, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "\n",
    "with open('data/assunto_dict.json') as fp:\n",
    "    uri_dic = json.load(fp)\n",
    "    \n",
    "with open('data/assunto_uri_pt.json') as fp:\n",
    "    label_uri_pt = json.load(fp)\n",
    "\n",
    "with open('data/assunto_uri_en.json') as fp:\n",
    "    label_uri_en = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000  teses carregadas\n",
      "31117  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Adding relationship between thesis and its subjects.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(0, len(thesis_uri)):\n",
    "    subj_uri = []\n",
    "    for sub in assunto_pt_v1[m]:\n",
    "        try:\n",
    "            subj_uri.append(label_uri_en[sub.strip()])\n",
    "        except:\n",
    "            subj_uri.append(label_uri_pt[sub.strip()])\n",
    "    for sub in assunto_en_v1[m]:\n",
    "        try:\n",
    "            subj_uri.append(label_uri_en[sub.strip()])\n",
    "        except:\n",
    "            subj_uri.append(label_uri_pt[sub.strip()])\n",
    "\n",
    "    for sub in set(subj_uri):\n",
    "        \n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:subject stardog:\"\"\" + sub +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if m%1000 == 0: \n",
    "        print (m, \" teses carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (m, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processando as àreas de conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as áreas não informadas pela instituicão\n",
    "AC = data['Área do conhecimento CNPq'][ data['Área do conhecimento CNPq'] != 'Não informado pela instituição']\n",
    "#Identificando as sequencias de areas únicas (todo um ramo da taxonomia)\n",
    "AC = AC.apply(lambda x: x.split('||'))\n",
    "AC_list = []\n",
    "for area in AC:\n",
    "    AC_list = AC_list + area\n",
    "AC_list = list(set(AC_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para receber o ramo da taxonomia, já processada como uri\n",
    "AC_uri_list = []\n",
    "# Dicionário para converter em URI para label\n",
    "AC_uri_dic = {}\n",
    "\n",
    "for areas in AC_list:\n",
    "    uri_area = []\n",
    "    for area in areas.split('::'):\n",
    "        area_translate = translate_pt_en(area)\n",
    "        uri_a = lemma(area_translate)\n",
    "        #uri_a = process_uri(area)\n",
    "        uri_area.append(uri_a)\n",
    "        if uri_a not in AC_uri_dic:\n",
    "            AC_uri_dic[uri_a] = [area]\n",
    "        else:\n",
    "            AC_uri_dic[uri_a] = list(set(AC_uri_dic[uri_a] + [area]))\n",
    "    AC_uri_list.append(uri_area)\n",
    "\n",
    "# Removendo o termo 'cnpq' e 'accnpq' do dicionário e das listas\n",
    "del AC_uri_dic['cnpq']\n",
    "\n",
    "new_AC_uri_list = []\n",
    "for l in AC_uri_list:\n",
    "    new_AC_uri_list.append([i for i in l if i != 'cnpq'])\n",
    "AC_uri_list = new_AC_uri_list\n",
    "\n",
    "del AC_uri_dic['accnpq']\n",
    "\n",
    "new_AC_uri_list = []\n",
    "for l in AC_uri_list:\n",
    "    new_AC_uri_list.append([i for i in l if i != 'accnpq'])\n",
    "AC_uri_list = new_AC_uri_list\n",
    "\n",
    "# Montando as tuplas com \"area do conhecimento\" has_part \"outra area do conhecimento\".\n",
    "\n",
    "tupla_has_part = []\n",
    "for areas in AC_uri_list:\n",
    "    if len(areas) > 1:\n",
    "        for n in range(len(areas)-1):\n",
    "            tupla_has_part.append((areas[n], areas[n+1]))\n",
    "\n",
    "tupla_has_part = list(set(tupla_has_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  URIs carregadas\n",
      "562  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Carregando as triplas das áreas de conhecimento na base de dados \n",
    "\n",
    "uri_dic_keys = list(AC_uri_dic.keys())\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in range(0, len(uri_dic_keys)):\n",
    "\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdf:type bibo:CNPQ.\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_pt in AC_uri_dic[uri_dic_keys[n]]:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_pt).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "        \n",
    "    if n%1000 == 0: \n",
    "        print (n, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (n, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as triplas \"hasp_part\" das áreas de conhecimento na base de dados \n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in tupla_has_part:\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + n[0] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000051> stardog:\"\"\" + n[1] + \"\"\".\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses às áreas do conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dicionario com label das áreas do conhecimento apontando para as uri\n",
    "label_area_uri = {}\n",
    "for uri in AC_uri_dic:\n",
    "    for area in AC_uri_dic[uri]:\n",
    "        label_area_uri[area] = uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000  URIs carregadas\n",
      "4000  URIs carregadas\n",
      "7000  URIs carregadas\n",
      "8000  URIs carregadas\n",
      "9000  URIs carregadas\n",
      "13000  URIs carregadas\n",
      "14000  URIs carregadas\n",
      "14401  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Adding relationship between thesis and its subjects.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in AC.index:\n",
    "    for areas in AC[m]:\n",
    "        for area in areas.split('::'):\n",
    "            try:\n",
    "                tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:subject stardog:\"\"\" + label_area_uri[area] +  \"\"\".\"\"\"\n",
    "                triplas = triplas + \" \" + tripla\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if m%1000 == 0: \n",
    "        print (m, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (m, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando as triplas conectando as teses aos degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14401  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "triplas = \"\"\"\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdf:type <http://purl.org/ontology/bibo/ThesisDegree>.\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdfs:label 'PhD degree'@en.\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdfs:label 'Doutorado'@pt.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdf:type <http://purl.org/ontology/bibo/ThesisDegree>.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdfs:label 'Master degree'@en.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdfs:label 'Mestrado'@pt.\"\"\"\n",
    "\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding relationship between thesis and degree.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(0, len(thesis_uri)):\n",
    "    if data['Tipo de documento'][m] == \"masterThesis\":\n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:degree <http://purl.org/ontology/bibo/degrees/master>.\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "    if data['Tipo de documento'][m] == \"doctoralThesis\":\n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:degree <http://purl.org/ontology/bibo/degrees/phd>.\"\"\"        \n",
    "        triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the connection\n",
    "\n",
    "Normally you would use a with statement similar to line 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.__exit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ?m ?r ?n\n",
    "WHERE {?m ?r ?n.\n",
    "}\n",
    "LIMIT 150\n",
    "\"\"\"\n",
    "\n",
    "csv_results = conn.select(query, content_type='text/csv')\n",
    "df = pd.read_csv(io.BytesIO(csv_results))\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

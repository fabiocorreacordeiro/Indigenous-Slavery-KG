{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pystardog\n",
    "#%pip install dotenv\n",
    "#%pip install Unidecode\n",
    "#%pip install langdetect\n",
    "#%pip install -U pip setuptools wheel\n",
    "#%pip install -U spacy\n",
    "#!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stardog\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import requests, uuid, json\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Stardog variables\n",
    "STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "connection_details = {\n",
    "    'endpoint': STARDOG_ENDPOINT,\n",
    "    'username': STARDOG_USERNAME,\n",
    "    'password': STARDOG_PASSWORD\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new database in Stardog\n",
    "\n",
    "Drop the database if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_name = 'IndigenousSlavery'\n",
    "\n",
    "#with stardog.Admin(**connection_details) as admin:\n",
    "#   if database_name in [db.name for db in admin.databases()]:\n",
    "#       admin.database(database_name).drop()\n",
    "#   db = admin.new_database(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Opcao - Adicionar o schema via Stardog Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autor(a)</th>\n",
       "      <th>ID Lattes do(a) autor(a)</th>\n",
       "      <th>Orientadores</th>\n",
       "      <th>ID Lattes dos orientadores</th>\n",
       "      <th>Membros da banca</th>\n",
       "      <th>ID Lattes dos membros da banca</th>\n",
       "      <th>Título</th>\n",
       "      <th>Ano de defesa</th>\n",
       "      <th>Instituição de defesa</th>\n",
       "      <th>Sigla da instituição de defesa</th>\n",
       "      <th>...</th>\n",
       "      <th>Tipos de acesso</th>\n",
       "      <th>Tipo de documento</th>\n",
       "      <th>Assuntos em português</th>\n",
       "      <th>Assuntos em inglês</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Resumo</th>\n",
       "      <th>Link de acesso</th>\n",
       "      <th>Resumo em Português</th>\n",
       "      <th>Resumo em Inglês</th>\n",
       "      <th>Referência Bibliográfica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCAS GROTH PEREIRA</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[]</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[]</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[en] AN ABOLICIONIST ARGUMENT: PENAL ABOLITION...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Pontifícia Universidade Católica do Rio de Jan...</td>\n",
       "      <td>PUC_RIO</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>doctoralThesis</td>\n",
       "      <td>['[pt] MARXISMO', '[pt] SISTEMA PUNITIVO', '[p...</td>\n",
       "      <td>['Não informado pela instituição']</td>\n",
       "      <td>por</td>\n",
       "      <td>[pt] O presente trabalho busca fazer uma retom...</td>\n",
       "      <td>https://www.maxwell.vrac.puc-rio.br/colecao.ph...</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Góes, Carolina Braz, 1988-</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[]</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[]</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Percepções dos pesquisadores da produção anima...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Universidade Estadual de Campinas (UNICAMP)</td>\n",
       "      <td>UNICAMP</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>masterThesis</td>\n",
       "      <td>['Agropecuária', 'Indústria animal', 'Animalis...</td>\n",
       "      <td>['Não informado pela instituição']</td>\n",
       "      <td>por</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://hdl.handle.net/20.500.12733/1637478||G...</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Krob, Bruna Emerim</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>['Xavier, Regina Célia Lima']</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>[]</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>\"Com a condição de servir gratuitamente a mim ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Universidade Federal do Rio Grande do Sul (UFRGS)</td>\n",
       "      <td>UFRGS</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>masterThesis</td>\n",
       "      <td>['Escravidão', 'Abolição da escravatura', 'Car...</td>\n",
       "      <td>['Slavery', 'Manumission', 'Abolition', 'Freed...</td>\n",
       "      <td>por</td>\n",
       "      <td>A presente pesquisa parte da emancipação de es...</td>\n",
       "      <td>http://hdl.handle.net/10183/148467</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pessoa, Valdirene Nunes de Santana</td>\n",
       "      <td>http://lattes.cnpq.br/4782270039388546</td>\n",
       "      <td>['Costa, Carlos Eduardo Coutinho da']</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>['Nascimento, Álvaro Pereira do', 'Silva, Alex...</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Entre as pessoas mais gradas do município: a t...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Universidade Federal Rural do Rio de Janeiro (...</td>\n",
       "      <td>UFRRJ</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>masterThesis</td>\n",
       "      <td>['Negro', 'Pós-abolição', 'Trajetória', 'Mobil...</td>\n",
       "      <td>['Post-abolition', 'Trajectory', 'Social Mobil...</td>\n",
       "      <td>por</td>\n",
       "      <td>O objeto central que baliza esta pesquisa é a ...</td>\n",
       "      <td>https://rima.ufrrj.br/jspui/handle/20.500.1440...</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>PESSOA, Valdirene Nunes de Santana. Entre as p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruz, Itan</td>\n",
       "      <td>http://lattes.cnpq.br/7904209184794040</td>\n",
       "      <td>['Negro, Antonio Luigi']</td>\n",
       "      <td>http://lattes.cnpq.br/8888819051963884||Não in...</td>\n",
       "      <td>['Negro, Antonio Luigi', 'Mata, Iacy Maia', 'P...</td>\n",
       "      <td>http://lattes.cnpq.br/8888819051963884||http:/...</td>\n",
       "      <td>Saraiva, Dantas e Cotegipe: baianismo, escravi...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Universidade Federal da Bahia (UFBA)</td>\n",
       "      <td>UFBA</td>\n",
       "      <td>...</td>\n",
       "      <td>openAccess</td>\n",
       "      <td>doctoralThesis</td>\n",
       "      <td>['Segundo Reinado', 'Baianismo', 'Política da ...</td>\n",
       "      <td>['Não informado pela instituição']</td>\n",
       "      <td>por</td>\n",
       "      <td>A presente tese investiga o baianismo e suas i...</td>\n",
       "      <td>https://repositorio.ufba.br/handle/ri/36441</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>Não informado pela instituição</td>\n",
       "      <td>CRUZ, Itan. Saraiva, Dantas e Cotegipe: baiani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Autor(a)                ID Lattes do(a) autor(a)  \\\n",
       "0                 LUCAS GROTH PEREIRA          Não informado pela instituição   \n",
       "1          Góes, Carolina Braz, 1988-          Não informado pela instituição   \n",
       "2                  Krob, Bruna Emerim          Não informado pela instituição   \n",
       "3  Pessoa, Valdirene Nunes de Santana  http://lattes.cnpq.br/4782270039388546   \n",
       "4                          Cruz, Itan  http://lattes.cnpq.br/7904209184794040   \n",
       "\n",
       "                            Orientadores  \\\n",
       "0                                     []   \n",
       "1                                     []   \n",
       "2          ['Xavier, Regina Célia Lima']   \n",
       "3  ['Costa, Carlos Eduardo Coutinho da']   \n",
       "4               ['Negro, Antonio Luigi']   \n",
       "\n",
       "                          ID Lattes dos orientadores  \\\n",
       "0                     Não informado pela instituição   \n",
       "1                     Não informado pela instituição   \n",
       "2                     Não informado pela instituição   \n",
       "3                     Não informado pela instituição   \n",
       "4  http://lattes.cnpq.br/8888819051963884||Não in...   \n",
       "\n",
       "                                    Membros da banca  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  ['Nascimento, Álvaro Pereira do', 'Silva, Alex...   \n",
       "4  ['Negro, Antonio Luigi', 'Mata, Iacy Maia', 'P...   \n",
       "\n",
       "                      ID Lattes dos membros da banca  \\\n",
       "0                     Não informado pela instituição   \n",
       "1                     Não informado pela instituição   \n",
       "2                     Não informado pela instituição   \n",
       "3                     Não informado pela instituição   \n",
       "4  http://lattes.cnpq.br/8888819051963884||http:/...   \n",
       "\n",
       "                                              Título  Ano de defesa  \\\n",
       "0  [en] AN ABOLICIONIST ARGUMENT: PENAL ABOLITION...           2022   \n",
       "1  Percepções dos pesquisadores da produção anima...           2019   \n",
       "2  \"Com a condição de servir gratuitamente a mim ...           2016   \n",
       "3  Entre as pessoas mais gradas do município: a t...           2018   \n",
       "4  Saraiva, Dantas e Cotegipe: baianismo, escravi...           2022   \n",
       "\n",
       "                               Instituição de defesa  \\\n",
       "0  Pontifícia Universidade Católica do Rio de Jan...   \n",
       "1        Universidade Estadual de Campinas (UNICAMP)   \n",
       "2  Universidade Federal do Rio Grande do Sul (UFRGS)   \n",
       "3  Universidade Federal Rural do Rio de Janeiro (...   \n",
       "4               Universidade Federal da Bahia (UFBA)   \n",
       "\n",
       "  Sigla da instituição de defesa  ... Tipos de acesso Tipo de documento  \\\n",
       "0                        PUC_RIO  ...      openAccess    doctoralThesis   \n",
       "1                        UNICAMP  ...      openAccess      masterThesis   \n",
       "2                          UFRGS  ...      openAccess      masterThesis   \n",
       "3                          UFRRJ  ...      openAccess      masterThesis   \n",
       "4                           UFBA  ...      openAccess    doctoralThesis   \n",
       "\n",
       "                               Assuntos em português  \\\n",
       "0  ['[pt] MARXISMO', '[pt] SISTEMA PUNITIVO', '[p...   \n",
       "1  ['Agropecuária', 'Indústria animal', 'Animalis...   \n",
       "2  ['Escravidão', 'Abolição da escravatura', 'Car...   \n",
       "3  ['Negro', 'Pós-abolição', 'Trajetória', 'Mobil...   \n",
       "4  ['Segundo Reinado', 'Baianismo', 'Política da ...   \n",
       "\n",
       "                                  Assuntos em inglês Idioma  \\\n",
       "0                 ['Não informado pela instituição']    por   \n",
       "1                 ['Não informado pela instituição']    por   \n",
       "2  ['Slavery', 'Manumission', 'Abolition', 'Freed...    por   \n",
       "3  ['Post-abolition', 'Trajectory', 'Social Mobil...    por   \n",
       "4                 ['Não informado pela instituição']    por   \n",
       "\n",
       "                                              Resumo  \\\n",
       "0  [pt] O presente trabalho busca fazer uma retom...   \n",
       "1                                                NaN   \n",
       "2  A presente pesquisa parte da emancipação de es...   \n",
       "3  O objeto central que baliza esta pesquisa é a ...   \n",
       "4  A presente tese investiga o baianismo e suas i...   \n",
       "\n",
       "                                      Link de acesso  \\\n",
       "0  https://www.maxwell.vrac.puc-rio.br/colecao.ph...   \n",
       "1  https://hdl.handle.net/20.500.12733/1637478||G...   \n",
       "2                 http://hdl.handle.net/10183/148467   \n",
       "3  https://rima.ufrrj.br/jspui/handle/20.500.1440...   \n",
       "4        https://repositorio.ufba.br/handle/ri/36441   \n",
       "\n",
       "              Resumo em Português                Resumo em Inglês  \\\n",
       "0  Não informado pela instituição  Não informado pela instituição   \n",
       "1  Não informado pela instituição  Não informado pela instituição   \n",
       "2  Não informado pela instituição  Não informado pela instituição   \n",
       "3  Não informado pela instituição  Não informado pela instituição   \n",
       "4  Não informado pela instituição  Não informado pela instituição   \n",
       "\n",
       "                            Referência Bibliográfica  \n",
       "0                     Não informado pela instituição  \n",
       "1                     Não informado pela instituição  \n",
       "2                     Não informado pela instituição  \n",
       "3  PESSOA, Valdirene Nunes de Santana. Entre as p...  \n",
       "4  CRUZ, Itan. Saraiva, Dantas e Cotegipe: baiani...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo os dados do arquivo CSV\n",
    "data = pd.read_csv(\"data/BDTD_Consolidado_feb2025.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando o texto em turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixos\n",
    "prefixos = \"\"\" @prefix ns: <http://www.w3.org/2003/06/sw-vocab-status/ns#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
    "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "@prefix vann: <http://purl.org/vocab/vann/> .\n",
    "@prefix event: <http://purl.org/NET/c4dm/event.owl#> .\n",
    "@prefix prism: <http://prismstandard.org/namespaces/1.2/basic/> .\n",
    "@prefix terms: <http://purl.org/dc/terms/> .\n",
    "@prefix schema: <http://schemas.talis.com/2005/address/schema#> .\n",
    "@prefix status: <http://purl.org/ontology/bibo/status/> .\n",
    "@prefix degrees: <http://purl.org/ontology/bibo/degrees/> .\n",
    "@prefix stardog: <tag:stardog:api:> .\n",
    "@base <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando com o banco e adicionando as triplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe os prefixos e triplas e as carrega à base de dados\n",
    "def add_triplas_to_stardog(prefixos, triplas):\n",
    "\n",
    "    # Incluindo prefixos às triplas\n",
    "    triplas = prefixos + \" \" + triplas\n",
    "    triplas = triplas.encode('utf-8')\n",
    "\n",
    "    ### Connect to the Stardog database\n",
    "    database_name = 'IndigenousSlavery'\n",
    "    conn = stardog.Connection(database_name, **connection_details)\n",
    "\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.Raw(triplas, 'text/turtle'))\n",
    "    conn.commit() # commit the transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando e processando os dados das Teses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe uma string e a limpar para ficar no formato aceitável para uma URI\n",
    "def process_uri(x):\n",
    "    return (re.sub('[^a-zA-Z0-9_ ]', '',\n",
    "            unidecode(x.strip())\n",
    "                        .replace(\" \", \"_\")\n",
    "                        .replace(\"[\",\"\")\n",
    "                        .replace(\"]\",\"\")\n",
    "                        .replace(\"?\",\"\")\n",
    "                        .replace(\"'\",\"\")\n",
    "                        .lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23732\\3317037659.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4] = data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4].apply(lambda x: 2000 + x if x < 25 else 1900 + x)\n",
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23732\\3317037659.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4] = data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4].apply(lambda x: 2000 + x if x < 25 else 1900 + x)\n"
     ]
    }
   ],
   "source": [
    "titulo = data['Título']\n",
    "thesis_uri = data['Título'].apply(lambda x: process_uri(x))\n",
    "#Alterando os anos com dois dígitos para 4 dígitos\n",
    "data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4] = data['Ano de defesa'][data['Ano de defesa'].apply(str).apply(len) != 4].apply(lambda x: 2000 + x if x < 25 else 1900 + x)\n",
    "ano = data['Ano de defesa']\n",
    "link = data['Link de acesso']\n",
    "referencia = data['Referência Bibliográfica']\n",
    "resumo = data['Resumo']\n",
    "resumo_pt = data['Resumo em Português']\n",
    "resumo_en = data['Resumo em Inglês']\n",
    "resumo_lang = data['Resumo'].apply(lambda x: detect(str(x) + \"sem texto\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" rdf:type bibo:Thesis.\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:title '\"\"\" + titulo[m].replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"\"\"'.\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:created '\"\"\" + str(ano[m]) +  \"\"\"'^^xsd:gYear.\n",
    "    \"\"\"\n",
    "    if link[m].startswith(\"http\"):\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:repository '\"\"\" + link[m].replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'. \"\"\"\n",
    "\n",
    "    if referencia[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:identifier '\"\"\" + referencia[m].replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'. \"\"\"\n",
    "\n",
    "    if resumo[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@\"\"\" + resumo_lang[m] + \"\"\". \"\"\"\n",
    "    \n",
    "    if resumo_pt[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo_pt[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "\n",
    "    if resumo_en[m] != 'Não informado pela instituição':\n",
    "        tripla = tripla + \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:abstract '\"\"\" + str(resumo_en[m]).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@en. \"\"\"\n",
    "\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + thesis_uri[m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando dados e propriedades das pessoas (\"Person\") - Autores, Orientadores e Membros da Banca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_person(person_column):\n",
    "\n",
    "    column_raw = person_column.apply(lambda x: x.split(\"',\")).replace(\"['\", \"\")\n",
    "\n",
    "    column_raw_list = []\n",
    "    for i in column_raw:\n",
    "        for person in i:\n",
    "            if person != '[]':\n",
    "                person = person.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"\", \"\").split(\",\")\n",
    "                column_raw_list.append(person)\n",
    "\n",
    "    column_raw_list = pd.Series(column_raw_list) \n",
    "\n",
    "    #Último Sobrenome   \n",
    "    column_family_name = column_raw_list.apply(lambda x: x[0].strip().replace(u'\\\\', u' '))\n",
    "\n",
    "    # Primeiros nomes\n",
    "    column_given_name = column_raw_list.apply(lambda x: x[1].strip().replace(u'\\\\', u' ') if len(x) > 1 else \"\")\n",
    "\n",
    "    # Unindo nome e sobrenome\n",
    "    column_uri = (column_given_name + \"_\" + column_family_name) \n",
    "\n",
    "    #substituindo espaco por \"_\", retirando diacrítico e colocando em minúscula\n",
    "    column_uri = column_uri.apply(lambda x: process_uri(x))\n",
    "\n",
    "    return (column_raw_list, column_family_name, column_given_name, column_uri)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando colunas\n",
    "autor_raw_list, autor_family_name, autor_given_name, autor_uri = clean_person(data[\"Autor(a)\"])\n",
    "orientador_raw_list, orientador_family_name, orientador_given_name, orientador_uri = clean_person(data['Orientadores'])\n",
    "banca_raw_list, banca_family_name, banca_given_name, banca_uri = clean_person(data['Membros da banca'])\n",
    "\n",
    "# Unindo as colunas com informacões de pessoas\n",
    "family_name = pd.concat([autor_family_name, orientador_family_name, banca_family_name],  ignore_index=True)\n",
    "given_name = pd.concat([autor_given_name, orientador_given_name, banca_given_name],  ignore_index=True)\n",
    "name_uri = pd.concat([autor_uri, orientador_uri, banca_uri],  ignore_index=True)\n",
    "\n",
    "# Removendo duplicados\n",
    "name_uri = name_uri.drop_duplicates()\n",
    "uniq_index = name_uri.index\n",
    "family_name = family_name[uniq_index]\n",
    "given_name = given_name[uniq_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in uniq_index:\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" rdf:type foaf:Person.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" rdfs:label '\"\"\" + family_name[m].replace(\"'\",\"\") + \"\"\", \"\"\"+ given_name[m].replace(\"'\",\"\") + \"\"\"'.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" foaf:givenname '\"\"\" + given_name[m].strip().replace(\"'\",\"\") + \"\"\"'.\n",
    "    stardog:\"\"\" + name_uri[m] + \"\"\" foaf:family_name '\"\"\" + family_name[m].replace(\"'\",\"\") + \"\"\"'.\n",
    "    \"\"\"\n",
    "\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + name_uri[m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding autor relationship between thesis and its author.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:author stardog:\"\"\" + autor_uri[m] +  \"\"\".\"\"\"\n",
    "    triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding autor relationship between thesis and its advisors and opponents.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    person_uris = clean_person(data['Orientadores'][m:m+1])[3]\n",
    "    for person_uri in person_uris:\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:advisor stardog:\"\"\" + person_uri +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    person_uris = clean_person(data['Membros da banca'][m:m+1])[3]\n",
    "    for person_uri in person_uris:\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:opponent stardog:\"\"\" + person_uri +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando dados e propriedades da instituicao de pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as triplas das instituicões\n",
    "university = data[['Instituição de defesa', 'Sigla da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(university)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdf:type bibo:University. \n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdfs:label '\"\"\" + university['Instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" bibo:acronym '\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\"'.\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + university['Sigla da instituição de defesa'][m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as triplas dos departamentos e programas\n",
    "departamento = data[data['Departamento da instituição de defesa'] != 'Não informado pela instituição']\n",
    "departamento = departamento[['Sigla da instituição de defesa', 'Departamento da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "departamento['uri'] = departamento['Sigla da instituição de defesa'] + '_' + departamento['Departamento da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "\n",
    "programa = data[data['Programa de Pós-Graduação da instituição de defesa'] != 'Não informado pela instituição']\n",
    "programa = programa[['Sigla da instituição de defesa', 'Programa de Pós-Graduação da instituição de defesa']].drop_duplicates(ignore_index=True)\n",
    "programa['uri'] = programa['Sigla da instituição de defesa'] + '_' + programa['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(departamento)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdf:type bibo:Department. \n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdfs:label '\"\"\" + departamento['Departamento da instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + departamento['uri'][m] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000050> stardog:\"\"\" + departamento['Sigla da instituição de defesa'][m] + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "for m in range(len(programa)):\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" rdf:type bibo:Program. \n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" rdfs:label '\"\"\" + programa['Programa de Pós-Graduação da instituição de defesa'][m] + \"\"\"'.\n",
    "    stardog:\"\"\" + programa['uri'][m] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000050> stardog:\"\"\" + programa['Sigla da instituição de defesa'][m] + \"\"\".\n",
    "    \"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "# stardog:\"\"\" + departamento['uri'][m] + \"\"\" rdf:type owl:NamedIndividual.\n",
    "# stardog:\"\"\" + programa['uri'][m] + \"\"\" rdf:type owl:NamedIndividual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses às organizacoes (univeridades, departamentos e programas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23732\\1663232402.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  publishers['dep_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Departamento da instituição de defesa'].apply(process_uri)\n",
      "C:\\Users\\facordei\\AppData\\Local\\Temp\\ipykernel_23732\\1663232402.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  publishers['program_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n"
     ]
    }
   ],
   "source": [
    "publishers = data[['Sigla da instituição de defesa', 'Departamento da instituição de defesa', 'Programa de Pós-Graduação da instituição de defesa']] \n",
    "publishers['dep_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Departamento da instituição de defesa'].apply(process_uri)\n",
    "publishers['program_uri'] = publishers['Sigla da instituição de defesa'] + '_' + publishers['Programa de Pós-Graduação da instituição de defesa'].apply(process_uri)\n",
    "\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(len(thesis_uri)):\n",
    "    if publishers['Sigla da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['Sigla da instituição de defesa'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if publishers['Departamento da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['dep_uri'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if publishers['Programa de Pós-Graduação da instituição de defesa'][m] != 'Não informado pela instituição':\n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:publisher stardog:\"\"\" + publishers['program_uri'][m] +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando os assuntos e áreas do conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando as listas únicas (SET) com assuntos\n",
    "# Inglês\n",
    "assunto_en_v1 = data['Assuntos em inglês'].apply(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")).values\n",
    "\n",
    "assunto_en_v2 = []\n",
    "for i in assunto_en_v1:\n",
    "    assunto_en_v2 = assunto_en_v2 + i\n",
    "\n",
    "assunto_en_v3 = []\n",
    "for i in assunto_en_v2:\n",
    "    assunto_en_v3.append(i.strip())\n",
    "assunto_en = set(assunto_en_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Português\n",
    "assunto_pt_v1 = data['Assuntos em português'].apply(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")).values\n",
    "\n",
    "assunto_pt_v2 = []\n",
    "for i in assunto_pt_v1:\n",
    "    assunto_pt_v2 = assunto_pt_v2 + i\n",
    "\n",
    "assunto_pt_v3 = []\n",
    "for i in assunto_pt_v2:\n",
    "    assunto_pt_v3.append(i.strip())\n",
    "assunto_pt = set(assunto_pt_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para encontrar o lemma da palavra em inglês e formar a URI do assunto\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def lemma(word):\n",
    "    doc = nlp(word)\n",
    "    uri = ''\n",
    "    for token in doc:\n",
    "        uri = uri + token.lemma_ + ' '\n",
    "    return (process_uri(uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para traduzir os assuntos em português para inglês\n",
    "\n",
    "# Add your key and endpoint\n",
    "key = os.getenv('TRANSLATOR_KEY') #\"<your-translator-key>\"\n",
    "endpoint = os.getenv('TRANSLATOR_ENDPOINT') #\"https://api.cognitive.microsofttranslator.com\"\n",
    "\n",
    "# location, also known as region.\n",
    "# required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
    "location = os.getenv('TRANSLATOR_LOCATION') #\"<YOUR-RESOURCE-LOCATION>\"\n",
    "\n",
    "path = '/translate'\n",
    "constructed_url = endpoint + path\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'pt',\n",
    "    'to': ['en']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    # location required if you're using a multi-service or regional (not global) resource.\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "# You can pass more than one object in body.\n",
    "#body = [{\n",
    "#    'text': 'I would really like to drive your car around the block a few times!'\n",
    "#}]\n",
    "\n",
    "def translate_pt_en(word):\n",
    "    body = [{'text': word}]\n",
    "\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body, verify=False)\n",
    "    response = request.json()\n",
    "    return (response[0]['translations'][0]['text'])\n",
    "    #print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário com assunto_URI e termos em inglês\n",
    "uri_dic = {}\n",
    "\n",
    "for word in assunto_en:\n",
    "    assunto_uri = lemma(word)\n",
    "    if assunto_uri not in uri_dic:\n",
    "        uri_dic[assunto_uri] = {'en': [word], 'pt': []}\n",
    "    else:\n",
    "        uri_dic[assunto_uri]['en'] = uri_dic[assunto_uri]['en'] + [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n",
      "69500\n",
      "69600\n",
      "69700\n",
      "69800\n",
      "69900\n",
      "70000\n",
      "70100\n",
      "70200\n",
      "70300\n",
      "70400\n",
      "70500\n",
      "70600\n",
      "70700\n",
      "70800\n",
      "70900\n",
      "71000\n",
      "71100\n",
      "71200\n",
      "71300\n",
      "71400\n",
      "71500\n",
      "71600\n",
      "71700\n",
      "71800\n",
      "71900\n",
      "72000\n",
      "72100\n",
      "72200\n",
      "72300\n",
      "72400\n",
      "72500\n",
      "72600\n",
      "72700\n",
      "72800\n",
      "72900\n",
      "73000\n",
      "73100\n",
      "73200\n",
      "73300\n",
      "73400\n"
     ]
    }
   ],
   "source": [
    "#Removing InsecureRequestWarning\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# Criando um dicionário com assunto_URI e termos em português\n",
    "#n = 0\n",
    "#for word in assunto_pt:\n",
    "for n in range(67300, len(list(assunto_pt))):\n",
    "    #n = n + 1\n",
    "    if n % 100 == 0:\n",
    "        print(n)\n",
    "        time.sleep(2.5)\n",
    "    word = list(assunto_pt)[n]\n",
    "    assunto_translate = translate_pt_en(word)\n",
    "    assunto_uri = lemma(assunto_translate)\n",
    "    if assunto_uri not in uri_dic:\n",
    "        uri_dic[assunto_uri] = {'en': [assunto_translate], 'pt': [word]}\n",
    "    else:\n",
    "        uri_dic[assunto_uri]['en'] = list(set(uri_dic[assunto_uri]['en'] + [assunto_translate]))\n",
    "        uri_dic[assunto_uri]['pt'] = uri_dic[assunto_uri]['pt'] + [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/assunto_dict.json', 'w') as fp:\n",
    "    json.dump(uri_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lista em de assuntos em português, possui muito termos em inglês porque os cadastros estao misturados. \n",
    "# Vamos verificar se um termo em portugês já existe na lista em ingles e exclui-los\n",
    "\n",
    "for uri in uri_dic:\n",
    "    for assunto_pt in uri_dic[uri]['pt']:\n",
    "        if assunto_pt in uri_dic[uri]['en']:\n",
    "            uri_dic[uri]['pt'].remove(assunto_pt)\n",
    "\n",
    "# Excluindo do dicionário os termos ' ' e 'Não informado pela instituição'.\n",
    "\n",
    "del uri_dic['']\n",
    "del uri_dic['_']\n",
    "del uri_dic[process_uri('Não informado pela instituição')]\n",
    "del uri_dic[process_uri('Not informed by the institution')]\n",
    "\n",
    "# save dict\n",
    "with open('data/assunto_dict.json', 'w') as fp:\n",
    "    json.dump(uri_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56160"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uri_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  URIs carregadas\n",
      "1000  URIs carregadas\n",
      "2000  URIs carregadas\n",
      "3000  URIs carregadas\n",
      "4000  URIs carregadas\n",
      "5000  URIs carregadas\n",
      "6000  URIs carregadas\n",
      "7000  URIs carregadas\n",
      "8000  URIs carregadas\n",
      "9000  URIs carregadas\n",
      "10000  URIs carregadas\n",
      "11000  URIs carregadas\n",
      "12000  URIs carregadas\n",
      "13000  URIs carregadas\n",
      "14000  URIs carregadas\n",
      "15000  URIs carregadas\n",
      "16000  URIs carregadas\n",
      "17000  URIs carregadas\n",
      "18000  URIs carregadas\n",
      "19000  URIs carregadas\n",
      "20000  URIs carregadas\n",
      "21000  URIs carregadas\n",
      "22000  URIs carregadas\n",
      "23000  URIs carregadas\n",
      "24000  URIs carregadas\n",
      "25000  URIs carregadas\n",
      "26000  URIs carregadas\n",
      "27000  URIs carregadas\n",
      "28000  URIs carregadas\n",
      "29000  URIs carregadas\n",
      "30000  URIs carregadas\n",
      "31000  URIs carregadas\n",
      "32000  URIs carregadas\n",
      "33000  URIs carregadas\n",
      "34000  URIs carregadas\n",
      "35000  URIs carregadas\n",
      "36000  URIs carregadas\n",
      "37000  URIs carregadas\n",
      "38000  URIs carregadas\n",
      "39000  URIs carregadas\n",
      "40000  URIs carregadas\n",
      "41000  URIs carregadas\n",
      "42000  URIs carregadas\n",
      "43000  URIs carregadas\n",
      "44000  URIs carregadas\n",
      "45000  URIs carregadas\n",
      "46000  URIs carregadas\n",
      "47000  URIs carregadas\n",
      "48000  URIs carregadas\n",
      "49000  URIs carregadas\n",
      "50000  URIs carregadas\n",
      "51000  URIs carregadas\n",
      "52000  URIs carregadas\n",
      "53000  URIs carregadas\n",
      "54000  URIs carregadas\n",
      "55000  URIs carregadas\n",
      "56000  URIs carregadas\n",
      "56159  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Carregando as triplas dos assuntos na base de dados \n",
    "\n",
    "uri_dic_keys = list(uri_dic.keys())\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in range(0, len(uri_dic_keys)):\n",
    "\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdf:type bibo:Subject.\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_pt in uri_dic[uri_dic_keys[n]]['pt']:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_pt).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_en in uri_dic[uri_dic_keys[n]]['en']:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_en).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@en. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if n%1000 == 0: \n",
    "        print (n, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (n, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses aos assuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dicionario com label apontando para as uri\n",
    "# portugues\n",
    "label_uri_pt = {}\n",
    "for uri in uri_dic:\n",
    "    for assunto_pt in uri_dic[uri]['pt']:\n",
    "        label_uri_pt[assunto_pt] = uri\n",
    "\n",
    "with open('data/assunto_uri_pt.json', 'w') as fp:\n",
    "    json.dump(label_uri_pt, fp)\n",
    "\n",
    "# inglês\n",
    "label_uri_en = {}\n",
    "for uri in uri_dic:\n",
    "    for assunto_en in uri_dic[uri]['en']:\n",
    "        label_uri_en[assunto_en] = uri\n",
    "\n",
    "with open('data/assunto_uri_en.json', 'w') as fp:\n",
    "    json.dump(label_uri_en, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os dicionários salvos anteriormente\n",
    "\n",
    "with open('data/assunto_dict.json') as fp:\n",
    "    uri_dic = json.load(fp)\n",
    "    \n",
    "with open('data/assunto_uri_pt.json') as fp:\n",
    "    label_uri_pt = json.load(fp)\n",
    "\n",
    "with open('data/assunto_uri_en.json') as fp:\n",
    "    label_uri_en = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  teses carregadas\n",
      "2000  teses carregadas\n",
      "3000  teses carregadas\n",
      "4000  teses carregadas\n",
      "5000  teses carregadas\n",
      "6000  teses carregadas\n",
      "7000  teses carregadas\n",
      "8000  teses carregadas\n",
      "9000  teses carregadas\n",
      "10000  teses carregadas\n",
      "11000  teses carregadas\n",
      "12000  teses carregadas\n",
      "13000  teses carregadas\n",
      "14000  teses carregadas\n",
      "15000  teses carregadas\n",
      "16000  teses carregadas\n",
      "17000  teses carregadas\n",
      "18000  teses carregadas\n",
      "19000  teses carregadas\n",
      "20000  teses carregadas\n",
      "21000  teses carregadas\n",
      "22000  teses carregadas\n",
      "23000  teses carregadas\n",
      "23171  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Adding relationship between thesis and its subjects.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(1, len(thesis_uri)):\n",
    "    subj_uri = []\n",
    "    for sub in assunto_pt_v1[m]:\n",
    "        try:\n",
    "            subj_uri.append(label_uri_en[sub.strip()])\n",
    "        except:\n",
    "            try:\n",
    "                subj_uri.append(label_uri_pt[sub.strip()])\n",
    "            except:\n",
    "                pass\n",
    "    for sub in assunto_en_v1[m]:\n",
    "        try:\n",
    "            subj_uri.append(label_uri_en[sub.strip()])\n",
    "        except:\n",
    "            try:\n",
    "                subj_uri.append(label_uri_pt[sub.strip()])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    for sub in set(subj_uri):\n",
    "        \n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:subject stardog:\"\"\" + sub +  \"\"\".\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    if m%1000 == 0: \n",
    "        print (m, \" teses carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (m, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processando as àreas de conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as áreas não informadas pela instituicão\n",
    "AC = data['Área do conhecimento CNPq'][ data['Área do conhecimento CNPq'] != 'Não informado pela instituição']\n",
    "#Identificando as sequencias de areas únicas (todo um ramo da taxonomia)\n",
    "AC = AC.apply(lambda x: x.split('||'))\n",
    "AC_list = []\n",
    "for area in AC:\n",
    "    AC_list = AC_list + area\n",
    "AC_list = list(set(AC_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para receber o ramo da taxonomia, já processada como uri\n",
    "AC_uri_list = []\n",
    "# Dicionário para converter em URI para label\n",
    "AC_uri_dic = {}\n",
    "\n",
    "for areas in AC_list:\n",
    "    uri_area = []\n",
    "    for area in areas.split('::'):\n",
    "        area_translate = translate_pt_en(area)\n",
    "        uri_a = lemma(area_translate)\n",
    "        #uri_a = process_uri(area)\n",
    "        uri_area.append(uri_a)\n",
    "        if uri_a not in AC_uri_dic:\n",
    "            AC_uri_dic[uri_a] = [area]\n",
    "        else:\n",
    "            AC_uri_dic[uri_a] = list(set(AC_uri_dic[uri_a] + [area]))\n",
    "    AC_uri_list.append(uri_area)\n",
    "\n",
    "# Removendo o termo 'cnpq' e 'accnpq' do dicionário e das listas\n",
    "del AC_uri_dic['cnpq']\n",
    "\n",
    "new_AC_uri_list = []\n",
    "for l in AC_uri_list:\n",
    "    new_AC_uri_list.append([i for i in l if i != 'cnpq'])\n",
    "AC_uri_list = new_AC_uri_list\n",
    "\n",
    "del AC_uri_dic['accnpq']\n",
    "\n",
    "new_AC_uri_list = []\n",
    "for l in AC_uri_list:\n",
    "    new_AC_uri_list.append([i for i in l if i != 'accnpq'])\n",
    "AC_uri_list = new_AC_uri_list\n",
    "\n",
    "# Montando as tuplas com \"area do conhecimento\" has_part \"outra area do conhecimento\".\n",
    "\n",
    "tupla_has_part = []\n",
    "for areas in AC_uri_list:\n",
    "    if len(areas) > 1:\n",
    "        for n in range(len(areas)-1):\n",
    "            tupla_has_part.append((areas[n], areas[n+1]))\n",
    "\n",
    "tupla_has_part = list(set(tupla_has_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  URIs carregadas\n",
      "100  URIs carregadas\n",
      "200  URIs carregadas\n",
      "300  URIs carregadas\n",
      "400  URIs carregadas\n",
      "500  URIs carregadas\n",
      "583  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Carregando as triplas das áreas de conhecimento na base de dados \n",
    "\n",
    "uri_dic_keys = list(AC_uri_dic.keys())\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in range(0, len(uri_dic_keys)):\n",
    "\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdf:type bibo:CNPQ.\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "\n",
    "    for label_pt in AC_uri_dic[uri_dic_keys[n]]:\n",
    "        tripla = \"\"\"stardog:\"\"\" + uri_dic_keys[n] + \"\"\" rdfs:label '\"\"\" + str(label_pt).replace(\"'\",\"\").replace(u'\\\\', u' ') + \"\"\"'@pt. \"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "        \n",
    "    if n%100 == 0: \n",
    "        print (n, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (n, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as triplas \"has_part\" das áreas de conhecimento na base de dados \n",
    "triplas = \"\"\" \"\"\"\n",
    "for n in tupla_has_part:\n",
    "    tripla = \"\"\"\n",
    "    stardog:\"\"\" + n[0] + \"\"\" <http://purl.obolibrary.org/obo/BFO_0000051> stardog:\"\"\" + n[1] + \"\"\".\"\"\"\n",
    "    triplas = triplas + \" \" + tripla\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando as teses às áreas do conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dicionario com label das áreas do conhecimento apontando para as uri\n",
    "label_area_uri = {}\n",
    "for uri in AC_uri_dic:\n",
    "    for area in AC_uri_dic[uri]:\n",
    "        label_area_uri[area] = uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  URIs carregadas\n",
      "6000  URIs carregadas\n",
      "13000  URIs carregadas\n",
      "17000  URIs carregadas\n",
      "18000  URIs carregadas\n",
      "20000  URIs carregadas\n",
      "22000  URIs carregadas\n",
      "23169  URIs carregadas\n"
     ]
    }
   ],
   "source": [
    "# Adding relationship between thesis and its subjects.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in AC.index:\n",
    "    for areas in AC[m]:\n",
    "        for area in areas.split('::'):\n",
    "            try:\n",
    "                tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" terms:subject stardog:\"\"\" + label_area_uri[area] +  \"\"\".\"\"\"\n",
    "                triplas = triplas + \" \" + tripla\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if m%1000 == 0: \n",
    "        print (m, \" URIs carregadas\")\n",
    "        add_triplas_to_stardog(prefixos, triplas)\n",
    "        triplas = \"\"\" \"\"\"\n",
    "\n",
    "print (m, \" URIs carregadas\")\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando as triplas conectando as teses aos degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplas = \"\"\"\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdf:type <http://purl.org/ontology/bibo/ThesisDegree>.\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdfs:label 'PhD degree'@en.\n",
    "<http://purl.org/ontology/bibo/degrees/phd> rdfs:label 'Doutorado'@pt.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdf:type <http://purl.org/ontology/bibo/ThesisDegree>.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdfs:label 'Master degree'@en.\n",
    "<http://purl.org/ontology/bibo/degrees/master> rdfs:label 'Mestrado'@pt.\"\"\"\n",
    "\n",
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding relationship between thesis and degree.\n",
    "\n",
    "triplas = \"\"\" \"\"\"\n",
    "\n",
    "for m in range(0, len(thesis_uri)):\n",
    "    if data['Tipo de documento'][m] == \"masterThesis\":\n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:degree <http://purl.org/ontology/bibo/degrees/master>.\"\"\"\n",
    "        triplas = triplas + \" \" + tripla\n",
    "    if data['Tipo de documento'][m] == \"doctoralThesis\":\n",
    "        tripla = \"\"\"stardog:\"\"\" + thesis_uri[m] + \"\"\" bibo:degree <http://purl.org/ontology/bibo/degrees/phd>.\"\"\"        \n",
    "        triplas = triplas + \" \" + tripla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triplas_to_stardog(prefixos, triplas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

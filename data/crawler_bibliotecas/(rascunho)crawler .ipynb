{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install beautifulsoup4\n",
    "#%pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "import stardog\n",
    "import os\n",
    "import io\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from PyPDF2 import PdfReader\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buscar os links para a tese no Neo4j\n",
    "- Buscar o link do PDF no repositório da universidade\n",
    "- Baixar o PDF\n",
    "- Extrair o texto do PDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar links para a tese no Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando ao Neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stardog variables\n",
    "#STARDOG_ENDPOINT = os.getenv('STARDOG_ENDPOINT')\n",
    "#STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
    "#STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
    "\n",
    "#connection_details = {\n",
    "#    'endpoint': STARDOG_ENDPOINT,\n",
    "#    'username': STARDOG_USERNAME,\n",
    "#    'password': STARDOG_PASSWORD\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_name = 'IndigenousSlavery'\n",
    "#conn = stardog.Connection(database_name, **connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thesis</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:stardog:api:substituicao_do_negro_de_fumo_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/3/3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:stardog:api:diversidade_na_unidade_a_tradi...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/71/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag:stardog:api:kuxima_paa_dizque_antigamente_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/8/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag:stardog:api:vai_da_muito_trabalho_cultura_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/48/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag:stardog:api:access_to_maternal_reproductiv...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/22/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>tag:stardog:api:entre_o_tipo_e_o_sujeito_os_re...</td>\n",
       "      <td>http://www.teses.usp.br/teses/disponiveis/27/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>tag:stardog:api:a_equacao_de_blackscholes_com_...</td>\n",
       "      <td>http://www.teses.usp.br/teses/disponiveis/55/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>tag:stardog:api:o_feitor_ausente_estudo_sobre_...</td>\n",
       "      <td>https://teses.usp.br/teses/disponiveis/8/8138/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>tag:stardog:api:um_ator_de_fronteira_uma_anali...</td>\n",
       "      <td>http://www.teses.usp.br/teses/disponiveis/27/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>tag:stardog:api:sobre_abolicionismos_penais_a_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/8/8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Thesis  \\\n",
       "0     tag:stardog:api:substituicao_do_negro_de_fumo_...   \n",
       "1     tag:stardog:api:diversidade_na_unidade_a_tradi...   \n",
       "2     tag:stardog:api:kuxima_paa_dizque_antigamente_...   \n",
       "3     tag:stardog:api:vai_da_muito_trabalho_cultura_...   \n",
       "4     tag:stardog:api:access_to_maternal_reproductiv...   \n",
       "...                                                 ...   \n",
       "2203  tag:stardog:api:entre_o_tipo_e_o_sujeito_os_re...   \n",
       "2204  tag:stardog:api:a_equacao_de_blackscholes_com_...   \n",
       "2205  tag:stardog:api:o_feitor_ausente_estudo_sobre_...   \n",
       "2206  tag:stardog:api:um_ator_de_fronteira_uma_anali...   \n",
       "2207  tag:stardog:api:sobre_abolicionismos_penais_a_...   \n",
       "\n",
       "                                             repository  \n",
       "0     https://www.teses.usp.br/teses/disponiveis/3/3...  \n",
       "1     https://www.teses.usp.br/teses/disponiveis/71/...  \n",
       "2     https://www.teses.usp.br/teses/disponiveis/8/8...  \n",
       "3     https://www.teses.usp.br/teses/disponiveis/48/...  \n",
       "4     https://www.teses.usp.br/teses/disponiveis/22/...  \n",
       "...                                                 ...  \n",
       "2203  http://www.teses.usp.br/teses/disponiveis/27/2...  \n",
       "2204  http://www.teses.usp.br/teses/disponiveis/55/5...  \n",
       "2205  https://teses.usp.br/teses/disponiveis/8/8138/...  \n",
       "2206  http://www.teses.usp.br/teses/disponiveis/27/2...  \n",
       "2207  https://www.teses.usp.br/teses/disponiveis/8/8...  \n",
       "\n",
       "[2208 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saprql query\n",
    "query1 = \"\"\"\n",
    "SELECT ?thesis ?link\n",
    "WHERE {\n",
    "  ?thesis <http://purl.org/dc/terms/publisher> <tag:stardog:api:USP>.\n",
    "  ?thesis a <http://purl.org/ontology/bibo/Thesis>.\n",
    "  ?thesis <http://purl.org/ontology/bibo/repository> ?link.  \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "#csv_results = conn.select(query1, content_type='text/csv')\n",
    "#thesis_abstract = pd.read_csv(io.BytesIO(csv_results))\n",
    "#thesis_abstract\n",
    "\n",
    "\n",
    "#Cypher query \n",
    "query2 = \"\"\"\n",
    "MATCH  (t:Thesis)-[:publisher]-(uni:University{uri:'tag:stardog:api:USP'})\n",
    "RETURN  t[\"uri\"] as Thesis, t[\"repository\"] as repository \n",
    "\"\"\"\n",
    "\n",
    "results = graph.query(query2)\n",
    "# Convert the results to a DataFrame\n",
    "thesis_repository = pd.DataFrame(results, columns=[\"Thesis\", \"repository\"])\n",
    "thesis_repository\n",
    "\n",
    "#2213 / 2208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "url = thesis_repository['repository'][i]\n",
    "thesis_uri = thesis_repository['Thesis'][i][16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para coletar link do pdf\n",
    "\n",
    "def get_pdf_link(url):\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, verify=True).text#, verify=False) \n",
    "    soup = bs(f, \"html.parser\")\n",
    "    \n",
    "    #Coletando link para as teses\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if doc['href'].endswith('.pdf'):\n",
    "            path = doc['href']\n",
    "            prefix_uni = 'https://www.teses.usp.br'\n",
    "            link = prefix_uni + path\n",
    "\n",
    "            return link\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_link = get_pdf_link(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer download do arquivo\n",
    "def download_file(pdf_link, thesis_uri):\n",
    "    # NOTE the stream=True parameter below\n",
    "    r = requests.get(pdf_link, verify=True, stream=True)\n",
    "    # raise_for_status() is not needed with stream=True\n",
    "    # r.raise_for_status()\n",
    "    with open(thesis_uri + '.pdf', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    return thesis_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revisao_narrativa_para_subsidiar_o_entendimento_do_panorama_da_cobertura_vacinal_em_criancas_menores_de_um_ano_de_idade_no_contexto_brasileiro'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(pdf_link, thesis_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrair texto do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os modelos SpaCy para inglês e português \n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "nlp_pt = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcão que recebe uma string e a limpar para ficar no formato aceitável para uma URI\n",
    "def process_uri(x):\n",
    "    return (re.sub('[^a-zA-Z0-9_ ]', '',\n",
    "            unidecode(x.strip())\n",
    "                        .replace(\" \", \"_\")\n",
    "                        .replace(\"[\",\"\")\n",
    "                        .replace(\"]\",\"\")\n",
    "                        .replace(\"?\",\"\")\n",
    "                        .replace(\"'\",\"\")\n",
    "                        .lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratc_text(tese_path):\n",
    "\n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    excerpt = {}\n",
    "\n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "\n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "                \n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "        except:\n",
    "            lang = None\n",
    "\n",
    "        # Extraindo as entidades\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        #orgs = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(process_uri(ent.text))\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(process_uri(ent.text))\n",
    "            #if ent.label_ == \"ORG\":\n",
    "            #    orgs.append(process_uri(ent.text))\n",
    "                \n",
    "        excerpt[page_number] = {'text': page_text, \n",
    "                                'lang': lang, \n",
    "                                'persons': list(set(persons)), \n",
    "                                'gpes': list(set(gpes)),\n",
    "                               #'orgs': list(set(orgs))\n",
    "                               }\n",
    "\n",
    "    return excerpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = extratc_text(thesis_uri + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '59 \\n de ESAVIS vem se estabelecendo e ganhando maior dimensão, mas a autonomia na \\nprodução de vacinas ainda é menor, em comparação à Índia . Fabricantes de países de \\nbaixo e médio nível socioeconômico têm um papel cada vez maior no fornecimento de \\nvacinas, e sua a entrada no mercado estimula quedas de preço das principais vacinas .  \\n 60 \\n 6. DISCUSSÃO  \\n \\nPelo exposto depreen de-se que, apesar do sucesso dos programas de vacinação, já \\nhavia sinais de preocupação em relação à manutenção das conquistas obtidas. A queda \\ndas coberturas vacinais vinha ocorrendo principalmente a partir de 2016.  \\nA vacinação se caracteriza por interdep endência de responsabilidades individuais, \\ncoletivas e institucionais. Esta dissertação priorizou a investigação sobre as \\nresponsabilidades institucionais na queda das coberturas vacinais.  \\nNesta revisão narrativa sobre a interrelação entre a cobertura vaci nal no Brasil e \\noutros indicadores de qualidade do SUS foram encontrados dados que corroboram a \\nqueda das coberturas vacinais, e dados que mostram fragilidades do SUS, no mesmo \\nperíodo.  \\nA cobertura vacinal registrada pelo antigo sistema API poderia estar s uperestimada. \\nOs registros eram de doses aplicadas, e não de pessoas imunizadas, nominal, como passou \\na ser feito a partir do SIPNI. Algumas vezes a cobertura ultrapassava a população alvo. \\nMas as dificuldades na implantação dos novos sistemas de informaçã o nominais podem \\nter contribuído para subregistro de doses de vacinas aplicadas. Entretanto, os dados do \\ninquérito de cobertura vacinal conduzido por Barata e colaboradores  (2023) , baseado em \\ndados da carteira vacinal das crianças investigadas, detectou qu eda da cobertura  vacinal, \\ne queda progressiva  da cobertura de todas as vacinas que necessitam de mais de uma dose \\npara completar o esquema de vacinação . Outros fatores estão influenciando a queda das \\ncoberturas vacinais. Entretanto são evidentes os problem as dos sistemas de informação. \\nSistemas complexos, com m últiplas entradas ; relatórios de doses aplicadas  inadequados, \\nlevando a d ificuldade de acesso aos dados  e demora na consolidação dos dados das \\ndiversas fontes ; perda de dados . Salienta -se que registro s inadequados podem levar a \\ninterpretações errôneas do problema . \\nSato e colaboradores (2023), em artigo em que analisaram a Cobertura Vacinal \\n(CV), a homogeneidade das CV e os casos  de sarampo no Brasil de 2011 a 2021,  referem \\nque, a partir de 2015, observ a-se queda progressiva  das CV e da homogeneidade, \\nacentuando -se após 2020 em todas as regiões, particularmente  Norte e Nordeste. \\nAglomerados de baixa CV foram  associados a piores indicadores d e desenvolvimento  \\nhumano, desigualdade social e menor  acesso à E stratégia de Saúde da Família . Até 2014, \\ntodas as regi ões brasileiras apresentavam  CV de primeira dose da vacina sarampo ( D1) \\n 61 \\n acima de 95%. A  partir de 2015, as coberturas começaram a cair  e, ap ós 2016, nenhuma \\nregião atingiu CV acima  de 95%.  Os autores co mentam que, n o Brasil, as ações verticais \\ndo PNI na década de 1980 contribu íram para diminuir o gradiente  social da CV e garantir \\no acesso universal à vacinação no país. Os primeiros inquéritos nacionais  de CV \\napontavam piores coberturas em  segmentos',\n",
       " 'lang': 'pt',\n",
       " 'persons': ['ap_os_2016', 'sato', 'barata'],\n",
       " 'gpes': ['nordeste',\n",
       "  'sus',\n",
       "  'brasil',\n",
       "  'pni',\n",
       "  'esavis',\n",
       "  'd1',\n",
       "  'saude_da_familia',\n",
       "  'india',\n",
       "  'cv',\n",
       "  'norte']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratc_text_NER(tese_uri, tese_path):\n",
    "\n",
    "    triplas = \"\"\" \"\"\"\n",
    "\n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "\n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "\n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "        except:\n",
    "            lang = None\n",
    "\n",
    "        # Extraindo as entidades\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        #orgs = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(process_uri(ent.text))\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(process_uri(ent.text))\n",
    "            #if ent.label_ == \"ORG\":\n",
    "            #    orgs.append(process_uri(ent.text))\n",
    "\n",
    "\n",
    "            \n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" rdf:type bibo:Excerpt.\n",
    "        stardog:\"\"\" + tese_uri +  \"\"\" <http://purl.obolibrary.org/obo/BFO_0000051> stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\".\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\" bibo:pages '\"\"\" + str(page_number + 1) +  \"\"\"'. \n",
    "        \"\"\"\n",
    "        if lang == 'pt':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@pt.\"\n",
    "        if lang == 'en':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@en.\"\n",
    "        \n",
    "        #print(set(persons), set(gpes))\n",
    "        for per in set(persons):  \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + per + \"\"\" rdf:type foaf:Person.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + per + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        for gpe in set(gpes): \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + gpe + \"\"\" rdf:type <https://schema.org/Place>.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + gpe + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    add_triplas_to_stardog(prefixos, triplas)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_lg\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install beautifulsoup4\n",
    "#%pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "import stardog\n",
    "import os\n",
    "import io\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from PyPDF2 import PdfReader\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buscar os links para a tese no Neo4j\n",
    "- Buscar o link do PDF no repositório da universidade\n",
    "- Baixar o PDF\n",
    "- Extrair o texto do PDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar links para a tese no Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando ao Neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thesis</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:stardog:api:substituicao_do_negro_de_fumo_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/3/3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:stardog:api:diversidade_na_unidade_a_tradi...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/71/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag:stardog:api:kuxima_paa_dizque_antigamente_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/8/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag:stardog:api:vai_da_muito_trabalho_cultura_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/48/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag:stardog:api:access_to_maternal_reproductiv...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/22/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Thesis  \\\n",
       "0  tag:stardog:api:substituicao_do_negro_de_fumo_...   \n",
       "1  tag:stardog:api:diversidade_na_unidade_a_tradi...   \n",
       "2  tag:stardog:api:kuxima_paa_dizque_antigamente_...   \n",
       "3  tag:stardog:api:vai_da_muito_trabalho_cultura_...   \n",
       "4  tag:stardog:api:access_to_maternal_reproductiv...   \n",
       "\n",
       "                                          repository  \n",
       "0  https://www.teses.usp.br/teses/disponiveis/3/3...  \n",
       "1  https://www.teses.usp.br/teses/disponiveis/71/...  \n",
       "2  https://www.teses.usp.br/teses/disponiveis/8/8...  \n",
       "3  https://www.teses.usp.br/teses/disponiveis/48/...  \n",
       "4  https://www.teses.usp.br/teses/disponiveis/22/...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cypher query to get all theses from USP\n",
    "query1 = \"\"\"\n",
    "MATCH  (t:Thesis)-[:publisher]-(uni:University{uri:'tag:stardog:api:USP'})\n",
    "RETURN  t[\"uri\"] as Thesis, t[\"repository\"] as repository \n",
    "\"\"\"\n",
    "\n",
    "results = graph.query(query1)\n",
    "# Convert the results to a DataFrame\n",
    "thesis_repository = pd.DataFrame(results, columns=[\"Thesis\", \"repository\"])\n",
    "thesis_repository = thesis_repository[:5]\n",
    "thesis_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funcao para coletar link do pdf\n",
    "\n",
    "def get_pdf_link(url):\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, verify=True).text#, verify=False) \n",
    "    soup = bs(f, \"html.parser\")\n",
    "    \n",
    "    #Coletando link para as teses\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if doc['href'].endswith('.pdf'):\n",
    "            path = doc['href']\n",
    "            prefix_uni = 'https://www.teses.usp.br'\n",
    "            link = prefix_uni + path\n",
    "\n",
    "            return link\n",
    "    \n",
    "    return None\n",
    "\n",
    "#fazer download do arquivo\n",
    "def download_file(pdf_link, thesis_uri):\n",
    "    # NOTE the stream=True parameter below\n",
    "    r = requests.get(pdf_link, verify=True, stream=True)\n",
    "    # raise_for_status() is not needed with stream=True\n",
    "    # r.raise_for_status()\n",
    "    with open(thesis_uri + '.pdf', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    return \n",
    "\n",
    "#Carregando os modelos SpaCy para inglês e português \n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "nlp_pt = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "# Funcão que recebe uma string e a limpar para ficar no formato aceitável para uma URI\n",
    "def process_uri(x):\n",
    "    return (re.sub('[^a-zA-Z0-9_ ]', '',\n",
    "            unidecode(x.strip())\n",
    "                        .replace(\" \", \"_\")\n",
    "                        .replace(\"[\",\"\")\n",
    "                        .replace(\"]\",\"\")\n",
    "                        .replace(\"?\",\"\")\n",
    "                        .replace(\"'\",\"\")\n",
    "                        .lower()))\n",
    "\n",
    "\n",
    "# Função para extrair texto de uma tese em PDF e identificar entidades\n",
    "def extratc_text(tese_path):\n",
    "    \n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    excerpt = {}\n",
    "    \n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "        \n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "      \n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "            \n",
    "        except:\n",
    "            lang = 'Não_detectado'\n",
    "        \n",
    "        # Extraindo as entidades\n",
    "        page_extracted = False\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "            page_extracted = True\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "            page_extracted = True\n",
    "        \n",
    "        if page_extracted:\n",
    "\n",
    "            persons = []\n",
    "            gpes = []\n",
    "            #orgs = []\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                    persons.append(process_uri(ent.text))\n",
    "                if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                    gpes.append(process_uri(ent.text))\n",
    "                #if ent.label_ == \"ORG\":\n",
    "                #    orgs.append(process_uri(ent.text))\n",
    "                    \n",
    "            excerpt[page_number] = {'text': page_text, \n",
    "                                    'lang': lang, \n",
    "                                    'persons': list(set(persons)), \n",
    "                                    'gpes': list(set(gpes)),\n",
    "                                #'orgs': list(set(orgs))\n",
    "                                }\n",
    "\n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterando por todas as URI para extrair o texto e gravar no grafo NEO4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural from https://www.teses.usp.br/teses/disponiveis/3/3133/tde-10082023-152417/publico/FabioJoseEsperCorr.pdf\n",
      "Extracted substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural\n",
      "Processed and added to graph: substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural\n",
      "No PDF link found for diversidade_na_unidade_a_tradicao_policroma_da_amazonia_na_historia_indigena_de_longa_duracao_do_medio_solimoes_5001900_dc\n",
      "Downloading kuxima_paa_dizque_antigamente_um_primeiro_olhar_para_fenomenos_de_contato_linguistico_com_o_nheengatu_no_portugues_falado_em_sao_gabriel_da_cachoeira_am from https://www.teses.usp.br/teses/disponiveis/8/8139/tde-29112024-110653/publico/2024_MarianaPaynoGomes_VCor.pdf\n",
      "Extracted kuxima_paa_dizque_antigamente_um_primeiro_olhar_para_fenomenos_de_contato_linguistico_com_o_nheengatu_no_portugues_falado_em_sao_gabriel_da_cachoeira_am\n"
     ]
    },
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 't': expected\r\n  \"!=\"\r\n  \"%\"\r\n  \"*\"\r\n  \"+\"\r\n  \",\"\r\n  \"-\"\r\n  \"/\"\r\n  \"::\"\r\n  \"<\"\r\n  \"<=\"\r\n  \"<>\"\r\n  \"=\"\r\n  \"=~\"\r\n  \">\"\r\n  \">=\"\r\n  \"AND\"\r\n  \"CONTAINS\"\r\n  \"ENDS\"\r\n  \"IN\"\r\n  \"IS\"\r\n  \"OR\"\r\n  \"STARTS\"\r\n  \"XOR\"\r\n  \"^\"\r\n  \"||\"\r\n  \"}\" (line 44, column 54 (offset: 3555))\r\n\"58 No original, em inglês: “[...] their dynamics don't necessarily favor efficiency; and once a stability is established,\"\r\n                                                      ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 38\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#Criando a query para inserir o nó Exerpt\u001b[39;00m\n\u001b[0;32m     32\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124mMATCH  (t:Thesis\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124muri: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m thesis_repository[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThesis\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124mMERGE  (e:Exerpt\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(excerpt_dict) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m)-[r:BFO_0000050]-(t)\u001b[39m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#Criando as relações com as entidades\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person \u001b[38;5;129;01min\u001b[39;00m excerpt[n][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersons\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:431\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneo4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jError\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m     data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\driver.py:971\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[1;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:574\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 574\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtransaction_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_work\\query.py:144\u001b[0m, in \u001b[0;36munit_of_work.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1307\u001b[0m, in \u001b[0;36m_work\u001b[1;34m(tx, query, parameters, transformer)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_work\u001b[39m(\n\u001b[0;32m   1302\u001b[0m     tx: ManagedTransaction,\n\u001b[0;32m   1303\u001b[0m     query: te\u001b[38;5;241m.\u001b[39mLiteralString,\n\u001b[0;32m   1304\u001b[0m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   1305\u001b[0m     transformer: t\u001b[38;5;241m.\u001b[39mCallable[[Result], t\u001b[38;5;241m.\u001b[39mUnion[_T]],\n\u001b[0;32m   1306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m-> 1307\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer(res)\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\transaction.py:195\u001b[0m, in \u001b[0;36mTransactionBase.run\u001b[1;34m(self, query, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    194\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters)\n\u001b[1;32m--> 195\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tx_ready_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:175\u001b[0m, in \u001b[0;36mResult._tx_ready_run\u001b[1;34m(self, query, parameters)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:231\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:425\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:181\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:977\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m    974\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    975\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    976\u001b[0m )\n\u001b[1;32m--> 977\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:466\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbolt_states\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:251\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    249\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 't': expected\r\n  \"!=\"\r\n  \"%\"\r\n  \"*\"\r\n  \"+\"\r\n  \",\"\r\n  \"-\"\r\n  \"/\"\r\n  \"::\"\r\n  \"<\"\r\n  \"<=\"\r\n  \"<>\"\r\n  \"=\"\r\n  \"=~\"\r\n  \">\"\r\n  \">=\"\r\n  \"AND\"\r\n  \"CONTAINS\"\r\n  \"ENDS\"\r\n  \"IN\"\r\n  \"IS\"\r\n  \"OR\"\r\n  \"STARTS\"\r\n  \"XOR\"\r\n  \"^\"\r\n  \"||\"\r\n  \"}\" (line 44, column 54 (offset: 3555))\r\n\"58 No original, em inglês: “[...] their dynamics don't necessarily favor efficiency; and once a stability is established,\"\r\n                                                      ^}"
     ]
    }
   ],
   "source": [
    "for i in range(len(thesis_repository)):\n",
    "    # Coletando o link do PDF\n",
    "    url = thesis_repository['repository'][i]\n",
    "    thesis_uri = thesis_repository['Thesis'][i][16:]\n",
    "    pdf_link = get_pdf_link(url)\n",
    "    if pdf_link is not None:\n",
    "        print(f\"Downloading {thesis_uri} from {pdf_link}\")\n",
    "        # Download do arquivo PDF\n",
    "        download_file(pdf_link, thesis_uri)\n",
    "        \n",
    "        # Extraindo o texto e entidades\n",
    "        tese_path = thesis_uri + '.pdf'\n",
    "        excerpt = extratc_text(tese_path)\n",
    "        print(f\"Extracted {thesis_uri}\")\n",
    "        \n",
    "        # Salvando o triplas no grafo Neo4j\n",
    "        for n in range(len(excerpt)):\n",
    "     \n",
    "            excerpt_uri = thesis_repository['Thesis'][i] + '_p_' + str(n)\n",
    "            excerpt_text = excerpt[n]['text']\n",
    "            excerpt_page = n\n",
    "            excerpt_lang = excerpt[n]['lang']\n",
    "            #criando o dicionário para a inserção no grafo\n",
    "            excerpt_dict = \"\"\"{\n",
    "                uri: '\"\"\" + excerpt_uri +\"\"\"',\n",
    "                text: '\"\"\" + excerpt_text + \"\"\"',\n",
    "                page: '\"\"\" + str(excerpt_page) + \"\"\"',\n",
    "                lang: '\"\"\" + excerpt_lang + \"\"\"'\n",
    "                }\"\"\"\n",
    "            \n",
    "            #Criando a query para inserir o nó Exerpt\n",
    "            query = \"\"\"\n",
    "            MATCH  (t:Thesis{uri: '\"\"\" + thesis_repository['Thesis'][i] +  \"\"\"'})\n",
    "            MERGE  (e:Exerpt\"\"\" + str(excerpt_dict) + \"\"\")-[r:BFO_0000050]-(t)\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            results = graph.query(query)\n",
    "                \n",
    "            #Criando as relações com as entidades\n",
    "            for person in excerpt[n]['persons']:\n",
    "                query = \"\"\"\n",
    "                MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "                MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + person + \"\"\"'})\n",
    "                MERGE  (e)-[r:mentions]-(p)\n",
    "                \"\"\"\n",
    "                results = graph.query(query)\n",
    "\n",
    "            for gpe in excerpt[n]['gpes']:\n",
    "                query = \"\"\"\n",
    "                MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "                MERGE  (p:Place{uri: 'tag:stardog:api:\"\"\" + gpe + \"\"\"'})\n",
    "                MERGE  (e)-[r:mentions]-(p)\n",
    "                \"\"\"\n",
    "                results = graph.query(query)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f\"Processed and added to graph: {thesis_uri}\")\n",
    "        #Deetando o arquivo PDF após o processamento\n",
    "        os.remove(thesis_uri + '.pdf')\n",
    "    else:\n",
    "        print(f\"No PDF link found for {thesis_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui 2\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 4\n",
      "aqui 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extratc_text(tese_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair texto de uma tese em PDF e identificar entidades\n",
    "def extratc_text(tese_path):\n",
    "    \n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    excerpt = {}\n",
    "    \n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "        \n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "      \n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "            \n",
    "        except:\n",
    "            lang = 'Não_detectado'\n",
    "        \n",
    "        # Extraindo as entidades\n",
    "        page_extracted = False\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "            page_extracted = True\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "            page_extracted = True\n",
    "        \n",
    "        if page_extracted:\n",
    "\n",
    "            persons = []\n",
    "            gpes = []\n",
    "            #orgs = []\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                    persons.append(process_uri(ent.text))\n",
    "                if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                    gpes.append(process_uri(ent.text))\n",
    "                #if ent.label_ == \"ORG\":\n",
    "                #    orgs.append(process_uri(ent.text))\n",
    "                    \n",
    "            excerpt[page_number] = {'text': page_text, \n",
    "                                    'lang': lang, \n",
    "                                    'persons': list(set(persons)), \n",
    "                                    'gpes': list(set(gpes)),\n",
    "                                #'orgs': list(set(orgs))\n",
    "                                }\n",
    "\n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrair texto do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = extratc_text(thesis_uri + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tag:stardog:api:o_jeito_yanomami_de_pendurar_redes'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thesis_repository['Thesis'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionar excerpt no Grafo Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cypher query \n",
    "for n in range(len(excerpt)):\n",
    "     \n",
    "    excerpt_uri = thesis_repository['Thesis'][i] + '_p_' + str(n)\n",
    "    excerpt_text = excerpt[n]['text']\n",
    "    excerpt_page = n\n",
    "    excerpt_lang = excerpt[n]['lang']\n",
    "    #criando o dicionário para a inserção no grafo\n",
    "    excerpt_dict = \"\"\"{\n",
    "        uri: '\"\"\" + excerpt_uri +\"\"\"',\n",
    "        text: '\"\"\" + excerpt_text + \"\"\"',\n",
    "        page: '\"\"\" + str(excerpt_page) + \"\"\"',\n",
    "        lang: '\"\"\" + excerpt_lang + \"\"\"'\n",
    "    }\"\"\"\n",
    "    \n",
    "    #Criando a query para inserir o nó Exerpt\n",
    "    query = \"\"\"\n",
    "    MATCH  (t:Thesis{uri: '\"\"\" + thesis_repository['Thesis'][i] +  \"\"\"'})\n",
    "    MERGE  (e:Exerpt\"\"\" + str(excerpt_dict) + \"\"\")-[r:BFO_0000050]-(t)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results = graph.query(query)\n",
    "        \n",
    "    #Criando as relações com as entidades\n",
    "    for person in excerpt[n]['persons']:\n",
    "        query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + person + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "        results = graph.query(query)\n",
    "\n",
    "    for gpe in excerpt[n]['gpes']:\n",
    "        query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Place{uri: 'tag:stardog:api:\"\"\" + gpe + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "        results = graph.query(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(thesis_uri + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        MATCH  (e:Exerpt{uri: 'tag:stardog:api:o_jeito_yanomami_de_pendurar_redes_p_263'})\n",
      "        MERGE  (p:Person{uri: 'tag:stardog:api:wilbert'})\n",
      "        MERGE  (e)-[r:mentions]-(p)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + excerpt[263]['persons'][0] + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MERGE  (e:Exerpt{\n",
      "    uri: 'tag:stardog:api:revisao_narrativa_para_subsidiar_o_entendimento_do_panorama_da_cobertura_vacinal_em_criancas_menores_de_um_ano_de_idade_no_contexto_brasileiro_p_0',\n",
      "    text: ' \n",
      " UNIVERSIDADE DE SÃO PAULO  \n",
      "FACULDADE DE MEDICINA  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "SILVANETE MENDES MONTAGNINI  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "REVISÃO NARRATIVA PAR A SUBSIDIAR O ENTEND IMENTO DO PANORAMA \n",
      "DA COBERTURA VACINAL  EM CRIANÇAS MENORES  DE UM ANO DE IDADE , \n",
      "NO CONTEXTO BRASILEI RO \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "São Paulo  \n",
      "2024  \n",
      "  \n",
      " SILVANETE MENDES MONTAGNINI  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "REVISÃO NARRATIVA PAR A SUBSIDIAR O ENTEND IMENTO DO PANORAMA \n",
      "DA COBERTURA VACINAL  EM CRIANÇAS MENORES  DE UM ANO DE IDADE , \n",
      "NO CONTEXTO BRASILEI RO \n",
      " \n",
      " \n",
      " \n",
      "Versão corrigida  \n",
      "Resolução CoPGr 6018/11, de 01 de novembro de 2011 . \n",
      "A versão or iginal está disponível na Biblioteca FMUSP.  \n",
      " \n",
      " \n",
      " \n",
      "Dissertação apresentada à Faculdade de \n",
      "Medicina da Universid',\n",
      "    page: '0',\n",
      "    lang: 'pt'\n",
      "})-[r:BFO_0000050]-(t:Thesis{uri: 'tag:stardog:api:revisao_narrativa_para_subsidiar_o_entendimento_do_panorama_da_cobertura_vacinal_em_criancas_menores_de_um_ano_de_idade_no_contexto_brasileiro'})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '59 \\n de ESAVIS vem se estabelecendo e ganhando maior dimensão, mas a autonomia na \\nprodução de vacinas ainda é menor, em comparação à Índia . Fabricantes de países de \\nbaixo e médio nível socioeconômico têm um papel cada vez maior no fornecimento de \\nvacinas, e sua a entrada no mercado estimula quedas de preço das principais vacinas .  \\n 60 \\n 6. DISCUSSÃO  \\n \\nPelo exposto depreen de-se que, apesar do sucesso dos programas de vacinação, já \\nhavia sinais de preocupação em relação à manutenção das conquistas obtidas. A queda \\ndas coberturas vacinais vinha ocorrendo principalmente a partir de 2016.  \\nA vacinação se caracteriza por interdep endência de responsabilidades individuais, \\ncoletivas e institucionais. Esta dissertação priorizou a investigação sobre as \\nresponsabilidades institucionais na queda das coberturas vacinais.  \\nNesta revisão narrativa sobre a interrelação entre a cobertura vaci nal no Brasil e \\noutros indicadores de qualidade do SUS foram encontrados dados que corroboram a \\nqueda das coberturas vacinais, e dados que mostram fragilidades do SUS, no mesmo \\nperíodo.  \\nA cobertura vacinal registrada pelo antigo sistema API poderia estar s uperestimada. \\nOs registros eram de doses aplicadas, e não de pessoas imunizadas, nominal, como passou \\na ser feito a partir do SIPNI. Algumas vezes a cobertura ultrapassava a população alvo. \\nMas as dificuldades na implantação dos novos sistemas de informaçã o nominais podem \\nter contribuído para subregistro de doses de vacinas aplicadas. Entretanto, os dados do \\ninquérito de cobertura vacinal conduzido por Barata e colaboradores  (2023) , baseado em \\ndados da carteira vacinal das crianças investigadas, detectou qu eda da cobertura  vacinal, \\ne queda progressiva  da cobertura de todas as vacinas que necessitam de mais de uma dose \\npara completar o esquema de vacinação . Outros fatores estão influenciando a queda das \\ncoberturas vacinais. Entretanto são evidentes os problem as dos sistemas de informação. \\nSistemas complexos, com m últiplas entradas ; relatórios de doses aplicadas  inadequados, \\nlevando a d ificuldade de acesso aos dados  e demora na consolidação dos dados das \\ndiversas fontes ; perda de dados . Salienta -se que registro s inadequados podem levar a \\ninterpretações errôneas do problema . \\nSato e colaboradores (2023), em artigo em que analisaram a Cobertura Vacinal \\n(CV), a homogeneidade das CV e os casos  de sarampo no Brasil de 2011 a 2021,  referem \\nque, a partir de 2015, observ a-se queda progressiva  das CV e da homogeneidade, \\nacentuando -se após 2020 em todas as regiões, particularmente  Norte e Nordeste. \\nAglomerados de baixa CV foram  associados a piores indicadores d e desenvolvimento  \\nhumano, desigualdade social e menor  acesso à E stratégia de Saúde da Família . Até 2014, \\ntodas as regi ões brasileiras apresentavam  CV de primeira dose da vacina sarampo ( D1) \\n 61 \\n acima de 95%. A  partir de 2015, as coberturas começaram a cair  e, ap ós 2016, nenhuma \\nregião atingiu CV acima  de 95%.  Os autores co mentam que, n o Brasil, as ações verticais \\ndo PNI na década de 1980 contribu íram para diminuir o gradiente  social da CV e garantir \\no acesso universal à vacinação no país. Os primeiros inquéritos nacionais  de CV \\napontavam piores coberturas em  segmentos',\n",
       " 'lang': 'pt',\n",
       " 'persons': ['ap_os_2016', 'sato', 'barata'],\n",
       " 'gpes': ['nordeste',\n",
       "  'sus',\n",
       "  'brasil',\n",
       "  'pni',\n",
       "  'esavis',\n",
       "  'd1',\n",
       "  'saude_da_familia',\n",
       "  'india',\n",
       "  'cv',\n",
       "  'norte']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratc_text_NER(tese_uri, tese_path):\n",
    "\n",
    "    triplas = \"\"\" \"\"\"\n",
    "\n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "\n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "\n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "        except:\n",
    "            lang = None\n",
    "\n",
    "        # Extraindo as entidades\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        #orgs = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(process_uri(ent.text))\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(process_uri(ent.text))\n",
    "            #if ent.label_ == \"ORG\":\n",
    "            #    orgs.append(process_uri(ent.text))\n",
    "\n",
    "\n",
    "            \n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" rdf:type bibo:Excerpt.\n",
    "        stardog:\"\"\" + tese_uri +  \"\"\" <http://purl.obolibrary.org/obo/BFO_0000051> stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\".\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\" bibo:pages '\"\"\" + str(page_number + 1) +  \"\"\"'. \n",
    "        \"\"\"\n",
    "        if lang == 'pt':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@pt.\"\n",
    "        if lang == 'en':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@en.\"\n",
    "        \n",
    "        #print(set(persons), set(gpes))\n",
    "        for per in set(persons):  \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + per + \"\"\" rdf:type foaf:Person.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + per + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        for gpe in set(gpes): \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + gpe + \"\"\" rdf:type <https://schema.org/Place>.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + gpe + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    add_triplas_to_stardog(prefixos, triplas)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_lg\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install beautifulsoup4\n",
    "#%pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "import stardog\n",
    "import os\n",
    "import io\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from PyPDF2 import PdfReader\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buscar os links para a tese no Neo4j\n",
    "- Buscar o link do PDF no repositório da universidade\n",
    "- Baixar o PDF\n",
    "- Extrair o texto do PDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar links para a tese no Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando ao Neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neo4j variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME =os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "#Connecting to the graph\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URL,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thesis</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:stardog:api:substituicao_do_negro_de_fumo_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/3/3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:stardog:api:diversidade_na_unidade_a_tradi...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/71/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag:stardog:api:etnoarqueologia_na_terra_indig...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/71/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag:stardog:api:desenho_roupagem_e_corporeidad...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/93/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag:stardog:api:os_yanomami_e_a_morte</td>\n",
       "      <td>http://www.teses.usp.br/teses/disponiveis/8/81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tag:stardog:api:o_cinema_documentario_de_zezin...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/27/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tag:stardog:api:encontros_poeticos_e_podcasts_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/8/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tag:stardog:api:estrutura_fundiaria_da_amazoni...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/11/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tag:stardog:api:para_que_o_mundo_prossiga_uma_...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/27/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tag:stardog:api:so_a_luta_muda_a_vida_um_estud...</td>\n",
       "      <td>https://www.teses.usp.br/teses/disponiveis/47/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Thesis  \\\n",
       "0   tag:stardog:api:substituicao_do_negro_de_fumo_...   \n",
       "1   tag:stardog:api:diversidade_na_unidade_a_tradi...   \n",
       "2   tag:stardog:api:etnoarqueologia_na_terra_indig...   \n",
       "3   tag:stardog:api:desenho_roupagem_e_corporeidad...   \n",
       "4               tag:stardog:api:os_yanomami_e_a_morte   \n",
       "..                                                ...   \n",
       "95  tag:stardog:api:o_cinema_documentario_de_zezin...   \n",
       "96  tag:stardog:api:encontros_poeticos_e_podcasts_...   \n",
       "97  tag:stardog:api:estrutura_fundiaria_da_amazoni...   \n",
       "98  tag:stardog:api:para_que_o_mundo_prossiga_uma_...   \n",
       "99  tag:stardog:api:so_a_luta_muda_a_vida_um_estud...   \n",
       "\n",
       "                                           repository  \n",
       "0   https://www.teses.usp.br/teses/disponiveis/3/3...  \n",
       "1   https://www.teses.usp.br/teses/disponiveis/71/...  \n",
       "2   https://www.teses.usp.br/teses/disponiveis/71/...  \n",
       "3   https://www.teses.usp.br/teses/disponiveis/93/...  \n",
       "4   http://www.teses.usp.br/teses/disponiveis/8/81...  \n",
       "..                                                ...  \n",
       "95  https://www.teses.usp.br/teses/disponiveis/27/...  \n",
       "96  https://www.teses.usp.br/teses/disponiveis/8/8...  \n",
       "97  https://www.teses.usp.br/teses/disponiveis/11/...  \n",
       "98  https://www.teses.usp.br/teses/disponiveis/27/...  \n",
       "99  https://www.teses.usp.br/teses/disponiveis/47/...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cypher query to get all theses from USP\n",
    "query1 = \"\"\"\n",
    "MATCH (t:Thesis)-[:publisher]-(uni:University{uri:'tag:stardog:api:USP'})\n",
    "Match (e:Exerpt)\n",
    "RETURN distinct(t[\"uri\"]) as Thesis, t[\"repository\"] as repository \n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "MATCH (t:Thesis)-[:publisher]-(uni:University{uri:'tag:stardog:api:USP'})\n",
    "WHERE NOT EXISTS {(:Exerpt)--(t)}\n",
    "RETURN distinct(t[\"uri\"]) as Thesis, t[\"repository\"] as repository \n",
    "\"\"\"\n",
    "\n",
    "results = graph.query(query2)\n",
    "# Convert the results to a DataFrame\n",
    "thesis_repository = pd.DataFrame(results, columns=[\"Thesis\", \"repository\"])\n",
    "thesis_repository = thesis_repository[:100]\n",
    "thesis_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funcao para coletar link do pdf\n",
    "\n",
    "def get_pdf_link(url):\n",
    "    \n",
    "    #Fazer requisição e parsear o arquivo html\n",
    "    f = requests.get(url, verify=True).text#, verify=False) \n",
    "    soup = bs(f, \"html.parser\")\n",
    "    \n",
    "    #Coletando link para as teses\n",
    "    for doc in soup.find_all('a', href=True):\n",
    "        if doc['href'].endswith('.pdf'):\n",
    "            path = doc['href']\n",
    "            prefix_uni = 'https://www.teses.usp.br'\n",
    "            link = prefix_uni + path\n",
    "\n",
    "            return link\n",
    "    \n",
    "    return None\n",
    "\n",
    "#fazer download do arquivo\n",
    "def download_file(pdf_link, thesis_uri):\n",
    "    # NOTE the stream=True parameter below\n",
    "    r = requests.get(pdf_link, verify=True, stream=True)\n",
    "    # raise_for_status() is not needed with stream=True\n",
    "    # r.raise_for_status()\n",
    "    with open('tese.pdf', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    return \n",
    "\n",
    "#Carregando os modelos SpaCy para inglês e português \n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "nlp_pt = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "# Funcão que recebe uma string e a limpar para ficar no formato aceitável para uma URI\n",
    "def process_uri(x):\n",
    "    return (re.sub('[^a-zA-Z0-9_ ]', '',\n",
    "            unidecode(x.strip())\n",
    "                        .replace(\" \", \"_\")\n",
    "                        .replace(\"[\",\"\")\n",
    "                        .replace(\"]\",\"\")\n",
    "                        .replace(\"?\",\"\")\n",
    "                        .replace(\"'\",\"\")\n",
    "                        .lower()))\n",
    "\n",
    "\n",
    "# Função para extrair texto de uma tese em PDF e identificar entidades\n",
    "def extratc_text(tese_path):\n",
    "    \n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    excerpt = {}\n",
    "    \n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "        \n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "      \n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "            \n",
    "        except:\n",
    "            lang = 'Não_detectado'\n",
    "        \n",
    "        # Extraindo as entidades\n",
    "        page_extracted = False\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "            page_extracted = True\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "            page_extracted = True\n",
    "        \n",
    "        if page_extracted:\n",
    "\n",
    "            persons = []\n",
    "            gpes = []\n",
    "            #orgs = []\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                    persons.append(process_uri(ent.text))\n",
    "                if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                    gpes.append(process_uri(ent.text))\n",
    "                #if ent.label_ == \"ORG\":\n",
    "                #    orgs.append(process_uri(ent.text))\n",
    "                    \n",
    "            excerpt[page_number] = {'text': page_text, \n",
    "                                    'lang': lang, \n",
    "                                    'persons': list(set(persons)), \n",
    "                                    'gpes': list(set(gpes)),\n",
    "                                #'orgs': list(set(orgs))\n",
    "                                }\n",
    "\n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterando por todas as URI para extrair o texto e gravar no grafo NEO4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Downloading and extracting: substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural from https://www.teses.usp.br/teses/disponiveis/3/3133/tde-10082023-152417/publico/FabioJoseEsperCorr.pdf\n",
      "Extracted substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural\n",
      "Processed and added to graph: substituicao_do_negro_de_fumo_em_compositos_e_nanocompositos_de_borracha_natural\n",
      "Total time: 0 days 00:00:14.983103\n",
      "Partial time: 0 days 00:00:14.983103\n",
      "No PDF link found for diversidade_na_unidade_a_tradicao_policroma_da_amazonia_na_historia_indigena_de_longa_duracao_do_medio_solimoes_5001900_dc\n",
      "2 - Downloading and extracting: etnoarqueologia_na_terra_indigena_apiaka_do_pontal_e_isolados from https://www.teses.usp.br/teses/disponiveis/71/71131/tde-12092024-090856/publico/Dissertacao_Luis_Vinicius_corrigida.pdf\n",
      "Extracted etnoarqueologia_na_terra_indigena_apiaka_do_pontal_e_isolados\n",
      "Processed and added to graph: etnoarqueologia_na_terra_indigena_apiaka_do_pontal_e_isolados\n",
      "Total time: 0 days 00:03:11.628440\n",
      "Partial time: 0 days 00:02:56.645337\n",
      "3 - Downloading and extracting: desenho_roupagem_e_corporeidade_a_pintura_do_javari_dos_wauja__acervo_harald_schultz_maeusp from https://www.teses.usp.br/teses/disponiveis/93/93131/tde-21102024-160419/publico/2024_RenataCardosoGuimaraesHoffmann_VCorr.pdf\n",
      "Extracted desenho_roupagem_e_corporeidade_a_pintura_do_javari_dos_wauja__acervo_harald_schultz_maeusp\n",
      "Processed and added to graph: desenho_roupagem_e_corporeidade_a_pintura_do_javari_dos_wauja__acervo_harald_schultz_maeusp\n",
      "Total time: 0 days 00:04:20.840877\n",
      "Partial time: 0 days 00:01:09.212437\n",
      "4 - Downloading and extracting: os_yanomami_e_a_morte from https://www.teses.usp.br/teses/disponiveis/8/8134/tde-04052009-154152/publico/MOISES_RAMALHO.pdf\n",
      "Extracted os_yanomami_e_a_morte\n",
      "Processed and added to graph: os_yanomami_e_a_morte\n",
      "Total time: 0 days 00:06:33.235535\n",
      "Partial time: 0 days 00:02:12.395657\n",
      "5 - Downloading and extracting: a_dadiva_e_o_circulo_um_ensaio_sobre_reciprocidade_auwexavante from https://www.teses.usp.br/teses/disponiveis/8/8134/tde-29012007-215748/publico/Guilherme_Lavinas_Jardim_Falleiros_I.pdf\n",
      "Extracted a_dadiva_e_o_circulo_um_ensaio_sobre_reciprocidade_auwexavante\n",
      "Processed and added to graph: a_dadiva_e_o_circulo_um_ensaio_sobre_reciprocidade_auwexavante\n",
      "Total time: 0 days 00:08:10.143675\n",
      "Partial time: 0 days 00:01:36.907141\n",
      "6 - Downloading and extracting: neoliberalismo_e_reserva_de_vagas_o_novo_perfil_de_estudantestrabalhadores_e_trabalhadoras_do_departamento_de_geografia_da_universidade_de_sao_paulodgusp from https://www.teses.usp.br/teses/disponiveis/8/8136/tde-22082023-173119/publico/2023_PatriciaPaulaDaSilva_VCorr.pdf\n",
      "Extracted neoliberalismo_e_reserva_de_vagas_o_novo_perfil_de_estudantestrabalhadores_e_trabalhadoras_do_departamento_de_geografia_da_universidade_de_sao_paulodgusp\n",
      "Processed and added to graph: neoliberalismo_e_reserva_de_vagas_o_novo_perfil_de_estudantestrabalhadores_e_trabalhadoras_do_departamento_de_geografia_da_universidade_de_sao_paulodgusp\n",
      "Total time: 0 days 00:13:25.799808\n",
      "Partial time: 0 days 00:05:15.656133\n",
      "7 - Downloading and extracting: concepcoes_e_praticas_na_relacao_com_o_animal_reflexoes_sobre_o_caso_yanomami from https://www.teses.usp.br/teses/disponiveis/8/8134/tde-29122022-122430/publico/2005_AnnaMariaDeCastroAndrade.pdf\n",
      "Extracted concepcoes_e_praticas_na_relacao_com_o_animal_reflexoes_sobre_o_caso_yanomami\n",
      "Processed and added to graph: concepcoes_e_praticas_na_relacao_com_o_animal_reflexoes_sobre_o_caso_yanomami\n",
      "Total time: 0 days 00:15:19.788299\n",
      "Partial time: 0 days 00:01:53.988491\n",
      "8 - Downloading and extracting: a_corpacha_da_educacao_com_manoel_de_barros_encantacoes_amerindias_e_nomadismos_cosmocorporais from https://www.teses.usp.br/teses/disponiveis/48/48135/tde-28032024-074310/publico/DANI_VI_rev.pdf\n",
      "Extracted a_corpacha_da_educacao_com_manoel_de_barros_encantacoes_amerindias_e_nomadismos_cosmocorporais\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('localhost', 7687)) (ResolvedIPv4Address(('127.0.0.1', 7687)))\n",
      "Transaction failed and will be retried in 0.8517769761041648s (Failed to read from defunct connection IPv4Address(('localhost', 7687)) (ResolvedIPv4Address(('127.0.0.1', 7687))))\n",
      "Failed to read from defunct connection ResolvedIPv4Address(('127.0.0.1', 7687)) (ResolvedIPv4Address(('127.0.0.1', 7687)))\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 0.8434734996365822s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 1.8247409227755853s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 3.356446985694083s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 8.111501846343028s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "Unable to retrieve routing information",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gpe \u001b[38;5;129;01min\u001b[39;00m excerpt[n][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpes\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     60\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124m        MATCH  (e:Exerpt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124muri: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m excerpt_uri \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124m        MERGE  (p:Place\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124muri: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag:stardog:api:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m gpe \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124m        MERGE  (e)-[r:mentions]-(p)\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 65\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed and added to graph: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthesis_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#Deetando o arquivo PDF após o processamento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:431\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneo4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jError\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m     data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\driver.py:971\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[1;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:613\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[1;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransaction failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:563\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 563\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtx_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mManagedTransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtelemetry_sent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_success_cb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_success_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction, ManagedTransaction)\n\u001b[0;32m    572\u001b[0m         tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:433\u001b[0m, in \u001b[0;36mSession._open_transaction\u001b[1;34m(self, tx_cls, access_mode, api, metadata, timeout, api_success_cb)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_transaction\u001b[39m(\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m     api_success_cb: t\u001b[38;5;241m.\u001b[39mCallable[[\u001b[38;5;28mdict\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    432\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccess_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:130\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:167\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;66;03m# This is the first time we open a connection to a server in a\u001b[39;00m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;66;03m# cluster environment for this session without explicitly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# we shall use this database explicitly for all subsequent\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;66;03m# actions within this session.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <WORKSPACE> resolve home database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 167\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_routing_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimp_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bookmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43macquisition_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macquisition_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatabase_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_cached_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness_check_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    182\u001b[0m }\n\u001b[0;32m    183\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\facordei\\OneDrive - Capgemini\\Documents\\GitHub\\Indigenous-Slavery-KG\\.venv-IndigSlave\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:939\u001b[0m, in \u001b[0;36mNeo4jPool.update_routing_table\u001b[1;34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;66;03m# None of the routers have been successful, so just fail\u001b[39;00m\n\u001b[0;32m    938\u001b[0m log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to retrieve routing information\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 939\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to retrieve routing information\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Unable to retrieve routing information"
     ]
    }
   ],
   "source": [
    "# Gravar hora de início do processamento\n",
    "start_time = pd.Timestamp.now()\n",
    "parcial_time = pd.Timestamp.now()\n",
    "\n",
    "for i in range(len(thesis_repository)):\n",
    "\n",
    "    # Coletando o link do PDF\n",
    "    url = thesis_repository['repository'][i]\n",
    "    thesis_uri = thesis_repository['Thesis'][i][16:]\n",
    "    pdf_link = get_pdf_link(url)\n",
    "    if pdf_link is not None:\n",
    "        print(f\"{i} - Downloading and extracting: {thesis_uri} from {pdf_link}\")\n",
    "        # Download do arquivo PDF\n",
    "        # Verificando se o arquivo já existe e removendo se necessário\n",
    "        #if os.path.exists('tese.pdf'):\n",
    "        #   os.remove('tese.pdf')\n",
    "        download_file(pdf_link, thesis_uri)\n",
    "        \n",
    "        # Extraindo o texto e entidades\n",
    "        tese_path = 'tese.pdf'\n",
    "        excerpt = extratc_text(tese_path)\n",
    "        print(f\"Extracted {thesis_uri}\")\n",
    "        \n",
    "        # Salvando o triplas no grafo Neo4j\n",
    "        for n in excerpt.keys():\n",
    "     \n",
    "            excerpt_uri = thesis_repository['Thesis'][i] + '_p_' + str(n)\n",
    "            excerpt_text = excerpt[n]['text']\n",
    "            if \"'\" in excerpt_text:\n",
    "                excerpt_text = excerpt_text.replace(\"'\", \"\\\\'\")\n",
    "            excerpt_page = n\n",
    "            excerpt_lang = excerpt[n]['lang']\n",
    "            #criando o dicionário para a inserção no grafo\n",
    "            excerpt_dict = \"\"\"{\n",
    "                uri: '\"\"\" + excerpt_uri +\"\"\"',\n",
    "                text: '\"\"\" + excerpt_text + \"\"\"',\n",
    "                page: '\"\"\" + str(excerpt_page) + \"\"\"',\n",
    "                lang: '\"\"\" + excerpt_lang + \"\"\"'\n",
    "                }\"\"\"\n",
    "            \n",
    "            #Criando a query para inserir o nó Exerpt\n",
    "            query = \"\"\"\n",
    "            MATCH  (t:Thesis{uri: '\"\"\" + thesis_repository['Thesis'][i] +  \"\"\"'})\n",
    "            MERGE  (e:Exerpt\"\"\" + str(excerpt_dict) + \"\"\")-[r:BFO_0000050]-(t)\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            results = graph.query(query)\n",
    "                \n",
    "            #Criando as relações com as entidades\n",
    "            for person in excerpt[n]['persons']:\n",
    "                query = \"\"\"\n",
    "                MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "                MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + person + \"\"\"'})\n",
    "                MERGE  (e)-[r:mentions]-(p)\n",
    "                \"\"\"\n",
    "                results = graph.query(query)\n",
    "\n",
    "            for gpe in excerpt[n]['gpes']:\n",
    "                query = \"\"\"\n",
    "                MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "                MERGE  (p:Place{uri: 'tag:stardog:api:\"\"\" + gpe + \"\"\"'})\n",
    "                MERGE  (e)-[r:mentions]-(p)\n",
    "                \"\"\"\n",
    "                results = graph.query(query)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f\"Processed and added to graph: {thesis_uri}\")\n",
    "        #Deetando o arquivo PDF após o processamento\n",
    "        os.remove('tese.pdf')\n",
    "        print(f\"Total time: {pd.Timestamp.now() - start_time}\")\n",
    "        print(f\"Partial time: {pd.Timestamp.now() - parcial_time}\")\n",
    "        # Atualizando a hora parcial\n",
    "        parcial_time = pd.Timestamp.now()\n",
    "    else:\n",
    "        print(f\"No PDF link found for {thesis_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ajustar o codigo cypher para inserir todas as triplas de uma vez só vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrair texto do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = extratc_text(thesis_uri + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tag:stardog:api:o_jeito_yanomami_de_pendurar_redes'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thesis_repository['Thesis'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionar excerpt no Grafo Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cypher query \n",
    "for n in range(len(excerpt)):\n",
    "     \n",
    "    excerpt_uri = thesis_repository['Thesis'][i] + '_p_' + str(n)\n",
    "    excerpt_text = excerpt[n]['text']\n",
    "    excerpt_page = n\n",
    "    excerpt_lang = excerpt[n]['lang']\n",
    "    #criando o dicionário para a inserção no grafo\n",
    "    excerpt_dict = \"\"\"{\n",
    "        uri: '\"\"\" + excerpt_uri +\"\"\"',\n",
    "        text: '\"\"\" + excerpt_text + \"\"\"',\n",
    "        page: '\"\"\" + str(excerpt_page) + \"\"\"',\n",
    "        lang: '\"\"\" + excerpt_lang + \"\"\"'\n",
    "    }\"\"\"\n",
    "    \n",
    "    #Criando a query para inserir o nó Exerpt\n",
    "    query = \"\"\"\n",
    "    MATCH  (t:Thesis{uri: '\"\"\" + thesis_repository['Thesis'][i] +  \"\"\"'})\n",
    "    MERGE  (e:Exerpt\"\"\" + str(excerpt_dict) + \"\"\")-[r:BFO_0000050]-(t)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results = graph.query(query)\n",
    "        \n",
    "    #Criando as relações com as entidades\n",
    "    for person in excerpt[n]['persons']:\n",
    "        query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + person + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "        results = graph.query(query)\n",
    "\n",
    "    for gpe in excerpt[n]['gpes']:\n",
    "        query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Place{uri: 'tag:stardog:api:\"\"\" + gpe + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "        results = graph.query(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(thesis_uri + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        MATCH  (e:Exerpt{uri: 'tag:stardog:api:o_jeito_yanomami_de_pendurar_redes_p_263'})\n",
      "        MERGE  (p:Person{uri: 'tag:stardog:api:wilbert'})\n",
      "        MERGE  (e)-[r:mentions]-(p)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        MATCH  (e:Exerpt{uri: '\"\"\" + excerpt_uri + \"\"\"'})\n",
    "        MERGE  (p:Person{uri: 'tag:stardog:api:\"\"\" + excerpt[263]['persons'][0] + \"\"\"'})\n",
    "        MERGE  (e)-[r:mentions]-(p)\n",
    "        \"\"\"\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MERGE  (e:Exerpt{\n",
      "    uri: 'tag:stardog:api:revisao_narrativa_para_subsidiar_o_entendimento_do_panorama_da_cobertura_vacinal_em_criancas_menores_de_um_ano_de_idade_no_contexto_brasileiro_p_0',\n",
      "    text: ' \n",
      " UNIVERSIDADE DE SÃO PAULO  \n",
      "FACULDADE DE MEDICINA  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "SILVANETE MENDES MONTAGNINI  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "REVISÃO NARRATIVA PAR A SUBSIDIAR O ENTEND IMENTO DO PANORAMA \n",
      "DA COBERTURA VACINAL  EM CRIANÇAS MENORES  DE UM ANO DE IDADE , \n",
      "NO CONTEXTO BRASILEI RO \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "São Paulo  \n",
      "2024  \n",
      "  \n",
      " SILVANETE MENDES MONTAGNINI  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "REVISÃO NARRATIVA PAR A SUBSIDIAR O ENTEND IMENTO DO PANORAMA \n",
      "DA COBERTURA VACINAL  EM CRIANÇAS MENORES  DE UM ANO DE IDADE , \n",
      "NO CONTEXTO BRASILEI RO \n",
      " \n",
      " \n",
      " \n",
      "Versão corrigida  \n",
      "Resolução CoPGr 6018/11, de 01 de novembro de 2011 . \n",
      "A versão or iginal está disponível na Biblioteca FMUSP.  \n",
      " \n",
      " \n",
      " \n",
      "Dissertação apresentada à Faculdade de \n",
      "Medicina da Universid',\n",
      "    page: '0',\n",
      "    lang: 'pt'\n",
      "})-[r:BFO_0000050]-(t:Thesis{uri: 'tag:stardog:api:revisao_narrativa_para_subsidiar_o_entendimento_do_panorama_da_cobertura_vacinal_em_criancas_menores_de_um_ano_de_idade_no_contexto_brasileiro'})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '59 \\n de ESAVIS vem se estabelecendo e ganhando maior dimensão, mas a autonomia na \\nprodução de vacinas ainda é menor, em comparação à Índia . Fabricantes de países de \\nbaixo e médio nível socioeconômico têm um papel cada vez maior no fornecimento de \\nvacinas, e sua a entrada no mercado estimula quedas de preço das principais vacinas .  \\n 60 \\n 6. DISCUSSÃO  \\n \\nPelo exposto depreen de-se que, apesar do sucesso dos programas de vacinação, já \\nhavia sinais de preocupação em relação à manutenção das conquistas obtidas. A queda \\ndas coberturas vacinais vinha ocorrendo principalmente a partir de 2016.  \\nA vacinação se caracteriza por interdep endência de responsabilidades individuais, \\ncoletivas e institucionais. Esta dissertação priorizou a investigação sobre as \\nresponsabilidades institucionais na queda das coberturas vacinais.  \\nNesta revisão narrativa sobre a interrelação entre a cobertura vaci nal no Brasil e \\noutros indicadores de qualidade do SUS foram encontrados dados que corroboram a \\nqueda das coberturas vacinais, e dados que mostram fragilidades do SUS, no mesmo \\nperíodo.  \\nA cobertura vacinal registrada pelo antigo sistema API poderia estar s uperestimada. \\nOs registros eram de doses aplicadas, e não de pessoas imunizadas, nominal, como passou \\na ser feito a partir do SIPNI. Algumas vezes a cobertura ultrapassava a população alvo. \\nMas as dificuldades na implantação dos novos sistemas de informaçã o nominais podem \\nter contribuído para subregistro de doses de vacinas aplicadas. Entretanto, os dados do \\ninquérito de cobertura vacinal conduzido por Barata e colaboradores  (2023) , baseado em \\ndados da carteira vacinal das crianças investigadas, detectou qu eda da cobertura  vacinal, \\ne queda progressiva  da cobertura de todas as vacinas que necessitam de mais de uma dose \\npara completar o esquema de vacinação . Outros fatores estão influenciando a queda das \\ncoberturas vacinais. Entretanto são evidentes os problem as dos sistemas de informação. \\nSistemas complexos, com m últiplas entradas ; relatórios de doses aplicadas  inadequados, \\nlevando a d ificuldade de acesso aos dados  e demora na consolidação dos dados das \\ndiversas fontes ; perda de dados . Salienta -se que registro s inadequados podem levar a \\ninterpretações errôneas do problema . \\nSato e colaboradores (2023), em artigo em que analisaram a Cobertura Vacinal \\n(CV), a homogeneidade das CV e os casos  de sarampo no Brasil de 2011 a 2021,  referem \\nque, a partir de 2015, observ a-se queda progressiva  das CV e da homogeneidade, \\nacentuando -se após 2020 em todas as regiões, particularmente  Norte e Nordeste. \\nAglomerados de baixa CV foram  associados a piores indicadores d e desenvolvimento  \\nhumano, desigualdade social e menor  acesso à E stratégia de Saúde da Família . Até 2014, \\ntodas as regi ões brasileiras apresentavam  CV de primeira dose da vacina sarampo ( D1) \\n 61 \\n acima de 95%. A  partir de 2015, as coberturas começaram a cair  e, ap ós 2016, nenhuma \\nregião atingiu CV acima  de 95%.  Os autores co mentam que, n o Brasil, as ações verticais \\ndo PNI na década de 1980 contribu íram para diminuir o gradiente  social da CV e garantir \\no acesso universal à vacinação no país. Os primeiros inquéritos nacionais  de CV \\napontavam piores coberturas em  segmentos',\n",
       " 'lang': 'pt',\n",
       " 'persons': ['ap_os_2016', 'sato', 'barata'],\n",
       " 'gpes': ['nordeste',\n",
       "  'sus',\n",
       "  'brasil',\n",
       "  'pni',\n",
       "  'esavis',\n",
       "  'd1',\n",
       "  'saude_da_familia',\n",
       "  'india',\n",
       "  'cv',\n",
       "  'norte']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extratc_text_NER(tese_uri, tese_path):\n",
    "\n",
    "    triplas = \"\"\" \"\"\"\n",
    "\n",
    "    # Processando o arquivo em PDF\n",
    "    reader = PdfReader(tese_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    # Iterando por cada página\n",
    "    for page_number in range(number_of_pages):\n",
    "        \n",
    "\n",
    "        # Extraindo o texto da página\n",
    "        if page_number == 0:\n",
    "            page_text = (reader.pages[page_number].extract_text() + '\\n ' \n",
    "                        + reader.pages[page_number+1].extract_text()[:400])\n",
    "        else:\n",
    "            \n",
    "            if page_number == number_of_pages -1:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text())\n",
    "            \n",
    "            else:\n",
    "                page_text = (reader.pages[page_number-1].extract_text()[-400:] + '\\n ' \n",
    "                            + reader.pages[page_number].extract_text() + '\\n ' \n",
    "                            + reader.pages[page_number+1].extract_text()[:400])  \n",
    "\n",
    "        # Detectando o idioma do texto\n",
    "        try:\n",
    "            lang = detect(page_text)\n",
    "        except:\n",
    "            lang = None\n",
    "\n",
    "        # Extraindo as entidades\n",
    "        if lang == 'pt':\n",
    "            doc = nlp_pt(page_text)\n",
    "        if lang == 'en':\n",
    "            doc = nlp_en(page_text)\n",
    "\n",
    "        persons = []\n",
    "        gpes = []\n",
    "        #orgs = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\": #\"PERSON\":\n",
    "                persons.append(process_uri(ent.text))\n",
    "            if ent.label_ == \"LOC\": #\"GPE\":\n",
    "                gpes.append(process_uri(ent.text))\n",
    "            #if ent.label_ == \"ORG\":\n",
    "            #    orgs.append(process_uri(ent.text))\n",
    "\n",
    "\n",
    "            \n",
    "        tripla = \"\"\"\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" rdf:type bibo:Excerpt.\n",
    "        stardog:\"\"\" + tese_uri +  \"\"\" <http://purl.obolibrary.org/obo/BFO_0000051> stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\".\n",
    "        stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \"\"\" bibo:pages '\"\"\" + str(page_number + 1) +  \"\"\"'. \n",
    "        \"\"\"\n",
    "        if lang == 'pt':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@pt.\"\n",
    "        if lang == 'en':\n",
    "            tripla = tripla + \"stardog:\" + tese_uri + \"__page_\" + str(page_number + 1 ) + \" <http://purl.org/dc/terms/description> '\" + page_text.replace(\"'\",\"\").replace(u'\\\\', u' ') +  \"'@en.\"\n",
    "        \n",
    "        #print(set(persons), set(gpes))\n",
    "        for per in set(persons):  \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + per + \"\"\" rdf:type foaf:Person.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + per + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        for gpe in set(gpes): \n",
    "            tripla = tripla + \"\"\"\n",
    "            stardog:\"\"\" + gpe + \"\"\" rdf:type <https://schema.org/Place>.\n",
    "            stardog:\"\"\" + tese_uri + \"__page_\" + str(page_number + 1) + \"\"\" <https://schema.org/mentions> stardog:\"\"\" + gpe + \"\"\". \n",
    "            \"\"\"\n",
    "\n",
    "        triplas = triplas + \" \" + tripla\n",
    "\n",
    "    add_triplas_to_stardog(prefixos, triplas)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download pt_core_news_lg\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import stardog\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Stardog connection details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-IndigSlave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
